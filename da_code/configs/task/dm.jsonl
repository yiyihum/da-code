{"id": "dm-csv-001", "type": "Data Manipulation", "instruction": "Analyze the UFC Fighters’ Statistics 2024 dataset to identify the top fighters in each weight class and count how many remain undefeated. Please ensure the results are entered into the provided undefeated.csv file, adhering strictly to its format.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-002", "type": "Data Manipulation", "instruction": "Determine how many of the students have been married before and how many have never been married. Please enter the corresponding results in the appropriate sections of the provided result.csv file, ensuring the format is followed precisely.", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-003", "type": "Data Manipulation", "instruction": "Using the dataset, identify the top five most frequent educational qualifications for both mothers and fathers. For each qualification, calculate its frequency and sort the results in descending order. Save the results in top_qualifications.csv, ensuring the file includes the following columns: ‘Mother’s Qualification’, ‘Mother’s Frequency’, ‘Father’s Qualification’, and ‘Father’s Frequency’. Ensure qualifications are formatted like ‘10th Year of Schooling’.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-004", "type": "Data Manipulation", "instruction": "Analyze the dataset to determine the total number of Games held for both the Summer and Winter Olympics. Record the results in allGames.csv, adhering to the template provided in sample_allGames.csv. Additionally, for each edition of both the Summer and Winter Olympics, identify the host city and the total number of events conducted. Compile this information in allEvents.csv, ensuring it matches the structure of the provided sample_allEvents.csv template", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-005", "type": "Data Manipulation", "instruction": "Using the instructions provided in age.txt, count the number of people in each age group. If any values in the ‘Age’ column are missing, fill them with 30. Record the results in result.csv, following the structure and format outlined in the sample_result.csv template.", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-006", "type": "Data Manipulation", "instruction": "Identify which products are frequently purchased together in the same order. Specifically, find the different product pairs and calculate the number of times they are purchased together. Record the information for the top two product pairs with the highest co-purchase count in result.csv, following the format in sample_result.csv. The column names should be ‘product_a’ for the first product in the pair, ‘product_b’ for the second product, and ‘co_purchase_count’ for the number of times the two products are purchased together. Ensure product names follow the format ‘Heller Shagamaw Frame - 2016’.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-007", "type": "Data Manipulation", "instruction": "Calculate the top 10 most popular movies by considering only those whose number of votes falls within the top 15%. Use the formula provided in wrFormula.tex to perform the calculation. Once the calculations are complete, write the names of the top 10 movies into result.csv, following the format specified in sample_result.csv.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-008", "type": "Data Manipulation", "instruction": "Calculate the correlation coefficient between leverage_ratio and profitability_ratio. Based on the value of the correlation coefficient, determine whether the relationship is positive, negative, or shows no correlation. Write the results into correlation_results.csv, following the format provided in sample_correlation_results.csv.", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-009", "type": "Data Manipulation", "instruction": "Identify the top 10 best-rated authors, the most expensive authors, and the authors with the most ratings. Save the results in author.csv, following the format provided in sample_result.csv.”", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-010", "type": "Data Manipulation", "instruction": "Calculate the monthly total sales volume for each bike category. Then compute the average monthly sales volume for each category across all months. Ensure that the average is calculated as the mean of monthly totals, and save the results in avg_units_sold.csv, matching the format of sample_result.csv.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-011", "type": "Data Manipulation", "instruction": "Calculate the total quantity sold and total sales revenue for each bike category from 2016 to 2018. Ensure that total sales revenue accounts for any discounts applied to each order. Write the results into result.csv, following the exact structure and formatting of sample_result.csv.\n", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-012", "type": "Data Manipulation", "instruction": "Identify the top five users based on their total expenditure and provide their full names (first name and last name) along with their corresponding total expenditure. Ensure that the results are sorted in descending order by total expenditure and written into result.csv, following the structure and format of sample_result.csv.\n", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-013", "type": "Data Manipulation", "instruction": "From the top 20 clubs with the highest average overall scores in FIFA 20, identify the club with the best average physicality based on the BMI calculation from the players’ heights and weights. Using the chosen club, find the player with the highest shooting score based on data from BMI.txt. Record both the name of the club and the full name of this player in result.csv, ensuring the result matches the format of sample_result.csv.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-014", "type": "Data Manipulation", "instruction": "Calculate the Wilson score for each review using the formula provided in Wilson.tex. Then, extract the summaries of the top 3 reviews based on the highest Wilson scores. Write the results into result.csv, ensuring that the format matches the template provided in sample_result.csv", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-015", "type": "Data Manipulation", "instruction": "Identify the top player in terms of games played, runs scored, hits, and home runs from the baseball dataset. Ensure that you save the player’s name and the respective category (e.g., “Most Games Played”) in result.csv, following the format provided in sample_result.csv.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-016", "type": "Data Manipulation", "instruction": "Compile season statistics for both Italian Serie A (IT1) and the Bundesliga (BESC), focusing on identifying the top-performing clubs in terms of wins for each season. Ensure that the results include the competition ID, season, and top-performing club for each competition, and write the results into a CSV file named result.csv, following the format provided in sample_result.csv.\n", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-017", "type": "Data Manipulation", "instruction": "Follow the instructions in data_standard.md to calculate the Net Promoter Score (NPS) for the dataset. After calculating the Net_Promoter_Score, save the results in result.csv, following the format and structure provided in the file template.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-018", "type": "Data Manipulation", "instruction": "Please review the Data Science Programs list dataset to determine the top 10 universities with the most affordable data science programs. Ensure that tuition fees are normalized to a per-year basis. Record the university names and their corresponding normalized tuition fees, sorted from lowest to highest, in result.csv. Ensure the output is formatted according to the structure specified in sample_result.csv.", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-019", "type": "Data Manipulation", "instruction": "Analyze the dataset to identify the top 20 teams based on their average score. For each of these teams, record the number of draws they have had. Arrange the results in result.csv, sorting by the number of draws from highest to lowest. Ensure that the format follows the structure outlined in sample_result.csv", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-020", "type": "Data Manipulation", "instruction": "Please review the Telco customer churn dataset to determine the top 10 cities with the highest churn rates. Ensure that the churn rate is calculated as the proportion of customers who churned in each city. Save the findings in result.csv, ensuring the output is formatted according to the template in sample_result.csv.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-021", "type": "Data Manipulation", "instruction": "You need to identify the top 3 most popular product categories among families with 0, 1, and 2 children. Use the total amount spent on each product category to determine popularity. Write the results into result.csv, following the format specified in sample_result.csv.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-022", "type": "Data Manipulation", "instruction": "Assuming the current year is 2024, calculate the Mean Campaign Acceptance Rate by Age for each country, based on the age groups specified in result.csv. Use the total number of accepted campaigns to compute the acceptance rate. Fill in the results in result.csv, ensuring the format is consistent with the provided file.", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-023", "type": "Data Manipulation", "instruction": "Calculate the average number of campaigns it takes for customers with each education level to accept their first offer. Record the results in average_campaign_accepted_by_education.csv, following the format specified in sample_result.csv.", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-024", "type": "Data Manipulation", "instruction": "Using the guidelines provided in tips.txt, calculate the total number of online purchases (NumWebPurchases) and in-store purchases (NumStorePurchases) for different income groups. The income groups should be categorized into the intervals specified in tips.txt. Once the calculations are completed, fill in the results in purchase_by_income.csv, following the exact format of the provided template.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-025", "type": "Data Manipulation", "instruction": "Enhance the existing code in analys.py to calculate the winning and losing probabilities for each team, as detailed in tips.txt. Determine which team has the highest winning probability and which team has the highest losing probability. Once identified, record their names along with their corresponding probabilities in team_probabilities.csv, ensuring the results follow the format provided in sample_result.csv.\n", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-026", "type": "Data Manipulation", "instruction": "Complete the analysis.py script to rank FIFA 22 players across various positions based on a specified score, covering the years 2015 to 2022. The score calculation for each position is outlined in the provided text and Markdown files. Ensure that both male and female player data are included in the analysis, and output the top 20 ranked players per position. Write the final results to result.csv, following the format of sample_result.csv.\n", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-027", "type": "Data Manipulation", "instruction": " Identify the top 10 countries by the number of produced shows and their corresponding counts, as well as the top 10 movie genres by the number of occurrences and their corresponding counts. Record the results in the provided templates: Top_10_countries.csv and Top_10_Movies.csv.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-028", "type": "Data Manipulation", "instruction": "Calculate the total profit for each state by subtracting the Cost from the Revenue. Then, sort the states by their total profits in descending order. Finally, save the results in state_profit.csv, ensuring the format matches the provided template.\n", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-029", "type": "Data Manipulation", "instruction": "Identify the top 3 users with the most pull requests and record their usernames and the number of pull requests in the top3_pull_requests.csv file using the provided template.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-030", "type": "Data Manipulation", "instruction": "Identify the latest 10 pull requests, merge the related file data, and find the unique files involved in these pull requests. Record the results in the unique_files.csv file using the sample_result.csv template.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-031", "type": "Data Manipulation", "instruction": " Identify the users who made the last 6 pull requests for the specific file \"src/compiler/scala/reflect/reify/phases/Calculate.scala\". Record the results in the users_last_6.csv file using the provided template.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-032", "type": "Data Manipulation", "instruction": "Calculate the proportion of 1-day retention being True for the gate_30 and gate_40 versions, respectively. Record the results in the retention_by_version.csv file using the provided template.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-033", "type": "Data Manipulation", "instruction": "Compare the 1-day retention rates between two versions of a game (gate_30 and gate_40) according to the instructions in guidance.txt. Calculate the probability (expressed as a decimal) that the retention rate is higher for gate_30 and record the result in the probability_greater_retention.csv file using the provided template.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-034", "type": "Data Manipulation", "instruction": "Calculate the proportion of 7-day retention being True for the gate_30 and gate_40 versions, respectively. Record the results in the retention_7_by_version.csv file using the provided template.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-035", "type": "Data Manipulation", "instruction": "Convert all time columns to Coordinated Universal Time (UTC) and record each user’s pulled files based on their pid. If a user pulled multiple files within one pid, you need to record these files separately. Write the results in the output.csv file using the format provided in sample_output.csv.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-036", "type": "Data Manipulation", "instruction": "Identify the last six users who made pull requests for `src/compiler/scala/reflect/reify/phases/Calculate.scala`. and fill in their usernames in the template file users_last_6.csv.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-037", "type": "Data Manipulation", "instruction": "Identify the top three users who made the most pull requests for src/compiler/scala/reflect/reify/phases/Calculate.scala. Fill in their usernames in the provided template file top_3_developers.csv.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-038", "type": "Data Manipulation", "instruction": "I want to know the number of pull requests made by two users with the nicknames “soc” and “xeno-by” for each year between 2011 and 2016. Please fill in your statistical results in the provided template file pull_requests_by_year_and_author.csv.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-039", "type": "Data Manipulation", "instruction": "conduct a supply chain analysis of three ingredients used in an avocado toast according to the instructions in tips.md, utilizing the Open Food Facts database. Identify the list of ingredients and their countries of origin, and record the results in the ingredient_origins.csv file using the provided template.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-040", "type": "Data Manipulation", "instruction": "Categorize the salary scale into four levels according to the salaries of all employees. For the company size with the most top-level employees, determine the designations and salaries of the top 10 paid employees. Save the results in result.csv, following the format in sample_result.csv.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-041", "type": "Data Manipulation", "instruction": "Count the stop outcomes for male and female drivers when they are pulled over for speeding, and express these outcomes as proportions. Save the results in the stop_outcomes_by_gender.csv file, ensuring that the format matches the provided template.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-042", "type": "Data Manipulation", "instruction": "Calculate the total number of days between the InvoiceDate and the CohortDate (the date of a customer’s first purchase) for each entry in the dataset. Save the calculated difference as CohortIndex in the result.csv file, ensuring the output matches the provided format", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-043", "type": "Data Manipulation", "instruction": "Calculate the retention rate for each cohort by comparing the number of unique customers who made a purchase in subsequent months to the initial cohort size. Save the calculated retention data to retension.csv, ensuring the format matches the provided template.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-044", "type": "Data Manipulation", "instruction": "Calculate the average unit price paid for items by customer groups, where each group is defined by the month of their first purchase. Track how the average unit price changes over time for each cohort. Save the results in average_price.csv, ensuring the format matches the provided template file.\n", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-045", "type": "Data Manipulation", "instruction": "According to the information in tips.txt, you need to use the RFM method to calculate values for each CustomerID in the datasmart.csv for the recent 12 months. Save the results in datasmart.csv.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-046", "type": "Data Manipulation", "instruction": "Calculate the annualized volatility and annualized variance for Microsoft trading data, using daily returns based on the ‘Close’ prices. Assume 252 trading days in a year for the annualization calculations. Save the calculated results in result.csv, ensuring the format matches the template provided in sample_result.csv.", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-047", "type": "Data Manipulation", "instruction": "Calculate the historical beta of FamaFrenchData using the Capital Asset Pricing Model (CAPM). Write the calculated results into result.csv, with the column named “result”.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-048", "type": "Data Manipulation", "instruction": "Your task is to calculate the drawdown of USO, an ETF that tracks oil prices. Fill in the results into result.csv, as provided in the corresponding file.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-049", "type": "Data Manipulation", "instruction": "Use the mean to fill in any missing values in the dataset. Then, calculate the correlation between Population Density and Life Expectancy, as well as the correlation between Population Density and GDP. Please output the answers below in JSON format by filling in the placeholders in:\n\n\"\"\"\n{\n  \"Correlation between Population Density and Life Expectancy\": [...],\n  \"Correlation between Population Density and GDP\": [...]\n}\n\"\"\"", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-050", "type": "Data Manipulation", "instruction": "Using the 2017 stock return datasets for the 9 biggest companies, calculate the cumulative returns for three different portfolio strategies: the default portfolio, the equal-weight portfolio, and the market value-weighted portfolio. Save the results in result.csv, ensuring the output follows the required format.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-051", "type": "Data Manipulation", "instruction": "Calculate the portfolio volatility of the default portfolio and express the result as a percentage. Write the result into output.csv, with the column labeled as result", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-052", "type": "Data Manipulation", "instruction": "Calculate the RFM (Recency, Frequency, Monetary) score for each customer, build segmentation based on these scores, and assign a level to each customer. Save the results, including the customer segmentation and levels, in result.csv.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-053", "type": "Data Manipulation", "instruction": "Using a 1-3 scale, calculate the RFM score for each CustomerID in RFM_Score.csv. Fill in the corresponding RFM scores for each customer, ensuring the results are saved in RFM_Score.csv as per the provided file format.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-054", "type": "Data Manipulation", "instruction": "Calculate the Sharpe Ratio for each asset and identify both the minimum and maximum Sharpe ratios. Save the results in result.csv, ensuring the output follows the format specified in sample_result.csv.", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-055", "type": "Data Manipulation", "instruction": "Calculate the cumulative returns of the portfolio (Portfolio) and the excess returns over the risk-free rate (Portfolio_Excess) based on FamaFrenchData over time. After completing the calculations, fill in the results in result.csv, ensuring the provided Date column is maintained.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-056", "type": "Data Manipulation", "instruction": "Using the Portfolio Risk Management dataset, select the equal-weighted portfolio and calculate its historical beta with the Fama-French data. Save the results in result.csv, ensuring the output follows the format provided in sample_result.csv.", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-057", "type": "Data Manipulation", "instruction": "Calculate a set of summary statistics on the purchase data, broken down by ‘device’ (Android or iOS) and ‘gender’ (Male or Female). These summary statistics should include the total purchases, average purchase amount, and purchase count for each group. Fill the corresponding blanks in purchase_summary.csv with these summary statistics, ensuring the format matches the provided template.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-058", "type": "Data Manipulation", "instruction": "Calculate and print the confidence interval for the difference in conversion rates (lift) between a test group and a control group. After performing the calculation, write the results into result.csv, ensuring the format matches the provided sample_result.csv.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-059", "type": "Data Manipulation", "instruction": "Analyze the purchasing behavior of users during the first week after their registration date. Calculate the average number of purchases made each day within the first week, and fill the results into result.csv.", "hardness": "Hard", "post_process": []}
{"id": "dm-csv-060", "type": "Data Manipulation", "instruction": "Calculate the average daily purchases and paywall views for the entire population. After calculating the results, write them into result.csv, ensuring the format matches the structure provided in sample_result.csv.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-061", "type": "Data Manipulation", "instruction": "Calculate the dates of the earliest and most recent reviews, the total number of private rooms, and the average listing price. Fill in the results into result.csv, ensuring the format matches the template provided in result.csv.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-062", "type": "Data Manipulation", "instruction": "Analyze the handwashing history dataset to calculate the average monthly reduction in the proportion of deaths after handwashing practices began on June 1, 1847. Record your findings in result.csv, ensuring the format matches the required template.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-063", "type": "Data Manipulation", "instruction": "Identify the oldest business on each continent and fill in the relevant information in result.csv, ensuring the format follows the specifications provided in result.csv.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-064", "type": "Data Manipulation", "instruction": "Identify the restaurants in the dataset that have been operating since before the year 1800. Fill in their relevant information into result.csv, ensuring the format matches the specifications provided in result.csv", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-065", "type": "Data Manipulation", "instruction": "Retrieve the necessary data to calculate the regression line for each category, with ‘days’ as the independent variable. Save the results to daily_sales_per_category.csv, ensuring the data is properly formatted.", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-066", "type": "Data Manipulation", "instruction": "For each of the top 10 cities with the most orders, retrieve the necessary data for each timestamp of the order stages. Save the results to order_stage_times_top_10_cities.csv, ensuring the data is properly formatted.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-067", "type": "Data Manipulation", "instruction": "Calculate the average delivery time for orders placed each day between June 1, 2017, and June 30, 2018. Save the results in a file named daily_avg_shipping_time.csv, ensuring the data is saved in chronological order.", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-068", "type": "Data Manipulation", "instruction": "Calculate the average occupancy per aircraft and save the result to occupancy_rate.csv", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-069", "type": "Data Manipulation", "instruction": "Identify the top 5 airports that attract the most business class passengers. Save the results in top_airports_business.csv, ensuring the data is properly formatted.", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-070", "type": "Data Manipulation", "instruction": "Calculate the number of individual wrestlers, tag teams, triple teams, and teams with more than 3 members from the Wrestlers table. Save the results in a file named wrestlers_team_count.csv, with the columns named: \"No_of_Individual_Wrestlers\", \"No_of_Tag_Teams\", \"No_of_Triple_Teams\", and \"No_of_Teams_with_More_Than_3_Members\"", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-071", "type": "Data Manipulation", "instruction": "Identify wrestlers in the dataset whose names contain more than 2 ampersands (&). Save the corresponding names in a file named wrestlers_with_more_than_2_ampersands.csv, with the column \"name.”", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-072", "type": "Data Manipulation", "instruction": "Analyze the dataset to determine the total number of title belts. Save the result in a file named number_of_titles.csv, with the column named \"Number_of_Titles\".", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-073", "type": "Data Manipulation", "instruction": "Calculate the number of title belts for each promotion (WE, WWF, WCW, NXT, ECW) in the dataset. Fill the results into promotions_title_counts.csv, ensuring the data is properly formatted", "hardness": "Easy", "post_process": []}
{"id": "dm-csv-074", "type": "Data Manipulation", "instruction": "Analyze the dataset to find the number of title belts for each promotion and gender. Fill the results into  promotions_gender_title_counts.csv, ensuring the data includes both the promotions and gender columns with the format provided", "hardness": "Medium", "post_process": []}
{"id": "dm-csv-075", "type": "Data Manipulation", "instruction": "Using the formula from tips.md, calculate Algeria's World Population Percentage for 2030, 2040, and 2050, starting from the year 2022. Please output the answers below in JSON format by filling in the placeholders in:\n\n\"\"\"\n{\n  \"Algeria 2030 World Population Percentage\": [...],\n  \"Algeria 2040 World Population Percentage\": [...],\n  \"Algeria 2050 World Population Percentage\": [...]\n}\n\"\"\"", "hardness": "Medium", "post_process": []}
