{"id": "dw-clean-001", "type": "Data Cleaning", "instruction": "NYC_Open_Data_Parking_Violations is stored in the local. We need to clean the noisy data. There is a local document that stores data standards. Please follow the data standards for data cleaning.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-clean-001"]}}], "post_process": []}
{"id": "dw-clean-002", "type": "Data Cleaning", "instruction": "Clean the data in the database using the local data standards document.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-clean-002"]}}], "post_process": []}
{"id": "dw-clean-003", "type": "Data Cleaning", "instruction": "There have been a number of complaints indicating that some New York residents have been receiving multiple parking tickets for a single violation. This is resulting in the affected residents having to incur additional legal fees for a single incident. You have been tasked with identifying records that reflect this duplication of violations.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-clean-003"]}}], "post_process": []}
{"id": "dw-clean-004", "type": "Data Cleaning", "instruction": "Handle the missing data by  following rules:\r\nFor normal numerical columns (including normalized-losses, bore, stroke, horsepower, peak-rpm), replace their missing values with their respective means.\r\nFor the categorical variable column num-of-doors, replace missing values with the most frequent value.\r\nDelete rows with missing values in the price column.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-clean-004"]}}], "post_process": []}
{"id": "dw-clean-006", "type": "Data Cleaning", "instruction": "Follow the data standard to clean the data, fill missing values using the most frequent value (mode) within each group defined by Street Name and Block. Save the result in \"Building_Permits.csv\"", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-clean-006"]}}], "post_process": []}
{"id": "dw-clean-007", "type": "Data Cleaning", "instruction": "Only keep the airports and aircrafts information in the database in english. Don't create new db or csv files.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-clean-007"]}}], "post_process": []}
{"id": "dw-clean-012", "type": "Data Cleaning", "instruction": "Extract specific job-related information, including job titles, technical skills, and educational degrees. Filtering out incomplete and not necessary records, save the result in \"result.csv\"", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-clean-012"]}}], "post_process": []}
{"id": "dw-clean-021", "type": "Data Cleaning", "instruction": "Follow the data schema to add new columns. Save the result in 'cars_details_merges.csv'", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-clean-021"]}}], "post_process": []}
{"id": "dw-clean-028", "type": "Data Cleaning", "instruction": "Calculate the values \u200b\u200bof is_arrested for different ratings and save them in 'result.csv'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-clean-028"]}}], "post_process": []}
{"id": "dw-clean-031", "type": "Data Cleaning", "instruction": "Merge the data, save the result in 'RI-clean.csv'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-clean-031"]}}], "post_process": []}
{"id": "dw-load-001", "type": "Data Loading", "instruction": "Complete data wrangling according to predefined data schema.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-load-001"]}}], "post_process": []}
{"id": "dw-load-002", "type": "Data Loading", "instruction": "Load these csv into the wwe.db sqlite database according to the schema.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-load-002"]}}], "post_process": []}
{"id": "dw-load-003", "type": "Data Loading", "instruction": "Load these csv into the sport.db sqlite database according to the schema.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-load-003"]}}], "post_process": []}
{"id": "dw-load-004", "type": "Data Loading", "instruction": "A batch of data about players has arrived, some of it may already exist in the database. Please organize and add it to the sport.db database.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-load-004"]}}], "post_process": []}
{"id": "dw-load-005", "type": "Data Loading", "instruction": "Load the data into the sqlite database 'database.db'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-load-005"]}}], "post_process": []}
{"id": "dw-load-006", "type": "Data Loading", "instruction": "Load the data into the sqlite database 'database.db'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-load-006"]}}], "post_process": []}
{"id": "dw-load-007", "type": "Data Loading", "instruction": "Calculate the profits for each sector from the `fortune500` data, with the results including the sector name and the 80th percentile of profits for that sector. Additionally, find the first occurrence date for each tag in the `stackoverflow` data. Save the results of the former in `profit.csv` and the latter in `startdates.csv`.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-load-007"]}}], "post_process": []}
{"id": "dw-load-008", "type": "Data Loading", "instruction": "Load the data into the sqlite database 'database.db'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-load-008"]}}], "post_process": []}
{"id": "dw-load-009", "type": "Data Loading", "instruction": "Generate a list of unique combinations of order_id and customer_id for orders of Trek brand products that received at least a 20% discount, and save it to 'order_customer.db'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-load-009"]}}], "post_process": []}
{"id": "dw-load-010", "type": "Data Loading", "instruction": "Query to get the top 10 customers based on total purchase amount, save the results to 'order_customer.db', which including each customer\u2019s name, their total number of transactions, and their rank based on the number of transactions.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dw-load-010"]}}], "post_process": []}
{"id": "text2sql001", "type": "Data Transformation", "instruction": "Determine which industries have the highest average valuations from 2019 to 2021, and tell me what new unicorns are in these industries?", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/text2sql001"]}}], "post_process": []}
{"id": "text2sql002", "type": "Data Transformation", "instruction": "Which are the most common categories for the oldest businesses on each continent? Show the continent, category and the number (greater than 5). ", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/text2sql002"]}}], "post_process": []}
{"id": "dm-csv-001", "type": "Data Transformation", "instruction": "I want to know the best fighters of every UFC weight class. Tell me in each class, how many fighters have never been defeated. Please fill in the results into CSV files, undefeated.csv", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dm-csv-001"]}}], "post_process": []}
{"id": "dt001", "type": "Data Transformation", "instruction": "Calculates rolling averages and standard deviations for height measurements in manufacturing, establishes control limits based on these statistics, and flags any measurements that fall outside these limits. Save the result in 'result.csv'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dt001"]}}], "post_process": []}
{"id": "dt002", "type": "Data Transformation", "instruction": "Create a report listing the top five assignments based on total donation amounts, including the assignment name, region, total rounded donation amount, and donor type.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dt002"]}}], "post_process": []}
{"id": "dt003", "type": "Data Transformation", "instruction": "Generate a report that lists the highest-impact assignments in each region, including their names, regions, impact scores, and the total number of donations received. Only include assignments that have received donations.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dt003"]}}], "post_process": []}
{"id": "dt004", "type": "Data Transformation", "instruction": "Create a summary showing the ten busiest start times for charging sessions by day and hour, specifically for shared users, including the total number of sessions for each period.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dt004"]}}], "post_process": []}
{"id": "dt005", "type": "Data Transformation", "instruction": "Show me a list of industry groups along with how many companies they have and their total carbon footprints for the latest year, sorted from highest to lowest footprint.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dt005"]}}], "post_process": []}
{"id": "dt006", "type": "Data Transformation", "instruction": "Create a summary that shows how many international students there are and their average scores for depression", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dt006"]}}], "post_process": []}
{"id": "dm-csv-009", "type": "Data Manipulation", "instruction": "Identify the top 10 best-rated authors, the most expensive authors, and the authors with the most ratings, save results to 'author.csv' following the template provided in'sample_result.csv'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dm-csv-009"]}}], "post_process": []}
{"id": "dm-csv-010", "type": "Data Manipulation", "instruction": "Calculate the monthly average sales volume for each bike category and write the results into 'avg_units_sold.csv' following the template of 'sample_result.csv'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dm-csv-010"]}}], "post_process": []}
{"id": "dm-csv-011", "type": "Data Manipulation", "instruction": "Calculate the total quantity sold and total sales revenue for each bike type from 2016 to 2018, write the results into 'result.csv' following the template of 'sample_result.csv'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dm-csv-011"]}}], "post_process": []}
{"id": "dm-csv-043", "type": "Data Manipulation", "instruction": "Calculate the retention data of each cohort, and save the results to 'retension.csv'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dm-csv-043"]}}], "post_process": []}
{"id": "dm-csv-044", "type": "Data Manipulation", "instruction": "Calculate the average unit price paid for items by groups of customers over time, where each group is based on the month of their first purchase. Save the results to 'average_price.csv', utilizing the provided template file.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dm-csv-044"]}}], "post_process": []}
{"id": "dm-csv-050", "type": "Data Manipulation", "instruction": "Using 2017 stock return datasets for 9 biggest companies, calculate the cumulative returns of three different portfolio strategies(default portfolio, equal-weight portfolio, and market value-weighted portfolio), and save the results in result.csv.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dm-csv-050"]}}], "post_process": []}
{"id": "dm-csv-052", "type": "Data Manipulation", "instruction": "Calculate RFM_Score for each customer, build segmentation and define the level, then assign it to each customer, save the result to 'result.csv'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dm-csv-052"]}}], "post_process": []}
{"id": "dm-csv-007", "type": "Data Manipulation", "instruction": "Following tips in \"wrFormula.tex\", please take a look at the TMDB 5000 Movie Dataset and determine the top 10 most popular movies. Save the list in a file called 'result.csv' for our records.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dm-csv-007"]}}], "post_process": []}
{"id": "dm-csv-015", "type": "Data Manipulation", "instruction": "I need you to go through the baseball dataset and identify the top player in terms of games played, runs scored, hits, and home runs. Make sure to save this information in a file named 'result.csv' following the template of `sample_result.csv`.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dm-csv-015"]}}], "post_process": []}
{"id": "dm-csv-016", "type": "Data Manipulation", "instruction": "As we look to analyze our football match data, I need your team to compile season statistics for both Italian Serie A (IT1) and the Bundesliga (BESC). Focus on identifying the top-performing clubs in terms of wins for each season. Once you've gathered this information, summarize the results in a CSV file named season_winning_clubs.csv.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/dm-csv-016"]}}], "post_process": []}
{"id": "di001", "type": "Data Insights", "instruction": "Get the year-to-date performance of Magnificent 7 stocks, show the percentage change in their price (Post-Market Close) from the beginning of the current year to the most recent available data", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/di001"]}}], "post_process": []}
{"id": "di002", "type": "Data Insights", "instruction": "What strategies could be implemented at electric vehicle charging stations to better accommodate the high volume of users and long-duration charging sessions observed at popular locations and peak times?", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/di002"]}}], "post_process": []}
{"id": "di003", "type": "Data Insights", "instruction": "Do you have some book data here, can you tell me who the protagonist is in each book?", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/di003"]}}], "post_process": []}
{"id": "di004", "type": "Data Insights", "instruction": "Can we review how Amazon and Facebook have been performing against the S&P 500? I\u2019d like to see the average daily return differences. Please pull up the latest data.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/di004"]}}], "post_process": []}
{"id": "di005", "type": "Data Insights", "instruction": "I'm curious about how companies, especially those under large conglomerates, are positioned in the Fortune 500. Can you pull up a ranked list for us to look over?", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/di005"]}}], "post_process": []}
{"id": "di006", "type": "Data Insights", "instruction": "Could you analyze which sectors have been leading in terms of average company valuations over the last three years? I\u2019d also like to know about any standout new companies in those sectors.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/di006"]}}], "post_process": []}
{"id": "di007", "type": "Data Insights", "instruction": "People started washing their hands on 1847-06-01. How much did it reduce the monthly proportion of deaths on average?", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/di007"]}}], "post_process": []}
{"id": "plot-bar-004", "type": "Visualization", "instruction": "Enhance the provided analysis.py, correct any potential errors, plot the images and save them in 'result.png' following the form of 'plot.yaml'", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/plot-bar-004"]}}], "post_process": ["plot_process"]}
{"id": "plot-line-015", "type": "Visualization", "instruction": "Please use the 2017 stock return data for the 9 largest companies to calculate the daily cumulative returns for three portfolio strategies: equal-weight, market value-weighted, highest Sharpe ratio, and global minimum volatility. Generate a line plot as specified in 'plot.yaml' and save it as 'result.jpg'. You can refer to 'analysis.py' for relevant code", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/plot-line-015"]}}], "post_process": ["plot_process"]}
{"id": "plot-pie-008", "type": "Visualization", "instruction": "Please find out which hub city has the largest biker average delivery distance. Then, generate a pie chart illustrating the distribution of order deliveries by driver modes in that city, adhering to the guidelines in 'plot.yaml', and save the chart in `result.jpg`", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/plot-pie-008"]}}], "post_process": ["plot_process"]}
{"id": "plot-bar-006", "type": "Visualization", "instruction": "Please compile the total scores of the top 10 football teams from the past 23 years and present them in a bar chart following the form of 'plot.yaml'. Save the image as 'team.png' so that we can better understand their performance.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/plot-bar-006"]}}], "post_process": ["plot_process"]}
{"id": "plot-bar-007", "type": "Visualization", "instruction": "Using the dataset and the calculation method in 'NeighborhoodCalculate.txt', create a bar chart showing the distribution of the top 10 neighborhoods by the number of listings. Save the bar chart as 'result.png' with dimensions 16x8. Title the chart \"Top 10 Neighborhoods by Number of Listings\", label the x-axis as \"Neighborhood\" with neighborhood names, and label the y-axis as \"Number of Listings\".", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/plot-bar-007"]}}], "post_process": ["plot_process"]}
{"id": "plot-bar-015", "type": "Visualization", "instruction": "Compile the sales data for products of each size sold on dataset. Sort the sizes in ascending order and plot these figures in a bar chart, measuring sales in units of $10,000. Save the image as result.png with dimensions 12x6. Title the chart 'Sales by Product Size', label the x-axis as 'Product Size', and the y-axis as 'Net Revenue in 10,000 dollars'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/plot-bar-015"]}}], "post_process": ["plot_process"]}
{"id": "plot-bar-005", "type": "Visualization", "instruction": "Using the dataset, draw a bar chart showing the number of people in each age group who filled out the survey. Follow the method for dividing age groups as outlined in AgeGroup.md. Save the bar chart as 'result.png' with the title 'Age Group Distribution', the x-axis labeled as 'Age Group', and the y-axis labeled as 'Count'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/plot-bar-005"]}}], "post_process": ["plot_process"]}
{"id": "plot-line-006", "type": "Visualization", "instruction": "Plot the global seasonal average temperature changes using the Climate Change Dataset and following the instructions in tips.txt. Save the plotted line graph as result.png with dimensions (16, 6). Title the graph \"Average temperature in each season\", label the x-axis as \"Year\", and label the y-axis as \"Average temperature\". Use the legend title \"Seasons Average Temperature\" and include legend labels for \"Spring\", \"Summer\", \"Autumn\", and \"Winter\". Assign line colors as follows: \"#ffa500\" for Spring, \"#0000ff\" for Summer, \"#008000\" for Autumn, and \"#ff0000\" for Winter.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/plot-line-006"]}}], "post_process": ["plot_process"]}
{"id": "plot-pie-005", "type": "Visualization", "instruction": "Complete the analysis.py script based on the instructions in guidance.txt to count the number of games for the four major genres in the Mobile Strategy Game dataset. Plot their proportions in a pie chart and save it as result.png. Size the chart as (12, 8) and use Green, Orange, Blue, and Red for pie colors. Include the genre names in the legend.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/plot-pie-005"]}}], "post_process": ["plot_process"]}
{"id": "plot-scatter-002", "type": "Visualization", "instruction": "Please create a scatter plot following the form of 'plot.yaml' to visualize the relationship between observed probabilities and predicted probabilities of football match outcomes? Use the CSV file compressed in gzip format and follow the instructions in 'guidance.txt'. Save the plot as 'result.png'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/plot-scatter-002"]}}], "post_process": ["plot_process"]}
{"id": "plot-bar-020", "type": "Visualization", "instruction": "Create a stacked horizontal bar chart, which illustrates the average days per order stage forthe top 10 cities by sales. Save the chart as \"result.png\" with settings from \"plot.yaml\".", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/plot-bar-020"]}}], "post_process": ["plot_process"]}
{"id": "data-sa-001", "type": "Statistical", "instruction": "Calculate the p-value and determine whether to reject or fail to reject the null hypothesis that the mean number of goals in women's and men's international soccer matches is the same. Use a 10% significance level. Save the result to 'result.csv'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/data-sa-001"]}}], "post_process": []}
{"id": "data-sa-026", "type": "Statistical", "instruction": "You need to determine the 99% Conditional Value at Risk for our portfolio using the historical data from 2008-2009. Utilize a Student's t-distribution and ensure the findings are saved in result.csv.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/data-sa-026"]}}], "post_process": []}
{"id": "data-sa-028", "type": "Statistical", "instruction": "Please analyze IBM stock using the Black-Scholes model. Calculate the option prices based on the annualized volatility and double the volatility from our historical data. Ensure the results are filled into result.csv.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/data-sa-028"]}}], "post_process": []}
{"id": "data-sa-029", "type": "Statistical", "instruction": "Please apply a delta hedging approach to our IBM portfolio using European put options. Make sure to compile your results in `result.csv` with the prescribed output format for review", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/data-sa-029"]}}], "post_process": []}
{"id": "data-sa-031", "type": "Statistical", "instruction": "Please conduct an analysis to see if there's a significant shift in the correlation between mortgage delinquencies and portfolio returns post-2008 financial crisis. Ensure the results are recorded in the specified output file `result.csv`.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/data-sa-031"]}}], "post_process": []}
{"id": "data-sa-039", "type": "Statistical", "instruction": "You are required to perform a Mann-Whitney U test to compare the number of goals scored in FIFA Women's and Men's World Cup matches from 2002 onwards. The test aims to evaluate whether the average number of goals in women's matches significantly exceeds that in men's matches. If the resulting p-value is less than 0.01, you should reject the null hypothesis (\"reject\"); otherwise, you should fail to reject the null hypothesis (\"fail to reject\"). Record the calculation outcomes and conclusion in the file named `result.csv` according to the specified format.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/data-sa-039"]}}], "post_process": []}
{"id": "data-sa-051", "type": "Statistical", "instruction": "You are tasked with identifying the geographic region and primary source of CO2 emissions with the highest levels. Additionally, conduct ANOVA tests to compare emissions from various fuel sources within each region. Record the analysis results in the file named anova_results.csv as per the provided format.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/data-sa-051"]}}], "post_process": []}
{"id": "data-sa-054", "type": "Statistical", "instruction": "I need you to perform an analysis on the Statistical Thinking dataset. Calculate 10,000 bootstrap replicates to determine the variance in annual rainfall at the Sheffield Weather Station. Please save your findings in 'result.csv'.(Set Random seed as 42)", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/data-sa-054"]}}], "post_process": []}
{"id": "data-sa-004", "type": "Statistical", "instruction": "Could you analyze our Business Case dataset to perform a hypothesis test comparing bike rentals across different weather conditions? I need the results formatted and saved in a file named 'weather.csv'  according to the required format.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/data-sa-004"]}}], "post_process": []}
{"id": "data-sa-043", "type": "Statistical", "instruction": "I need you to explore the Airline Reviews Dataset and calculate the correlation matrix for Overall Rating, Seat Comfort, Staff Service, and Food & Beverages. Ensure the output is filled correctly into 'result.csv', following its format.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/data-sa-043"]}}], "post_process": []}
{"id": "data-sa-106", "type": "Statistical", "instruction": "We have seen three different measures to calculate the importance of the characters, get the correlation between PageRank, betweenness centrality and degree centrality for each books using Pearson correlation, we have provided you correlation1.csv", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/data-sa-106"]}}], "post_process": []}
{"id": "ml-binary-013", "type": "ML Classification", "instruction": "Predict whether each turbine will fail based on the data provided in `Test.csv`. Write the prediction results into a file named target.csv, with a single column labeled \"Target\". Please format your results according to the example provided in `sample_target.csv.`", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-binary-013"]}}], "post_process": []}
{"id": "ml-competition-001", "type": "ML Classification", "instruction": "Design a method to predict churn based on the bank customer data in test.csv for the churn prediction competition. Save your results into submission.csv, adhering to the format specified in sample_submission.csv.\r\n", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-competition-001"]}}], "post_process": []}
{"id": "ml-competition-003", "type": "ML Classification", "instruction": "As a contestant in this health features and medical condition prediction competition, design a method to predict the data in test.csv according to the competition requirements. Write your results into submission.csv, following the format provided in sample_submission.csv.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-competition-003"]}}], "post_process": []}
{"id": "ml-multi-003", "type": "ML Classification", "instruction": "Predict the experience level of job positions in test.csv using the dataset, and write the results into result.csv with the column name \"formatted_experience_level\".\r\n", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-multi-003"]}}], "post_process": []}
{"id": "ml-multi-011", "type": "ML Classification", "instruction": "Predict the sentiment of the data in Corona_NLP_test.csv from the Coronavirus Tweets NLP - Text Classification dataset, classifying them as \"Positive,\" \"Negative,\" or \"Neutral.\" Write the predicted results into sentiment.csv with the column labeled \"Sentiment.\"\r\n", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-multi-011"]}}], "post_process": []}
{"id": "ml-competition-006", "type": "ML Classification", "instruction": "You are participating in the Wine Quality Prediction competition by designing a method to predict test.csv data according to competition requirements. Submit your results in submission.csv, adhering to the format specified in sample_submission.csv.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-competition-006"]}}], "post_process": []}
{"id": "ml-competition-005", "type": "ML Classification", "instruction": "You are a participant in the Patient data for cirrhosis outcomes prediction competition by designing a method to predict test.csv data according to competition requirements. Submit your results in submission.csv, adhering to the format specified in sample_submission.csv.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-competition-005"]}}], "post_process": []}
{"id": "ml-multi-008", "type": "ML Classification", "instruction": "Predict the categories based on the text information in test.csv for the News Aggregator Dataset competition. Save the predicted results into a file named category.csv, with the column name \"CATEGORY\".", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-multi-008"]}}], "post_process": []}
{"id": "ml-binary-012", "type": "ML Classification", "instruction": "Predict the sentiment of the comments in test.csv. Save your prediction results into sentiment.csv, using the column name 'emotion' to represent the sentiment.\r\n", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-binary-012"]}}], "post_process": []}
{"id": "ml-binary-009", "type": "ML Classification", "instruction": "Predict passenger satisfaction in test.csv using the dataset. Save the prediction results into result.csv with the column name 'satisfaction'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-binary-009"]}}], "post_process": []}
{"id": "ml-regression-002", "type": "ML Regression", "instruction": "Predict the electricity prices in test.csv using the dataset. Write your prediction results into result.csv with the column name \"price actual\".\r\n", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-regression-002"]}}], "post_process": []}
{"id": "ml-regression-004", "type": "ML Regression", "instruction": "Predict the popularity of songs based on the dataset. Write the prediction results into popularity.csv with the column labeled \"Popularity\" using the data from test.csv.\r\n", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-regression-004"]}}], "post_process": []}
{"id": "ml-competition-009", "type": "ML Regression", "instruction": "Design a solution for the abalone dataset competition, incorporating the supplementary dataset. Generate prediction results in submission.csv following the format of sample_submission.csv.\r\n", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-competition-009"]}}], "post_process": []}
{"id": "ml-regression-011", "type": "ML Regression", "instruction": "Predict the Biogas Generation Estimate (cu-ft/day) in test.csv using the biogas dataset. Write the prediction results into result.csv with the column name 'biogas_generation_estimate_cuftday'.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-regression-011"]}}], "post_process": []}
{"id": "ml-regression-014", "type": "ML Regression", "instruction": "Predict the prices of vehicles in the test.csv. Write the predicted results into price.csv with the column name \"price\" using the data from test.csv.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-regression-014"]}}], "post_process": []}
{"id": "ml-regression-015", "type": "ML Regression", "instruction": "Predict the appliance energy consumption in test.csv . Write the predicted results into appliance.csv with the column name \"Appliances\" using the data from test.csv.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-regression-015"]}}], "post_process": []}
{"id": "ml-regression-012", "type": "ML Regression", "instruction": "Predict the Mileage of vehicles in test.csv using the dataset of vehicle information in New York described in README.md. Write the prediction results into result.csv with the column name \"Mileage\".", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-regression-012"]}}], "post_process": []}
{"id": "ml-regression-008", "type": "ML Regression", "instruction": "Predict the product sales based on the shoe product information in the test.csv. Write the prediction results into quantity.csv with the column name \"quantity_sold\" using the data from test.csv.\r\n", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-regression-008"]}}], "post_process": []}
{"id": "ml-competition-008", "type": "ML Regression", "instruction": "Please work on predicting flood probabilities using the competition dataset. Save your predictions for test.csv in a file named submission.csv, following the example in sample_submission.csv.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-competition-008"]}}], "post_process": []}
{"id": "ml-competition-017", "type": "ML Regression", "instruction": "Generate predictions for the data in test.csv as part of the Automated Essay Scoring competition. Save your results in a submission file named submission.csv, following the format specified in sample_submission.csv.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-competition-017"]}}], "post_process": []}
{"id": "ml-cluster-006", "type": "ML Clustering", "instruction": "Perform a clustering task on the Patient Dataset. Save the clustering results in cluster.csv with the column names \"Feature_i\" (where i represents the ith value in the feature vector) and \"Cluster\" (the cluster label).", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-cluster-006"]}}], "post_process": []}
{"id": "ml-cluster-009", "type": "ML Clustering", "instruction": "Perform a clustering task on the global countries dataset, dividing the data into 3 clusters. Save the results in cluster.csv with the column names \"Feature_i\" (where i represents the ith value in the feature vector) and \"Cluster\" (the cluster label).\r\n", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-cluster-009"]}}], "post_process": []}
{"id": "ml-cluster-010", "type": "ML Clustering", "instruction": "Perform a clustering task on the dataset, dividing the data into an appropriate number of clusters. Save the clustering results in cluster.csv with the columns named \"Feature_i\" (where i indicates the ith value of the feature vector) and \"Cluster\" (the label of the cluster).\r\n", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-cluster-010"]}}], "post_process": []}
{"id": "ml-cluster-013", "type": "ML Clustering", "instruction": "Perform a clustering task on the dataset of socioeconomic and health factors for various countries, dividing the data into an appropriate number of clusters. Save the clustering results in a file named cluster.csv with the column names \"Feature_i\" (where i represents the ith value of the feature vector) and \"Cluster\" (the label of the cluster).", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-cluster-013"]}}], "post_process": []}
{"id": "ml-cluster-016", "type": "ML Clustering", "instruction": "Perform a clustering task on the dataset to segment the customers into an appropriate number of clusters. Save the clustering results in a file named cluster.csv with the column names \"Feature_i\" (where i represents the ith value of the feature vector) and \"Cluster\" (the label of the cluster).\r\n", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-cluster-016"]}}], "post_process": []}
{"id": "ml-cluster-019", "type": "ML Clustering", "instruction": "Please review our customer data from 2009-2010 and cluster the customers into distinct groups. Capture these clusters in a file named cluster.csv for our records with column names 'Feature_i' (for each feature) and 'Cluster' (for the cluster labels).", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-cluster-019"]}}], "post_process": []}
{"id": "ml-cluster-014", "type": "ML Clustering", "instruction": "Using the dataset, divide the data into a reasonable number of clusters. Save the clustering results in 'cluster.csv' with column names 'Feature_i' (for each feature) and 'Cluster' (for the cluster labels).", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-cluster-014"]}}], "post_process": []}
{"id": "ml-cluster-007", "type": "ML Clustering", "instruction": "Perform a clustering task on the dataset. Save the clustering results in cluster.csv with the column names \"Feature_i\" (where i represents the ith value in the feature vector) and \"Cluster\" (the cluster label).\r\n", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-cluster-007"]}}], "post_process": []}
{"id": "ml-cluster-002", "type": "ML Clustering", "instruction": "Please analyze the wine chemical components in wine-clustering.csv, cluster them into groups, and store the results in result.csv. Make sure to include the column names \"Feature_i\" (where i represents the ith value in the feature vector) and \"Cluster\" (the cluster label).", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-cluster-002"]}}], "post_process": []}
{"id": "ml-cluster-005", "type": "ML Clustering", "instruction": "Please conduct clustering analysis on the blob_dataset.csv dataset. Save the results in cluster_blob.csv, ensuring columns 'Feature_i' for feature vector values and 'Cluster' for cluster labels are included.", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./da_code/source/ml-cluster-005"]}}], "post_process": []}
