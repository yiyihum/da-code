id,Comments,id.,Natural language instruction,Refined Instruction,Hints,Competition,Brief description of the Task,Brief description of the context,Input format,Output format,w/o ML,w/o knowledge,Who in charge,Source,Context details,Setup,Who check,Double check,Data description
,"不能用机器学习，答案不唯一

×
",dm-z023,"Please read the given study_performance.csv, which is a table about student learning performance. Now, please write a Python method for me to use this CSV file to predict math_score through linear regression using data other than math-score",,,,,pandas analysis,ipynb,CSV,No,Liang Sirui,https://www.kaggle.com/code/bhavikjikadara/student-performance-linear-regression-100/notebook#Evaluation,https://drive.google.com/drive/folders/1FunZzoqxh_WEIL279h6Qc6wUGyIffqHC,没有标准答案,,,,
,"不能有机器学习

×",Kaggle-70,"I am going to do a steel plate defect detection. Please load the UCI steel plate defect dataset, do the initial cleaning and preprocessing, and then predict the defect probability using the XGBoost algorithm modeling for me. Finally  you are supposed to save the prediction to 'result.csv'.",,,,,pandas analysis & sklearn,csv,CSV,No,Chengfeng,https://www.kaggle.com/code/japleenkaurbedi/steel-plate,https://drive.google.com/drive/folders/1j1jRXpRlahG1wzorJcGxJ7hVlMIvE6Av?usp=sharing,,,,,
,"不能有机器学习

×",zDC5-12,"Q: Run a linear regression using the Fama-French five-factor model to analyze the returns of a portfolio adjusted for risk (Portfolio_Excess), print the regression's adjusted R-squared value. A: 0.8367245019225793",,,,,,"csv, md",CSV,Yes,yy,Statistical tests for normality | Python (datacamp.com),https://drive.google.com/drive/folders/14P3TB_psQXOzHHT02qD0eho3ghJq8l_M?usp=drive_link,,,,,
,"不需要Data Cleaning任务

×",pd002,"Data clening。According to the data standard file, modify and filter the original csv file to generate a new csv file that meets the data standard",,,,,pandas,csv,CSV,No,zyt,https://www.kaggle.com/datasets/vsridevi/cardio-good-fitness/data,https://drive.google.com/drive/u/0/folders/1ClO4y_1f2sFIT2ha_vKVgQoQhzX7x_A5,✅,,,,
,"答案不固定

×",zDC6-6,"Q: Group users by gender and device, and analyze which demographic has the highest monthly revenue (possible answers: 'Android+Female', 'Android+Male', 'Ios+Female', 'Ios+Male'). A:Ios+Male",,,,,,csv,Single,No,yy,Grouping & aggregating | Python (datacamp.com),https://drive.google.com/drive/folders/1RIu333xmibHA7QXhbgFr1DXhls4-ZCkI?usp=drive_link,,,,,
,"感觉有点多此一举，而且过于简单

×",dm-z029,"Right now, I'm going to analyze a bunch of laptop data. Select the appropriate columns for analysis; these columns cannot have more than 20 categories. For these columns, calculate the average price for each category in these columns and set the column name to ""TARGET_MEAN"". Save the dataframe with the most categories in all results to ""result.csv""",,,,,pandas analysis,csv,CSV,Yes,Chengfeng,https://www.kaggle.com/code/berkayozturkx/laptop-price-prediction,https://drive.google.com/drive/folders/1Xp_dZzGzcirJBvlLTdMdcZf7l-hhbszF?usp=sharing,✅,,,,
,"跟前面的问题重复了

×",pd048,calculate the number of pull requests submitted each (calendar) month during the project's lifetime.,,,,,"csv,md",CSV,No,No,zyt,https://github.com/Andy-Nkumane/The-GitHub-History-of-the-Scala-Language,pd048 - Google 云端硬盘,,,,,
,"跟前面的问题重复了 

×",pd049,Count the number of pull requests submitted by each user and save them as csv,,,,,"csv,md",CSV,No,No,zyt,https://github.com/Andy-Nkumane/The-GitHub-History-of-the-Scala-Language,pd049 - Google 云端硬盘,,,,,
,"跟前面的问题重复了 

×",pd050,What files were changed in the last ten pull requests?,,,,,"csv,md",CSV,No,No,zyt,https://github.com/Andy-Nkumane/The-GitHub-History-of-the-Scala-Language,pd050 - Google 云端硬盘,,,,,
,"跟Drug的敏感信息有关

×",zDC1-2,"Q:Did the rate of drug-related stops and the rate of vehicle searches both increase significantly between 2005 and 2015? If yes, then output 'Y', if not, then output 'N'. A: N",,,You can calculate the rate by resampling the corresponding column.,,,CSV,Single,No,yy,https://campus.datacamp.com/courses/analyzing-police-activity-with-pandas/analyzing-the-effect-of-weather-on-policing?ex=1,https://drive.google.com/drive/folders/10LIPayvt4nAHaYXXWCLl5wSx4BjoY3wW?usp=drive_link,✅,,,,
,"跟Vilolation等敏感信息有关

×",zDC1-3,"Calculate the arrest rate for each combination of violation and rating, save the result to result.csv.",,,,,,"csv, md",CSV,Yes,yy,https://campus.datacamp.com/courses/analyzing-police-activity-with-pandas/analyzing-the-effect-of-weather-on-policing?ex=1,https://drive.google.com/drive/folders/1IvaDvTRqMbzqunUOBDkiURzXMrIxVbXV?usp=drive_link,✅,,,,
,"过于简单

×",pd003,"For data.csv, complete data analysis according to the given file format and requirements.",,,,,pandas,csv,CSV,No,zyt,https://www.kaggle.com/code/sasakitetsuya/why-is-german-bike-market-so-profitable/notebook,https://drive.google.com/drive/u/0/folders/1mwf0DRCGrsR7nqN_GDulXFxu5k1mOsE9,✅,,,,
,"过于简单，而且没什么实际意义

×",dm027,"Please make a query based on the database I have provided. Required to show the invoice of the customer from Brazil.The resultant table should show the customer's full name, Invoice ID, Date of the invoice and billing country. Please save the result in result.csv.",,,,,sqlite,db,CSV,No,Chengfeng,https://www.kaggle.com/code/alaasedeeq/chinook-questions-with-sqlite/notebook,https://drive.google.com/drive/folders/1tMP34PUpDB-2ZgH40vI_EdTzu8i2zEWC?usp=sharing,？？,,,,
,"过于简单，就5行代码

×",Kaggle-75,"Please tell me which artist has the most number of songs charting in 2021 spotify. Sort their top 10 in descending order and add a ""Count"" column to indicate how many of their works have charted. Save the result in ""result.csv"".",,,,,pandas analysis,csv,CSV,No,Chengfeng,https://www.kaggle.com/code/muhammedtausif/top-songs-eda/notebook,https://drive.google.com/drive/folders/14wSthZUzvRWcKo4ojRYRSLA470vrbS71?usp=sharing,,,,,
,"结果受数据处理方法的波动太大

×
",dmz-022,"Following the existing code and hints provided in analysis.ipynb, complete a recommendation system based on TF-IDF and cosine similarity. Utilize the metrics outlined in result.txt to calculate two types of similarities for 'S.T.A.L.K.E.R.: Shadow of Chernobyl' in order to identify the top 5 books most similar to it. Record the names of these books in the result.txt file",,,,,plotly & pandas,"ipynb, txt, csv",txt,No,Jianwen,https://www.kaggle.com/code/cloudy17/eda-steam,https://drive.google.com/drive/folders/1zEwgRQFJWQ3DwMvAQOZ2gNyB3kb9Cx4V?usp=sharing,✅,,,,
,"没看懂为什么date, pid, year都是个很简单的数字

×",pd030,calculate the number of pull requests submitted each (calendar) month during the project's lifetime.,,,,,"csv,py,md",CSV,No,No,zyt,https://projects.datacamp.com/projects/163,https://drive.google.com/drive/folders/1kdi8Gp-F_Mmgtf_4dD4pWOyTProffik_,✅,,,,
,"没看懂这是要干什么，如果只是resample的话结果会有随机性吧

×",pd041,Here we will use bootstrapping: We will repeatedly re-sample our dataset (with replacement) and calculate 1-day retention for those samples. The variation in 1-day retention will give us an indication of how uncertain the retention numbers are.,,,,,"csv,md",CSV,No,No,zyt,https://projects.datacamp.com/projects/184,https://drive.google.com/drive/folders/10dNWvNYkK31Kl1Jf0FYNQDE3C6OZmKTw,✅,,,,
,"没看懂这是要干什么，如果只是resample的话结果会有随机性吧

×",pd042,Here we will use bootstrapping: We will repeatedly re-sample our dataset (with replacement) and calculate 1-day retention for those samples. The variation in 1-day retention will give us an indication of how uncertain the retention numbers are.Adding a column with the % difference between the two AB-groups,,,,,"csv,md",CSV,No,No,zyt,https://projects.datacamp.com/projects/184,https://drive.google.com/drive/folders/1zHAUlpe_i74uKFFId3UKbVCmrpdJwdbU,✅,,,,
,"没什么实际意义

×",dmz-026,"Could you please help me to count the distribution of scores for each question for couples, i.e., what percent of people pick this score for each score. For the last category ""Divorce Y/N"" no statistics are needed. The final result should be saved in ""result.csv"".",,,,,pandas analysis,"csv, txt",CSV,Yes,Chengfeng,https://www.kaggle.com/code/azminetoushikwasi/divorce-reasons-machine-interpretation-analysis/notebook,https://drive.google.com/drive/folders/1rp4_-r2bV3wNqmU0cWhJuWlnN43oqZsH?usp=sharing,✅,,,,
,"没有提供的google drive链接

×",pd005,"For data.csv, filter the 2015 data and calculate the total profit by age category, complete data analysis according to the given file format and requirements.",,,,,pandas,csv,CSV,No,zyt,https://www.kaggle.com/code/sasakitetsuya/why-is-german-bike-market-so-profitable/notebook,,✅,,,,
56b4aeb8-756a-48bd-a068-e24a5a626cc7,"没有真值

×",text2sql001,"Determine which industries have the highest average valuations from 2019 to 2021, and tell me what new unicorns are in these industries?",,,,,CSV-based Text-to-SQL,"csv, json, xlsx, md, txt, py, ipynb, pdf, img",CSV,No,Fangyu,https://app.datacamp.com/learn/projects/1531,https://drive.google.com/file/d/1R1mfoP_A9mFfS6buvYW0GIbLWvzuRNT3/view?usp=drive_link,✅,, ,,
21dd4809-86e5-4785-8c43-ae2091902142,"没有真值

×",text2sql002,"Which are the most common categories for the oldest businesses on each continent? Show the continent, category and the number (greater than 5). ",,,,,CSV-based Text-to-SQL,,CSV,No,Fangyu,https://app.datacamp.com/learn/projects/worlds_oldest_businesses,https://drive.google.com/file/d/1MXVqNE4BYu_hJGl4Y1HN6gy6cf_JvOhl/view?usp=drive_link,✅,,,,
,"没有真值

×",zbq001,"I am working on a project where I need to forecast PM2.5 concentrations in mining areas. To achieve this, I require air quality data with specific parameters from cities with gold mining activities and their environs. Parameters: PM2.5 PM10, Cities: United States: Sacramento, South Africa: Johannesburg, Australia: Bendigo From 2018 to 2022. I am seeking assistance in writing a Python script to fetch this air quality data from the Bigquery API. I intend to use this data for my forecasting model to analyze PM2.5 concentrations in relation to the given parameters in mining areas. Please help to continue the my python scripts and save this data with 5 columns on city, country, pollutant, value, timestamp as 'data.csv'"",",,,,,,,,,Fangyu,https://stackoverflow.com/questions/76833664/how-to-fetch-data-from-openaq-api-with-python-filter-by-country-city-and-spec,,,,,,
,"没有真值的google drive链接

×",zdc100,People started washing their hands on 1847-06-01. How much did it reduce the monthly proportion of deaths on average? Save the number in result.txt,,,,,,csv,txt,No,Fangyu,https://projects.datacamp.com/projects/20,,,,,,
,"缺失表格信息，过于简单

×",timezone,"Change the time in the data to UTC+8 time（data info：(type:datetime, timezone:+5:30)）
or 
This dataset was originally created with my system time, so all the date-times are in my local timezone ('Asia/Colombo'). Since different machines can have different timezones, it's important to standardize the timezone in the dataset to ensure consistency when using multiple virtual machines to collect data. Therefore, in this notebook, your task is to convert the dataset from its original timezone to UTC for future ease of use.",,,,,pandas,csv,CSV,Yes,Fangyu,https://www.kaggle.com/code/asaniczka/how-to-convert-timezones-in-pandas,https://drive.google.com/drive/u/0/folders/1AFkEyWYXSrtqcIddGAgbCEfHHNYjPmfJ,,,,,
,"缺失信息

×
",Kaggle4-1,"Please design a data processing workflow and a machine learning algorithm to train a model based on onlinefoods.csv. Use the trained model to make predictions on test.csv. Finally, write the predicted character labels (""Negative"", ""Positive"") into result.csv, following the provided result.csv template.",,,,,,,,,,,,,,,,
,"涉及Murder的敏感话题

×",pd006,"For sql-murder-mystery.db,Retrieve suspect details using sql.
The crime was a murder that occurred sometime on Jan.15, 2018 and that it took place in SQL City.
complete suspect_data.csv according to the given file format and requirements.",,,,,sql,sqlite,CSV,No,zyt,https://www.kaggle.com/datasets/johnp47/sql-murder-mystery-database/data,https://drive.google.com/drive/u/0/folders/1jbhDSKWvVO9M_EH5vDVCTV3H4y8GjLOx,✅,,,,
,"提到的Apriori 算法可能会导致结果不唯一

×",dm024,"Perform market basket analysis on trading data of Whole_Foods_Transaction_Data.csv By analyzing the transaction data of Whole Foods, explore consumer purchasing behavior and discover possible association rules between products. Using the given Python code, preprocess the data, mine frequent itemsets, and generate association rules, and explain the analysis results. Fill in the analysis results in result.csv.",,,,,pandas analysis,"csv, ipynb",CSV,No,Liang Sirui,https://www.kaggle.com/code/jasonyu001/wholefoods-market-basket-association-rule/notebook#3.-Modeling,https://drive.google.com/drive/folders/127r2NvYm61xJUTmhIXNSD68Sy9AdBC_g,✅,,,,
,"统计功效（statistical power）需要一个阈值，但这个在问题和真值里都没给出

×",zC6-9,Q: Find and output the smallest sample size that achieves or exceeds the desired statistical power. A:0.03468607351645712,,,,,,csv,Single,No,yy,Grouping & aggregating | Python (datacamp.com),https://drive.google.com/drive/folders/1TATad8mxy_I07OC-1C3h-Cma1Evr-1fU?usp=drive_link,,,,,
,"为什么这个的真值会和前面类似问题的真值冲突

×",pd033,"Top 3 developers who submitted the most pull requests, saved as csv",,,,,"csv,py,md",CSV,No,No,zyt,https://projects.datacamp.com/projects/163,https://drive.google.com/drive/folders/1G43xSYyeL9ODi_UFpPosGCi-cYzdRkXG,✅,,,,
,"文件太大

×",KaggleNo.8,"Please complete the code in the analysis.txt file to accurately count the number of bike rides starting in different time periods (morning, afternoon, evening, and early morning). Ultimately, identify which time period has the highest number of bike rides starting and record the corresponding number of rides.",,,,,pandas analysis,"txt, csv",txt,Yes,Jianwen,https://www.kaggle.com/code/jacopoferretti/cyclistic-bike-share-data-analytics,https://drive.google.com/drive/folders/1sMz5NkOWYpNv_TUiMwuDqThEgy_ciEnu?usp=share_link,文件太大,,,,
,"问题有点简单，而且现在不支持对图片的理解

×",KaggleNo.66,Please analyze the chart below and answer which model performs the worst for me,,,,,Chart analysis,csv,Longform,No,Liang Sirui,https://aclanthology.org/2023.acl-long.236/,https://drive.google.com/drive/folders/1bNNYM17lQWTwXoaLs5lFNMbjAOMkF6QY,,,,,
,"应该算统计分析

×",dmz-028,"I need to process the weather data for England. Please discard null values in the data and ensure that the date is 2006 and later (adjust the date earlier than 2006 to ""2006-1-1 00:00:00+00:00""). Discard humidity and pressure values less than or equal to 0. Finally, please divide the date into three columns: year, month, and day, and keep only temperature, wind speed, pressure, and humidity for the remaining columns. Finally, calculate Pearson correlations between the seven columns and save the results in result.csv.",,,,,pandas analysis,csv,CSV,No,Chengfeng,https://www.kaggle.com/code/ateferajabi97/englandweather-preprocessing,https://drive.google.com/drive/folders/1kczwsH1GFR9nk74CX4INqE-8AjWcfVvk?usp=sharing,✅,,,,
,"这是机器学习任务

×",KaggleNo.64,"Please understand the three CSV files and data descriptions provided, and write code to complete the housing price prediction. Store the prediction results in submission.csv (file names are id and SalesPrice)",,,,,pandas analysis,csv,CSV,No,Liang Sirui,https://www.kaggle.com/code/quyenhua/group-18-house-prices/notebook,https://drive.google.com/drive/folders/16Cu-ePBKJrIHnwKj2Nj8QIK63k3JiEFJ,,,,,
,"真值里含有nan

×",zDC4-1,"（已修改，原本含有NaN的两行没有直接意义，直接删除了）Calculate the performance results(in percentage) of backtested trading strategies over different lookback periods using the Google stock historical price data from 2017 to 2020, save the results to lookback_returns.csv.",,,"Strategy 1: strategy with a 30-day lookback period, Strategy 2: strategy with a 50-day lookback period. ",,,csv,CSV,No,yy,Compare return results of multiple strategies | Python (datacamp.com),https://drive.google.com/drive/folders/1AMuHku3QybONiTfPYLZnWBT-rVSrqXTk?usp=drive_link,✅,,,,
,"真值文件的Country列是空着的

×",zDC6-4,"Calculate the total number of purchases made by users in their first week of registration, grouped by different countries and devices, and fill in the parts marked with -1 in the result.csv.",,,,,,csv,CSV,No,yy,Grouping & aggregating | Python (datacamp.com),https://drive.google.com/drive/folders/1JF3j2a-yzXX0SJyE6_3RglQ8TgTes67C?usp=drive_link,,,,,
,"真值文件里面有NaN值

×",zDC6-5,"Calculate the rolling average of the data with a 7, 28, 365 day window, and save them to result.csv.",,,,,,csv,CSV,No,yy,Grouping & aggregating | Python (datacamp.com),https://drive.google.com/drive/folders/1pLzSW35i99iR0TCPg35uo6b79C4seZCC?usp=drive_link,,,,,
,"真值文件呢？？？

×",pd039,let's look at what 1-day retention is overall.he % of users that came back the day after they installed,,,,,"csv,md",CSV,No,No,zyt,https://projects.datacamp.com/projects/184,https://drive.google.com/drive/folders/1D6XXENMaB4Cu8KLwdTNYoLucGLDoecM4,✅,,,,
,"只需要转换下时间？过于简单

×",pd046,"The pull request times are all in UTC (also known as Coordinated Universal Time). The commit times, however, are in the local time of the author with time zone information (number of hours difference from UTC). To make comparisons easy, we should convert all times to UTC.",,,,,"csv,md",CSV,No,No,zyt,https://github.com/Andy-Nkumane/The-GitHub-History-of-the-Scala-Language,https://drive.google.com/drive/folders/18DJ3UZKBFOhY-qUNUZSf-bJBvo0OX0Sm,,,,,
,"最后一行真值有问题

×",zDC8-6,Look at the oldest business in each category of commerce for Africa. Save the result to result.csv.,,,,,,"csv, md",CSV,Yes,yy,https://app.datacamp.com/learn/projects/worlds_oldest_businesses,https://drive.google.com/drive/folders/1qDecWWm9VR5KSF6kA7pf69hMbopzEkxw?usp=drive_link,,,,,
,"check&recheck step 不是必须的，easy 任务

×",sqlite001,Delete all records with missing values in the database,,,,,"sql, pandas",sqlite,sqlite,No,Fangyu,https://www.kaggle.com/code/youssefismail20/sql-e-commerce,https://drive.google.com/drive/u/0/folders/1xKBEmO70v45a5t3lL350TZ7lpFsxNu8R,,,,,
,"data cleaning 不属于manipulation这类

×",dmz-030,"Here are some records of past earthquakes. However, there may be some inconsistencies in the recording format of time. Please clean the data and try to figure out the days with the most earthquakes in history. Save the days and earthquakes in result.csv.",,,,,pandas analysis,csv,CSV,No,Chengfeng,https://www.kaggle.com/code/habibsiddique/exercise-parsing-dates,https://drive.google.com/drive/folders/1MXbyStfBEUkGwqwFwRvPlB4FWL36Enz7?usp=sharing,,,,,
,"google drive链接里面就只有一个文件，没有提供真值？

×",KaggleNo.65,"Please complete a Python method for me, store this CSV as sqlite, and use SQL queries to retrieve the top ten cities with the highest city_development index and save it to result.csv",,,,,sqlite,csv,CSV,No,Liang Sirui,https://www.kaggle.com/code/klmsathishkumar/job-change-prediction-data-cleaning,https://drive.google.com/drive/folders/1rCF4LeuOvW1jhYLMRBz55K2EwulfeI3D,,,,,
,,dc104,Explore the history of Lego and complete the analysis result.,,,,,,csv,CSV,No,Fangyu,https://app.datacamp.com/learn/projects/history-of-lego,,,,,,
,,dc105,Who are the most important characters in the five books?,,,,,,csv,CSV,No,Fangyu,https://projects.datacamp.com/projects/76,,,,,,
,,dc106,"We have seen three different measures to calculate the importance of the characters, get the correlation between PageRank, betweenness centrality and degree centrality for each books using Pearson correlation, we have provided you correlation1.csv",,,,,,csv,CSV,No,Fangyu,https://projects.datacamp.com/projects/76,,,,,,
,,dc107,Get The Average Difference in Daily Returns Stocks vs S&P 500 of Amazon and Facebook.,,,,,,csv,,,,,,,,,,
,,dc109,"Identifiy the likely genders of different names, let's find author genders by searching for each author's name in the data.",,,,,,csv,,,,,,,,,,
,,dc110,"Identifiy the likely genders of different names, let's find author genders by searching for each author's name in the data. Let's find out if there have been changes spans 2008 to 2017. ",,,,,,csv,,,,,,,,,,
,,dc111,Find top10 most common words in these paper titles.,,,,,,csv,,,,,,,,,,
,,dc113,Find the top 3 developers who made the most changes to the file src/compiler/scala/reflect/reify/phases/Calculate.scala. ,,,,,,csv,,,,,,,,,,
,,dc114,"Following the predefined data format, we need to collect information about the top 3 developers who made the most changes to the file src/compiler/scala/reflect/reify/phases/Calculate.scala.
We have already collected information about one developer, please help to complete the information of the other two.",,,,,,csv,,,,,,,,,,
,,dc115,Calculate the average age of lefthanded and righthanded.,,,,,,,,,,,,,,,,
,,dc116,We scrape news headlines for FB and TSLA then apply sentiment analysis to generate investment insight. Please refer to the data analysis format of FB to analyze the data of tsla. Please use SentimentIntensityAnalyzer from nltk,,,,,,,,,,,,,,,,
,,dc117,Recommend products suitable for different skin types by analyzing the ingredients of cosmetics. Perform word segmentation on the ingredients and generate a document-term matrix. Saving the result in 'matrix.pkl'.,,,,,,,,,,,,,,,,
,,dc119,What are the total distance and climb for each type of activity based on the provided dataset? Please note that data cleaning should be performed first,,,,,,,,,,,,,,,,
,,dc121,"Based on the top 10 movies listed above, it appears that certain genres are more popular than others. To investigate which genres are becoming increasingly popular, we will group the movies by genre and then by year to examine the adjusted gross earnings of each genre annually.",,,,,,,,,,,,,,,,
,,dc122,List the common trends of us and world.,,,,,,,,,,,,,,,,
,,dc124,Calculating the Net Promoter Score,,,,,,,,,,,,,,,,
,,dc125,Calculating the Net Promoter Score of each source,,,,,,,,,,,,,,,,
,,dc133,"analyze licensed themes, specifically focusing on the Star Wars theme. Get the percentage of licensed sets that are Star Wars themed and identifies the year when the most Star Wars sets were released",,,,,,,,,,,,,,,,
,,dc134,"Retrieve and sort company names from the `company` table alongside their titles and ranks from the `fortune500` table, using parent company tickers where applicable. Sort the results by rank.",,,,,,,,,,,,,,,,
,,dc135,"List gold medalists in Javelin Throw by gender from 2000, showing the previous year's winning country for each event, sorted by gender and year.",,,,,,,,,,https://campus.datacamp.com/courses/postgresql-summary-stats-and-window-functions/introduction-to-window-functions?ex=10,,,,,,
,,dc136,"List gold medalists for 100M and 10000M Athletics from 2000 onward, including the prior year's winning country for each gender and event, sorted by event, gender, and year.",,,,,,,,,,,,,,,,
,,dc137,"Calculate and list the annual gold medals won by Scandinavian countries, and determine the maximum number of gold medals obtained in two consecutive years, ordered by year.",,,,,,,,,,,,,,,,
♻️,,dm-csv-001,"I want to know the best fighters of every UFC weight class. Tell me in each class, how many fighters have never been defeated.
Please fill in the results into CSV files, undefeated.csv","This is a UFC Fighters’ Statistics 2024 dataset with a description in README.md.  You should filter out the best fighters in each UFC weight class and determine how many fighters in each class have never been defeated. Finally, fill in the results into ‘undefeated.csv’",,,data process,pandas analysis,"csv, md",CSV,Yes,Fangyu,https://www.kaggle.com/code/aaronfriasr/ufc-fighters-statistics-2024/notebook,https://drive.google.com/drive/folders/1OU_cqpOHpBpXk-BuvOz11GFr96Z7a7gC?usp=sharing,✅,,,,
"
♻️",,dm-csv-002,"Tell me how many of these students have been married before and how many have never been married, fill the corresponding answers into the appropriate places in result.csv.","This is a Dropout and Success: Student Data Analysis dataset with a description in README.md. Count the number of students who are “Never Married” and “Previously Married”, and fill the results into result.csv, following the template in sample_result.csv.",,,,pandas analysis,"csv, md",CSV,Yes,yy,https://www.kaggle.com/datasets/marouandaghmoumi/dropout-and-success-student-data-analysis/data,https://drive.google.com/drive/folders/1sp-WM5vMDhbmtz7I3u_Z7-S9CPuc26KE?usp=share_link,✅,🏗️,,,
⭐️,,dm-csv-003,"This is a Dropout and Success: Student Data Analysis dataset with a description in README.md. Determine the top five most common educational qualifications for both mothers and fathers. Analyze the data to find the frequency of each qualification and save the results in a file named top_qualifications.csv. The file should include the qualification names instead of codes and should be sorted in decreasing order of frequency. Ensure the top_qualifications.csv file has the following column names: “Mother’s Qualification”, “Mother’s Frequency”, “Father’s Qualification”, “Father’s Frequency”.","This is a Dropout and Success: Student Data Analysis dataset with a description in README.md. Determine the top five most common educational qualifications for both mothers and fathers. Analyze the data to find the frequency of each qualification and save the results in a file named top_qualifications.csv. The file should include the qualification names instead of codes and should be sorted in decreasing order of frequency. Ensure the top_qualifications.csv file has the following column names: “Mother’s Qualification”, “Mother’s Frequency”, “Father’s Qualification”, “Father’s Frequency”.",,,,pandas analysis,"csv, md",CSV,No,hym,https://www.kaggle.com/datasets/marouandaghmoumi/dropout-and-success-student-data-analysis/data,https://drive.google.com/drive/folders/1pnuwL2YklpB3Ulybz9Iq9NUqjsJCdKPI?usp=share_link,✅,,,,
,,dm-csv-004,"From the ""Olympics 124 years Dataset (till 2020)"", conduct an analysis to determine the total number of Games held for both the Summer and Winter Olympics, and record this information in ""allGames.csv"". Additionally, for each edition of both the Summer and Winter Olympics, identify the host city and the total number of events conducted. Compile this detailed information into ""allEvents.csv"".","This is an Olympics 124 years Dataset (till 2020) with a description in README.md. You should onduct an analysis to determine the total number of Games held for both the Summer and Winter Olympics, and record this information in “allGames.csv” following the template in “sample_allGames.csv”. Additionally, for each edition of both the Summer and Winter Olympics, identify the host city and the total number of events conducted, and compile this detailed information in “allEvents.csv” following the template in “sample_allEvents.csv”.",,,,pandas analysis,csv,CSV,No,Jianwen,https://www.kaggle.com/datasets/nitishsharma01/olympics-124-years-datasettill-2020/code,https://drive.google.com/drive/folders/1YN5lSZInIb75vYQfdEaWKGau-RTCKF_2?usp=share_link,✅,✅,,,
,,dm-csv-005,"Complete the python code to output the number of people in each age group mentioned in the txt file, and save it to 'result.csv'.","This is a Book Recommendation Dataset with a description in README.md. Based on the instructions in age.txt, count the number of people in each age group and record the results in result.csv following the template provided in sample_result.csv.",,,,pandas analysis,"csv, txt",CSV,Yes,yy,https://www.kaggle.com/code/sergiopranteddu/recommendation-system-using-sql-in-pandas/notebook,https://drive.google.com/drive/folders/1XvKXqZNPLXco8efGE33fpMN3zVF9PmZ6?usp=share_link,✅,,,,
,,dm-csv-006,"Find all pairs of products that have been ordered together, count how often each pair appears, and save the most commonly co-purchased pairs to result.csv.","This is a Bike Store Relational Database dataset with a description in README.md. Determine which products are frequently purchased together. Specifically, find the different products that are purchased together in the same order and calculate the number of times they are purchased together. Write the information of the top two pairs with the highest purchase count into result.csv. The column names in result.csv should be “product_a” for the name of the first product, “product_b” for the name of the second product, and “co_purchase_count” for the number of times the two products are purchased together.",,"""The CSV has a header row indicating the names of the columns:
'product_a'
'product_b'
'co_purchase_count': A numeric value representing the count of co-purchases between product_a and product_b.
There are two data rows, each describing a pair of products that have been purchased together.
The second row repeats the same products of first row in reverse order, because of that the relationship between product_a and product_b is bidirectional and the count of co-purchases applies to both directions.
The sorting order of the two rows is such that the one with the smaller product_id of product_a comes first.",,"pandas, insert all csv files into db ",csv,CSV,No,yy,https://www.kaggle.com/code/dillonmyrick/sql-beginner-to-advanced-with-practical-examples,https://drive.google.com/drive/folders/1jwQT4xLOG4uHCjWSvEqbgAwOan7051qC?usp=share_link,✅,,,,
,,dm-csv-007,"Please calculate the top 10 most popular movies, considering only those movies whose number of votes falls within the top 15%. The formula for this calculation is described in ""wrFormula.tex"". Once you have completed the calculations, write the names of the resulting movies line by line into ""result.txt"".","This is a TMDB 5000 Movie Dataset with a description in README.md. According to the guidance in ‘wrFormula.tex’, you should identify the top 10 most popular movies and record their name in result.csv following the template provided in sample_result.csv.",,,,pandas analysis,"md,csv,tex",CSV,Yes,Jianwen,https://www.kaggle.com/code/bhaveshmittal/tmdb-movie-insights-recommendations,https://drive.google.com/drive/folders/1wVs85eVx4KYhN0qa-eLjlNEBSLEoJGQc?usp=share_link,✅,,,,
,,dm-csv-009,"Filter the top 10 best-rated authors, the most expensive authors, and the authors with the most ratings. Save these authors' names in author_list.txt, with each category occupying one line, and adjacent names separated by "", "".","This is an Amazon Books Dataset with a description in README.md. Identify the top 10 Best-Rated Authors, Most Expensive Authors, and Most Rated Authors. Record the results in author.csv following the template provided in sample_result.csv.",,"Remove unnamed columns, and if there are any missing values, fill the missing values with ""Unknown"". The definations of those 3 types are given in README.md.",,pandas,"csv, md",CSV,Yes,yy,https://www.kaggle.com/code/rewidashabaanmohamed/amazon-book-viz,https://drive.google.com/drive/folders/14793kyfMJ5GRbe5djEr0uzvQwXkwr-JM?usp=share_link,✅,,,,
,,dm-csv-010,Calculate the average monthly sales for each product category and save it to result.json.,"This is a Bike Store Relational Database, with related descriptions provided in the README.md file. You need to calculate the annual average sales volume for each bike category and write the results into avg_units_sold.csv following the template of sample_result.csv.",,,,,csv,CSV,No,yy,SQL | Beginner to Advanced with Practical Examples (kaggle.com),https://drive.google.com/drive/folders/1V339AXpqR-f1DZK9wJNd0CN_svQf-I7o?usp=sharing,✅,,,,
,,dm-csv-011,"I want to determine what the most popular model, brand and category of bike was from 2016-2018 as well as determining what product is the highest grossing for the company. Save the results to the result.csv file, ordered by total sales in descending order.","This is a Bike Store Relational Database, with relevant descriptions provided in the README.md file. You need to calculate and aggregate the total quantity sold and total sales revenue for each bike type from 2016 to 2018. Finally, write the results into result.csv following the template of sample_result.csv.",,,,,csv,CSV,No,yy,Bike Rental SQL (In Progress) (kaggle.com),https://drive.google.com/drive/folders/1tO4GVH2DYJJwF2-HmSf3zTEzOUopthwH?usp=sharing,✅,,,,
,,dm-csv-012,"Tell me 100 most valuable costumers, save the results to result.csv.","This is a Bike Store Relational Database, with relevant descriptions provided in the README.md file. You need to assist in selecting the names of the top five users ranked by total expenditure along with their corresponding total expenditure, and then write the results into result.csv following the template of sample_result.csv.",,"name' consists both first name and last name. he customer who has spent the most will appear at the top of the list, and the amounts decrease as you move down the list.",,,csv,CSV,No,yy,SQL Data Analysis (kaggle.com),https://drive.google.com/drive/folders/1cAh_ZTFINYS6PoEnV6VHfo3_cCS4QAnZ?usp=share_link,✅,,,,
,,dm-csv-013,"Identify the club with the best average physicality among the top 20 clubs with the highest average scores in FIFA 20. Additionally, determine the club's top scorer. Record the name of the club and the full name of the player in result.xlsx.","This is a FIFA 20 complete player dataset, with relevant descriptions provided in the README.md file. You need to identify the club with the best average physicality among the top 20 clubs with the highest average scores in FIFA 20. Additionally, according to the description in BMI.txt, you are required to determine the top scorer of the selected club. Record the name of the club and the full name of the player following the template of sample_result.csv.",,,,pandas analysis,"txt, csv, xlsx",xlsx,Yes,Jianwen,https://www.kaggle.com/code/eishkaran/fifa-2020-eda,https://drive.google.com/drive/folders/1WaS17AYMtntVQPjmg7uEboQJTQLMt8sz?usp=share_link,✅,,,,
,,dm-csv-014,"The Wilson score lower bound formula offers a precise way to evaluate reviews by balancing positive ratings and the uncertainty of a small number of reviews, ensuring a fair ranking. Your task is to calculate each review's score using this formula, then extract and write the summaries of the top 3 reviews into a file named result.txt.","This is the Amazon Musical Instruments Reviews dataset, with relevant descriptions provided in the README.md file. You need to calculate each review’s score using the formula designed in Wilson.tex, then extract summaries of the top 3 reviews. Finally, write the results into result.csv following the template of sample_result.csv.",,,,jsonlines,"jsonl, tex",CSV,Yes,Jianwen,https://www.kaggle.com/code/zhreturgay/rating-musical-instruments-sorting-reviews,https://drive.google.com/drive/folders/1ffMCL3EzHaFgQhXKSQX_n4uEZDWQiExV?usp=share_link,✅,,,,
,,dm-csv-015,"This is a dataset of baseball games. I need you to help me calculate the player with the most games played, the player with the most runs scored, the player with the most hits, and the player with the most home runs. Each statistical data should include the player's name and their corresponding data, for example, for the player with the most games played, record their number of games played, and for the player with the most runs scored, record their runs scored. Write the data you collect into the result.csv file. Please note that the template for result.csv has been provided, please write according to the template.","This is a dataset of baseball games, with relevant descriptions provided in the README.md file. You need to help me calculate the player with the most games played, the player with the most runs scored, the player with the most hits, and the player with the most home runs. Each statistical data should include the player’s name and their corresponding data; for example, for the player with the most games played, record their number of games played, and for the player with the most runs scored, record their runs scored. Finally, write the results into result.csv following the template of sample_result.csv.",,,,sql & pandas,"csv, txt, sqlite",CSV,No,Jianwen,https://www.kaggle.com/code/arvinthsss/history-of-baseball-dive-deep-using-sql,https://drive.google.com/drive/folders/1yAz4jIJ4nuBf8qKEvzPYHrzja9RBMdek?usp=share_link,✅,,,,
,,dm-csv-016,"This is a dataset for football matches, and I would like you to help me calculate the seasons hosted by IT1 and BESC as well as the winning clubs. Please write your calculated results into the result.csv file, the template has been provided.","This is a dataset for football matches, with relevant descriptions provided in the README.md file. I would like you to help me compile statistics for the seasons and the corresponding winning clubs hosted by IT1 and BESC. Finally, write the results into result.csv following the template of sample_result.csv.",,,,pandas,"csv,md",CSV,No,Jianwen,https://www.kaggle.com/code/luisgasparcordeiro/football-champions-by-season,https://drive.google.com/drive/folders/1Nfx9mAWRZzmY6e3GPrIb2oAo2JSXfsIs?usp=share_link,✅,,,,
,,dm-csv-018,Show the top10 universities offer the most affordable data science programs?,"This is a Data Science Programs list dataset, with relevant descriptions provided in the README.md file. You need to identify the top 10 universities offering the most affordable data science programs and record their tuition fees. Finally, write the results into result.csv following the template of sample_result.csv.",,,,pandas,"csv, py",CSV,No,Fangyu,https://www.kaggle.com/code/msahmed/data-science-program-eda-analysis,https://drive.google.com/drive/folders/196KJ6-Xt_zpAyvYUjTuB-j7wzYQrDSka?usp=share_link,✅,,,,
,,dm-csv-019,Get the number of draws for each team in La Liga. Note that missing values default to draws.,"This is a La Liga Complete Dataset, with relevant descriptions provided in the README.md file. You need to calculate the top 20 teams by average score and their corresponding number of draws. Finally, write the results into result.csv following the template of sample_result.csv.",,,,pandas,csv,CSV,No,Fangyu,https://www.kaggle.com/code/kishan305/la-liga-eda-and-visualization/notebook,https://drive.google.com/drive/folders/1FBBwFmmHPwIq5CaEasj2ngfjEnIXknEI?usp=share_link,✅,,,,
,,dm-csv-020,Top 10 cities with the highest telecom customer churn rate,"This is a Telco customer churn dataset, with relevant descriptions provided in the README.md file. You need to identify the top 10 cities with the highest telecom customer churn rate and write the results into result.csv following the template of sample_result.csv.",,将Churn Category和Churn Reason中的缺失值填充为“not churned”，表示这些客户没有流失；将Offer和Internet Type中的缺失值填充为'None',,pandas,csv,CSV,No,Fangyu,https://www.kaggle.com/code/alfathterry/telco-customer-churn-analysis/notebook,https://drive.google.com/drive/folders/18pL4CXpmnngXz8GYbjog9c1Pkj1kaSRD?usp=share_link,✅,,,,
,,dm-csv-021,"Please analyze the top three items most purchased by families with different numbers of children, and fill them into the result.csv file.","This is a Marketing Campaigns Dataset, with relevant descriptions provided in the README.md file. You need to identify the top 3 most popular product categories among families with 0, 1, and 2 children, and write the results into result.csv following the template of sample_result.csv.",,,EDA,,CSV,CSV,Yes,yy,https://www.kaggle.com/datasets/sahilnbajaj/marketing-campaigns-data-set/data,https://drive.google.com/drive/folders/18pL4CXpmnngXz8GYbjog9c1Pkj1kaSRD?usp=share_link,✅,,,,
,,dm-csv-022,"Assuming it is now the year 2024, please fill in the given result.csv.","This is a Marketing Campaigns Dataset, with relevant descriptions provided in the README.md file. Assuming the current year is 2024, you need to calculate the Mean Campaign Acceptance Rate by Age for each country according to the year ranges specified in result.csv, and fill in the results in result.csv.",,The defination of age_country_response_mean: the average acceptance rate of the last marketing campaign for different age groups within each country. Acceptance rate is the proportion of customers who accepted the offer in the last campaign.,EDA,,CSV,CSV,Yes,yy,https://www.kaggle.com/datasets/sahilnbajaj/marketing-campaigns-data-set/data,https://drive.google.com/drive/folders/1p8b_Tyx_J9g7wpyhn-LlrKSl-pgkk4m6?usp=drive_link,✅,,,,
,,dm-csv-023,"Analyze at which campaign number, on average, individuals of each education level accept the offer, and fill in the results in the average_campaign_accepted_by_education.csv file.","This is a Marketing Campaigns Data Set, with relevant descriptions provided in the README.md file. You need to calculate the average number of campaigns it takes for customers with each education level to accept an offer, and write the results into result.csv following the template of sample_result.csv.",,,EDA,,CSV,CSV,Yes,yy,https://www.kaggle.com/datasets/sahilnbajaj/marketing-campaigns-data-set/data,https://drive.google.com/drive/folders/1BlxnCEL8hNS5s5TwapGsf_FsF-8i0ca_?usp=share_link,✅,,,,
,,dm-csv-024,"Count the total number of online purchases and the total number of direct store purchases for each income bracket, and input the data into a file named purchase_by_income.csv.","This is a Marketing Campaigns Data Set, with relevant descriptions provided in the README.md file. You need to calculate the total number of online purchases and in-store purchases for different income groups, and fill in the results in purchase_by_income.csv. The template for purchase_by_income.csv has been provided.",,Income values for a few customers are missing. Perform missing value imputation. The impulation rule is given in README.md,EDA,,CSV,CSV,Yes,yy,https://www.kaggle.com/datasets/sahilnbajaj/marketing-campaigns-data-set/data,https://drive.google.com/drive/folders/1GDZHUgkCjeXax63vd-fRo6kfo8gUWIri?usp=share_link,✅,,,,
,,dm-csv-025,"Continue developing the existing code in analys.txt to calculate the winning and losing probabilities for each team. Sort these probabilities from highest to lowest for all teams, and save the sorted winning probabilities in win.npy and the sorted losing probabilities in lose.npy.","This is a IPL Complete Dataset (2008-2024), with relevant descriptions provided in the README.md file. Your task is to continue the development of the existing code in analys.py to calculate the winning and losing probabilities for each team. Afterwards, you need to identify the team with the highest probability of winning and the team with the highest probability of losing. Finally, write their names and corresponding (winning or losing) probabilities into team_probabilities.csv following the template provided in sample_result.csv.",,,,numpy & pandas,"txt, csv",npy,No,JIanwen,https://www.kaggle.com/code/chitwanmanchanda/statistics-is-all-you-need-2,https://drive.google.com/drive/folders/1_ZmzR5S8YNzsl9HhK1YX06y91zoX-xLR?usp=share_link,,,,,
,,dm-csv-026,"Understand the dataset and complete analysis.py to accomplish the task of ""ranking the players based on the above score at position level."" Relevant hints can be found in some txt and md files.","This is a dataset containing information on FIFA 22 players, with detailed descriptions provided in the README.md file. Your task is to complete the analysis.py script to rank the players based on the specified score at the position level. You can find relevant hints in some text (txt) and Markdown (md) files. Ensure that the results are written to the result.csv file in the format demonstrated in sample_result.csv.",,,,pandas & sql,"csv, md, txt, py",CSV,Yes,Jianwen,https://www.kaggle.com/code/mayuriawati/fifa-22-analysis-using-sql-and-python#Ranking-the-Player-with-respect-to-there-postion-full-form-based-on-the-following-matrics,https://drive.google.com/drive/folders/1MNmqFKeUQR7hpgVxc7pPJOcymQa35K9p?usp=share_link,,,,,
,,dm-csv-027,"For netflix1.csv, complete data analysis according to the given file format and requirements.","This is a Netflix Data dataset, with detailed descriptions provided in the README.md file. Your task is to identify the top 10 countries by the number of produced shows and their corresponding counts, as well as the top 10 movie genres by the number of occurrences and their corresponding counts. Record the results in the provided templates: Top_10_countries.csv and Top_10_Movies.csv.",,,,pandas,csv,CSV,No,zyt,https://www.kaggle.com/datasets/ariyoomotade/netflix-data-cleaning-analysis-and-visualization/data,https://drive.google.com/drive/folders/1bzqJXG2xjnXjbzZdW8UYyH7MYVF0ZHsw?usp=share_link,✅,,,,
,,dm-csv-028,"For data.csv, Calculate the total profit and save it in a CSV file，complete data analysis according to the given file format and requirements.","This is a Sales Data dataset, with detailed descriptions provided in the README.md file. Your task is to calculate the total profit for each state, sort the results in descending order, and write them into the state_profit.csv file using the provided template.",,, hypothesis test,pandas,csv,CSV,No,zyt,https://www.kaggle.com/code/sasakitetsuya/why-is-german-bike-market-so-profitable/notebook,https://drive.google.com/drive/u/0/folders/1FVNk4S8BxmjlJWER84a8rCsQP4ZUZj3z,✅,,,,
,,dm-csv-029,Count the number of pull requests submitted by each user and save them as csv,"This is a dataset titled “The-GitHub-History-of-the-Scala-Language,” with detailed descriptions provided in the README.md file. Your task is to identify the top 3 users with the most pull requests and record their usernames and the number of pull requests in the top3_pull_requests.csv file using the provided template.",,,,"csv,py,md",CSV,No,No,zyt,https://projects.datacamp.com/projects/163,https://drive.google.com/drive/folders/1ibfAui8NvdVlZTQGW5MQab57BKPQeAH_?usp=share_link,✅,,,,
,,dm-csv-030,"This code works by identifying the latest 10 pull requests, merging the related file data, finding the unique files involved in these pull requests, and saving them to a csv.","This is a dataset titled “The-GitHub-History-of-the-Scala-Language,” with detailed descriptions provided in the README.md file. Your task is to identify the latest 10 pull requests, merge the related file data, and find the unique files involved in these pull requests. Record the results in the unique_files.csv file using the sample_result.csv template.",,,,"csv,py,md",CSV,No,No,zyt,https://projects.datacamp.com/projects/163,https://drive.google.com/drive/folders/1Wyg0lPtEKqh3F_sZOnR7wNZFb2iW7yt8?usp=share_link,✅,,,,
,,dm-csv-031,Identify the users who made the last ten pull requests for a specific file src/compiler/scala/reflect/reify/phases/Calculate.scala . Save to csv,"This is a dataset titled “The-GitHub-History-of-the-Scala-Language,” with detailed descriptions provided in the README.md file. Your task is to identify the users who made the last 6 pull requests for the specific file ""src/compiler/scala/reflect/reify/phases/Calculate.scala"". Record the results in the users_last_6.csv file using the provided template.",,,,"csv,py,md",CSV,No,No,zyt,https://projects.datacamp.com/projects/163,https://drive.google.com/drive/folders/1evC6AsX-2sevVmpbE5nlpqrfO1LZgmUJ,✅,,,,
,,dm-csv-032,let's look at how 1-day retention differs between the two AB-groups.,"This is a dataset titled “Mobile-Games-Testing-with-Cookie-Cats,” with detailed descriptions provided in the README.md file. Your task is to calculate the proportion of 1-day retention being True for the gate_30 and gate_40 versions, respectively. Record the results in the retention_by_version.csv file using the provided template.",,,,"csv,md",CSV,No,No,zyt,https://projects.datacamp.com/projects/184,https://drive.google.com/drive/folders/1y7Z4-O-2b5O4j3a20CnORFZ3dOcn9cq-?usp=share_link,✅,,,,
,,dm-csv-033, what is the probability that the difference is above 0%? Let's calculate that as well.,"This is a dataset titled “Mobile-Games-Testing-with-Cookie-Cats,” with detailed descriptions provided in the README.md file. Your task is to compare the 1-day retention rates between two versions of a game (gate_30 and gate_40) according to the instructions in guidance.txt. Calculate the probability that the retention rate is higher for gate_30 and record the result in the probability_greater_retention.csv file using the provided template.
",,,,"csv,md",CSV,No,No,zyt,https://projects.datacamp.com/projects/184,https://drive.google.com/drive/folders/13jdtj7v3Ie4Hj9aasZiNjQUc46PE9eH3?usp=sharing,✅,,,,
,,dm-csv-034,Let's start by calculating 7-day retention for the two AB-groups.,"This is a dataset titled “Mobile-Games-Testing-with-Cookie-Cats,” with detailed descriptions provided in the README.md file. Your task is to calculate the proportion of 7-day retention being True for the gate_30 and gate_40 versions, respectively. Record the results in the retention_7_by_version.csv file using the provided template.",,,,"csv,md",CSV,No,No,zyt,https://projects.datacamp.com/projects/184,https://drive.google.com/drive/folders/19EUef4q8aewkLlRDndOMM55OPCCBsFmo?usp=share_link,✅,,,,
,,dm-csv-035,convert all times to UTC.The data extracted comes in two separate files. Merging the two DataFrames will make it easier for us to analyze the data in the future tasks.,"This dataset is titled “The-GitHub-History-of-the-Scala-Language,” with detailed descriptions provided in the README.md file. Your task is to convert all time columns to Coordinated Universal Time (UTC) and record each user’s pulled files based on their pid. If a user pulled multiple files within one pid, you need to record these files separately. Write the results in the output.csv file using the format provided in sample_output.csv.",,,,"csv,md",CSV,No,No,zyt,https://github.com/Andy-Nkumane/The-GitHub-History-of-the-Scala-Language,https://drive.google.com/drive/folders/17qStaA8VTAsCf50HWVlZT4x-e7nw2haB?usp=share_link,,,,,
,,dm-csv-036,Who made the last ten pull requests on a given file?look at the history of  <code>src/compiler/scala/reflect/reify/phases/Calculate.scala.,"This is a dataset titled “The-GitHub-History-of-the-Scala-Language,” with detailed descriptions provided in the README.md file. Your task is to identify the last six users who made pull requests for `src/compiler/scala/reflect/reify/phases/Calculate.scala`. and fill in their usernames in the template file users_last_6.csv.",,,,"csv,md",CSV,No,No,zyt,https://github.com/Andy-Nkumane/The-GitHub-History-of-the-Scala-Language,https://drive.google.com/drive/folders/1o7QlFnyB-_RcHE9Kp7Jfa3VPu1Yf72-S?usp=share_link,,,,,
,,dm-csv-037,Who made the most pull requests to a given file?as being recently changed. We are interested in the top 3 developers who changed that file. look at the history of  <code>src/compiler/scala/reflect/reify/phases/Calculate.scala,"This is a dataset titled “The-GitHub-History-of-the-Scala-Language,” with detailed descriptions provided in the README.md file. Your task is to identify the top three users who made the most pull requests for `src/compiler/scala/reflect/reify/phases/Calculate.scala` and fill in their usernames in the template file top_3_developers.csv.",,,,"csv,md",CSV,No,No,zyt,https://github.com/Andy-Nkumane/The-GitHub-History-of-the-Scala-Language,https://drive.google.com/drive/folders/1G-zP7Vu07sIpX4mw598XqS2v8muQXRtf?usp=share_link,,,,,
,,dm-csv-038,"he pull requests of two special developers
<p>Now that we have identified two potential contacts in the projects, we need to find the person who was most involved in the project in recent times. That person is most likely to answer our questions. For each calendar year, we are interested in understanding the number of pull requests the authors submitted. ","This is a dataset titled “The-GitHub-History-of-the-Scala-Language,” with detailed descriptions provided in the README.md file. I want to know the number of pull requests made by two users with the nicknames “soc” and “xeno-by” for each year between 2011 and 2016. Please fill in your statistical results in the provided template file pull_requests_by_year_and_author.csv.",,,,"csv,md",CSV,No,No,zyt,https://github.com/Andy-Nkumane/The-GitHub-History-of-the-Scala-Language,https://drive.google.com/drive/folders/1X9N6aLhTfXbic4dgXAt0e8G2x8TaTHir?usp=share_link,,,,,
,,dm-csv-039,"conduct a supply chain analysis of three of these ingredients used in an avocado toast, utilizing the Open Food Facts database.be armed with a list of ingredients and their countries of origin","This is an Avocado Toast dataset, with detailed descriptions provided in the README.md file. You need to conduct a supply chain analysis of three ingredients used in an avocado toast, utilizing the Open Food Facts database. Identify the list of ingredients and their countries of origin, and record the results in the ingredient_origins.csv file using the provided template.",,,,"csv,md",CSV,No,No,zyt,https://app.datacamp.com/learn/projects/1685,https://drive.google.com/drive/folders/16Hk8i_1SqBwYWI3sp-hp4rMAgyynqsjk?usp=share_link,,,,,
,,dm-csv-040,"Divide the salary scale into four level according to the salary of all employees. Among the company size with the largest number of top level employees, find the designation of the top10 paid employees and their salaries. Save the result in result.csv.","This is a dataset titled “Categorizing salaries,” with detailed descriptions provided in the README.md file. You need to divide the salary scale into four levels according to the salaries of all employees. For the company size with the largest number of top-level employees, find the designations of the top 10 paid employees and their salaries. Write the results in the result.csv file using the format provided in sample_result.csv.",,,,pandas analysis,csv,CSV,No,chengfeng,https://campus.datacamp.com/courses/exploratory-data-analysis-in-python/turning-exploratory-analysis-into-action?ex=7,https://drive.google.com/drive/folders/1VVAuXJEKeeM2MuLAa7Yh68y0JZSjXbhR?usp=sharing,✅,,,,
,,dm-csv-041,"When a driver is pulled over for speeding, many people believe that gender has an impact on whether the driver will receive a ticket or a warning. Can you find evidence of this in the dataset? Count the stop outcomes for the female and male drivers and express them as proportions, save the results to stop_outcomes_by_gender.csv.","This is a dataset titled “Police Activity,” with detailed descriptions provided in the README.md file. You need to count the stop outcomes for female and male drivers when they are pulled over for speeding, and express them as proportions. Save the results to the stop_outcomes_by_gender.csv file using the provided template.",,Drop all rows that are missing driver_gender.,,,CSV,CSV,No,yy,https://campus.datacamp.com/courses/analyzing-police-activity-with-pandas/analyzing-the-effect-of-weather-on-policing?ex=1,https://drive.google.com/drive/folders/1tO4GVH2DYJJwF2-HmSf3zTEzOUopthwH?usp=share_link,✅,,,,
,,dm-csv-042,"Calculate the total days difference between the Invoice and Cohort dates, and save as `CohortIndex` to result.csv.",This task involves working with a user Segmation dataset. Detailed descriptions are provided in the README.md file. Your objective is to calculate the total number of days between the Invoice date and the Cohort date for each entry in the dataset. Save this calculated difference as CohortIndex in the result.csv file.,,"Assume 365 days in a year, and 30 days in a month, you can calculate the difference in years, months and days, then multipy the differences, and don't forget to plus one in the end.",,,csv,CSV,No,yy,https://app.datacamp.com/learn/courses/customer-segmentation-in-python,https://drive.google.com/drive/folders/1qrL2U5vJWbYCNVeAGMiIcXutZULmQnBU?usp=share_link,✅,,,,
,,dm-csv-043,"Calculate the retention data of each cohort, and save the results to retension.csv.","You are provided with a Customer Segmation dataset, and detailed descriptions can be found in the README.md file. Your task is to calculate the retention data for each cohort according to the instructions provided in the tips.txt file. Save the calculated results to a file named retention.csv.",,,,,"csv, md",CSV,Yes,yy,https://app.datacamp.com/learn/courses/customer-segmentation-in-python,https://drive.google.com/drive/folders/1izUKLoSM66ofPI6CV_l4_gzhM3uIZI5N?usp=share_link,✅,,,,
,,dm-csv-044,"Calculate the average unit price paid for items by groups of customers over time, where each group is based on the month of their first purchase.","This is a Customer Segmation dataset, and detailed descriptions are provided in the README.md file. Your task is to calculate the average unit price paid for items by groups of customers over time. Each group should be determined by the month of their first purchase. Save the calculated results in a file named average_price.csv, utilizing the provided template file.",,,,,"csv, md",CSV,Yes,yy,https://app.datacamp.com/learn/courses/customer-segmentation-in-python,https://drive.google.com/drive/folders/1mgjfhA3CF-Ksq7U2WHLCXspVV-RJNWvP?usp=share_link,✅,,,,
,,dm-csv-045,"Compute the Recency, Frequency, and Monetary (RFM) values for each customer in the recent 12 months, save the results to datamart.csv.","This is a customer Segmentation dataset, with detailed descriptions available in the README.md file. Following the instructions in tips.txt, you need to use the RFM method to calculate values for each CustomerID in the datasmart.csv for the recent 12 months. Save the results in datasmart.csv.",,,,,"csv, md",CSV,Yes,yy,https://app.datacamp.com/learn/courses/customer-segmentation-in-python,https://drive.google.com/drive/folders/1rkI23NdN7xI8LPrKfxQkAiIY0EhQIFJA?usp=share_link,✅,,,,
,,dm-csv-046,"
Calculate annualized volatility and annualized variance of Microsoft trading data, and save the results to result.txt.","This is a Portfolio Risk Management dataset, with detailed descriptions available in the README.md file. Your task is to calculate the annualized volatility and annualized variance of Microsoft trading data. Fill in the calculated results in result.csv according to the template provided in sample_result.csv.",,Assume that there are 252 trading days in a calendar year.,,,csv,CSV,No,yy,Statistical tests for normality | Python (datacamp.com),https://drive.google.com/drive/folders/1dyc8eZCeu6zKmv0UPn1pIdPZ66KUll-6?usp=share_link,✅,,,,
,,dm-csv-047,Q:Calculate historical beta of FamaFrenchData using CAPM. A:0.0.973775516574546,"This is a Portfolio Risk Management dataset, with detailed descriptions provided in the README.md file. Your task involves calculating the historical beta of FamaFrenchData using the Capital Asset Pricing Model (CAPM). Write the calculated results into result.csv, with the column named “result”.",,,,,"csv, md",CSV,Yes,yy,Statistical tests for normality | Python (datacamp.com),https://drive.google.com/drive/folders/1NwxdeEnmJkl6G0Mx9luiN4eLyKsuholH?usp=share_link,✅,,,,
,,dm-csv-048,"Calculate drawdown of USO, an ETF that tracks oil prices, and save the results to result.csv.","This is a Portfolio Risk Management dataset, and detailed descriptions are available in the README.md file. Your task is to calculate the drawdown of USO, an ETF that tracks oil prices. Fill in the results into result.csv, as provided in the corresponding file.",,,,,"csv, md",CSV,Yes,yy,Statistical tests for normality | Python (datacamp.com),https://drive.google.com/drive/folders/1DrVlEaMwsnu482InXkR_-IjmAwb8BRmH?usp=share_link,✅,,,,
,,dm-csv-050,"Using 2017 stock return datasets for 9 biggest companies, calculate the cumulative returns of three different portfolio strategies(default portfolio, equal-weight portfolio, and market value-weighted portfolio), and save the results in result.csv.","This is a Portfolio Risk Management dataset, with detailed descriptions available in the README.md file. Using the 2017 stock return datasets for the 9 biggest companies, you need to calculate the cumulative returns of three different portfolio strategies: the default portfolio, the equal-weight portfolio, and the market value-weighted portfolio. Write the results into result.csv according to the template provided in sample_result.csv.",,,,,"csv, md",CSV,Yes,yy,Statistical tests for normality | Python (datacamp.com),https://drive.google.com/drive/folders/1DQdtNaN-K38D6s5WMpqkGUUW1n9mdkTX?usp=share_link,✅,,,,
,,dm-csv-051,"Q: Calculate portfolio volatility of default portfolio, answer in percentage. A: 8.931417642713793%","This is a Portfolio Risk Management dataset, with detailed descriptions provided in the README.md file. Following the instructions in tips.md, you need to calculate the portfolio volatility of the default portfolio and provide the answer in percentage. Write the result into output.csv, with the column named “result”.",,,,,"csv, md",CSV,Yes,yy,Statistical tests for normality | Python (datacamp.com),https://drive.google.com/drive/folders/1wajE6rnIL5gxdtPzPg1DU2qLcSdr2RdV?usp=share_link,✅,,,,
,,dm-csv-052,"Using the datamart dataset calculated in DC3-2_0, calculate RFM_Score for each customer, build segmentation and then assign it to each customer, save the result to result.csv.","This is a customer segmentation dataset, with detailed descriptions available in the README.md file. Following the instructions in tips.md, use a 1-4 scale to calculate the RFM Score and complete the segmentation of users. Write the results into result.csv according to the format provided in sample_result.csv.",,,,,"csv, md",CSV,Yes,yy,https://app.datacamp.com/learn/courses/customer-segmentation-in-python,https://drive.google.com/drive/folders/1fLUJMT9WE5_NbHjnlMG_gvgejo8TrhlL?usp=share_link,✅,,,,
,,dm-csv-053,"Using the datamart dataset calculated in DC3-2_0, calculate RFM_Score for each customer, save the results to RFM_Score.csv.","This is a customer segmentation dataset, with detailed descriptions available in the README.md file. Following the instructions in tips.md, use a 1-3 scale to calculate the RFM Score. For each CustomerID in RFM_Score.csv, calculate the corresponding user’s RFM score and fill in the results in RFM_Score.csv.",,,,,"csv, md",CSV,Yes,yy,https://app.datacamp.com/learn/courses/customer-segmentation-in-python,https://drive.google.com/drive/folders/1FXrR01v8UUqjqSO28ukK6UUkIFDe8Jm-?usp=share_link,✅,,,,
,,dm-csv-054,"Calculate the Sharpe Ratio for each asset, find the minimum and maximum value of Sharpe ratios, save them to result.txt.","This is a Portfolio Risk Management dataset, with detailed descriptions available in the README.md file. Following the instructions in tips.md, calculate the Sharpe Ratio for each asset, and find the minimum and maximum values of the Sharpe ratios. Write the results into result.csv according to the format provided in sample_result.csv.",,,,,"csv, md",CSV,Yes,yy,Statistical tests for normality | Python (datacamp.com),https://drive.google.com/drive/folders/1uChU1XaP_wqGWPCIYtUF2eUO4y7UMAmc?usp=share_link,✅,,,,
,,dm-csv-055,"Calculate the cumulative returns of the portfolio (""Portfolio"") and the excess returns over the risk-free rate (""Portfolio_Excess"") of FamaFrenchData over time, and save the results to result.csv.","This is a Portfolio Risk Management dataset, with detailed descriptions available in the README.md file. Your task is to calculate the cumulative returns of the portfolio (“Portfolio”) and the excess returns over the risk-free rate (“Portfolio_Excess”) of FamaFrenchData over time. After calculating, ensure to fill in your results into result.csv. Please note that the Date column data in result.csv has already been provided.",,The portfolio return minus the risk-free rate of return is known as the Excess Portfolio Return. The portfolio you will be working with is the equal-weighted portfolio.,,,csv,CSV,No,yy,Statistical tests for normality | Python (datacamp.com),https://drive.google.com/drive/folders/1LnrifRqeAvrKIaTQR8HTCN6xuGNImKjz?usp=share_link,✅,,,,
,,dm-csv-056,Q:Calculate historical beta of FamaFrenchData using the given figma in README.md. A:0.9737755165745455,"This is a Portfolio Risk Management dataset, with detailed descriptions available in the README.md file. Following the instructions in tips.md, calculate the historical beta of FamaFrenchData. Write the results into result.csv according to the format provided in sample_result.csv.",,The portfolio you will be working with is the equal-weighted portfolio.,,,"csv, md",CSV,Yes,yy,Statistical tests for normality | Python (datacamp.com),https://drive.google.com/drive/folders/1liDYNKkhlboeM-b4opXRQJfxd842I2Lu?usp=drive_link,✅,,,,
,,dm-csv-057,"Calculate a set of summary statistics about the purchase data broken out by 'device' (Android or iOS) and 'gender' (Male or Female), and fill the corresponding blanks in purchase_summary.csv.","This is a Customer Analytics dataset, with detailed descriptions available in the README.md file. Your task is to calculate a set of summary statistics about the purchase data, broken out by ‘device’ (Android or iOS) and ‘gender’ (Male or Female). Fill the corresponding blanks in purchase_summary.csv with these summary statistics.",,,,,csv,CSV,No,yy,Grouping & aggregating | Python (datacamp.com),https://drive.google.com/drive/folders/1jsG1ULrKBLm_CCSpnfAOszZmLJ-yY9-X?usp=share_link,✅,,,,
,,dm-csv-058,"Q: Calculate and print the confidence interval for the difference in conversion rates (lift) between a test group and a control group(In format '(,)'). A:(0.011039999822042502, 0.011040000177957487)","This is a Customer Analytics dataset, with detailed descriptions available in the README.md file. Your task is to calculate and print the confidence interval for the difference in conversion rates (lift) between a test group and a control group. Write the results into result.csv according to the format provided in sample_result.csv.",,,,,csv,CSV,No,yy,Grouping & aggregating | Python (datacamp.com),https://drive.google.com/drive/folders/1waeq3xZJljGcT0rCM31bPf9bpKZ5b1MM?usp=share_link,✅,,,,
,,dm-csv-059,"Analyze the purchasing behavior of users within the first week of their registration date, calculate the average number of purchases made in the first week on a daily basis, and save the results in result.csv.","This is a Customer Analytics dataset, with detailed descriptions available in the README.md file. Based on the registration dates in result.csv, you need to analyze the purchasing behavior of users within the first week of their registration date. Calculate the average number of purchases made in the first week on a daily basis, and then fill the results into result.csv.",,,,,csv,CSV,No,yy,Grouping & aggregating | Python (datacamp.com),https://drive.google.com/drive/folders/1t1cWSI9zD7hKexuPQtIBxd2fNsXYAQlb?usp=share_link,✅,,,,
,,dm-csv-060,"The dataset is a sample of 0.1% of our overall population for ease of use, calculates the average daily purchases and paywall views of all population, and save the result to result.txt, the first row is the number of average daily purchases, and the third row is paywall views. ","This is a Customer Analytics dataset, with detailed descriptions available in the README.md file. The dataset is a sample of 0.1% of our overall population for ease of use. Your task is to calculate the average daily purchases and paywall views for the entire population. Write the results into result.csv according to the format provided in sample_result.csv.",,,,,csv,CSV,No,yy,Grouping & aggregating | Python (datacamp.com),https://drive.google.com/drive/folders/1xUuZ27EPlYFTIxpY4T3IUANcuflqx-4m?usp=share_link,✅,,,,
,,dm-csv-061,"Calculate the dates of the earliest and most recent reviews, numbers of private rooms and average listing price, save the result to result.csv.","This is an Airbnb Market Trends dataset, with detailed descriptions available in the README.md file. Your task is to calculate the dates of the earliest and most recent reviews, the numbers of private rooms, and the average listing price. Fill in the results into result.csv according to the template provided in result.csv.",,,,,"csv, tsv, xlsx",CSV,No,yy,https://app.datacamp.com/learn/projects/exploring-airbnb-market-trends,https://drive.google.com/drive/folders/16BgZCLUksJ1Kg1hV9tOfOr8sRMHevom7?usp=share_link,✅,,,,
,,dm-csv-063,"Find the oldest business on each continent, and save the result to result.csv.","This is a World’s Oldest Businesses dataset, with detailed descriptions available in the README.md file. Your task is to find the oldest business on each continent and fill in the relevant information into result.csv according to the fomat specified in result.csv.",,,,,"csv, md",CSV,Yes,yy,https://app.datacamp.com/learn/projects/worlds_oldest_businesses,https://drive.google.com/drive/folders/1u84GU0Cxb7znHRIGY7_Q2ShT2BUSLiNC?usp=share_link,✅,,,,
,,dm-csv-064,Which restaurants in our dataset have been around since before the year 1800? Save the result to result.csv.,"This is a World’s Oldest Businesses dataset, with detailed descriptions available in the README.md file. Your task is to identify the restaurants in our dataset that have been around since before the year 1800. Then, fill in their relevant information into result.csv according to the format specified in result.csv.",,"Those cafe shops, restaurants, and bars can be regard as restaurants.",,,"csv, md",CSV,Yes,yy,https://app.datacamp.com/learn/projects/worlds_oldest_businesses,https://drive.google.com/drive/folders/1yVJ8DAhrJXrAgDgNO1LEh_IR8VAkKooh?usp=sharing,✅,,,,
,,pd059,,,,,,"csv,md",CSV,No,No,zyt,https://app.datacamp.com/learn/projects/1792,,,,,,
,,pd060,,,,,,"csv,md",CSV,No,No,zyt,https://app.datacamp.com/learn/projects/1792,,,,,,
,,pd061,,,,,,"csv,md",CSV,No,No,zyt,https://app.datacamp.com/learn/projects/1792,,,,,,
,,pd062,,,,,,"csv,md",CSV,No,No,zyt,https://app.datacamp.com/learn/projects/1792,,,,,,
,,pd063,,,,,,"csv,md",CSV,No,No,zyt,https://app.datacamp.com/learn/projects/1792,,,,,,
,,pd064,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,https://www.kaggle.com/code/jvdahemad/telco-churn-eda-and-prediction,,,,,,
,,,,,,,,,,,,,https://www.kaggle.com/code/prantosifat/world-painting,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,https://www.kaggle.com/datasets/joebeachcapital/top-10000-spotify-songs-1960-now/data,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,yy,,,,,,,
,,,,,,,,,,,,yy,,,,,,,
,,,,,,,,,,,,yy,,,,,,,