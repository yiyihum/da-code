{"id": "ml-binary-001", "source": "https://www.kaggle.com/code/pratik250/eda-predicting-model#Model-2:-Decision-Tree", "instruction": "I have a dataset for sentiment classification, and the dataset information can be found in the README.md file.  Please help memake predictions on test.csv. Finally, write the predicted character labels (\"Negative\", \"Positive\") into result.csv, following the provided result.csv template.", "hints": "1. Use a hyperparameter tuning process for a decision tree model based on randomized search cross-validation \n2.Numerical encoding for non-numeric features and upsampling for imbalanced classes.\n3. gold result: Precision: 0.8400, Recall: 0.8400, F1 Score: 0.8400, Accuracy: 0.8400", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-001"]}}], "post_process": []}
{"id": "ml-binary-002", "source": "https://www.kaggle.com/code/krishd123/predicting-earthquake-damage-lgbm/notebook#4.-Prediction-on-Test-data", "instruction": "I have a dataset about earthquake-affected building damages. The dataset information can be found in the README.md file. Please help me predict the damage status of the buildings listed in the incomplete.csv file. Save the results to a file named prediction.csv with the following column names: building_id, damage_grade.", "hints": "1. Choose LGBMClassifier\n2. scaling feature", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-002"]}}], "post_process": []}
{"id": "ml-binary-003", "source": "https://www.kaggle.com/code/ranahafezz/twitter-sentiment-analysis-nlp", "instruction": "I have a sentiment classification dataset for statements from various platforms, with the dataset description available in README.md. Please help me predict the sentiment categories for the texts in twitter_validation.csv. Fill your prediction results into prediction.csv, following the provided template.", "hints": "1. Although there are four labels in the training set, according to the description in README.md, Irrelevant and Neutral are considered as one category.\n2. Using multi-threading to process data can speed up data processing time, and we will also select the Random Forest model for training.\n3. accuracy: 95.3%, precision: 95.62%, recall: 94.98%, f1:95.29%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-003"]}}], "post_process": []}
{"id": "ml-binary-004", "source": "https://www.kaggle.com/code/computervisi/best-models-spaceship-titanic", "instruction": "I have a Spaceship Titanic dataset, with the dataset description available in README.md. You need to predict whether passengers were transported to an alternate dimension after the spaceship collision based on this dataset. The data to be predicted is in test.csv. You need to write the predicted data into submission.csv, following the template provided in sample_submission.csv. Please strictly adhere to the template.", "hints": "1. Choose Decision Tree Model, and select suitable hyperparameters, which are max_depth=10, min_samples_split=4, min_samples_leaf=2\n2. fill missing values, and could use method such as Using Statistical Values, Group-based Filling, Mode Filling, Regression Prediction, Logical Filling.\n3. Gold Result:  accuracy: 76.44%, precision: 81.64%, recall: 67.27%, f1:. 73.76%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-004"]}}], "post_process": []}
{"id": "ml-binary-005", "source": "https://www.kaggle.com/code/bhatnagardaksh/pca-and-lda-implementation", "instruction": "This is a Breast Cancer Wisconsin (Diagnostic) Data Set, with the dataset description available in README.md. You need to predict the tumor diagnosis result (B or M) based on the given information. The data to be predicted is in test.csv. You need to write the predicted results into label.csv with the column name 'result'.", "hints": "1.Calculate the p-value between variables and the target value, exclude variables that are not statistically significant.\n2.Calculate the proportion of the number of samples between categories, introduce class weight ratios when training the model.\n3. Normalize the feature values.\n4. Use the Random Forest model.\n5. Gold Result: accuracy: 97.37%, precision: 97.62%, recall: 95.35%, f1: 96.47%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-005"]}}], "post_process": []}
{"id": "ml-binary-006", "source": "https://www.kaggle.com/code/zimhadi1/logestic-reg-svm-naive-bayes-random-forset", "instruction": "I have a dataset containing real and fake news, with the dataset description available in README.md. You need to help me predict the authenticity of the news in validation.csv. Write the prediction results into result.csv with the column name 'result'.", "hints": "\n1.Merge the content of fake and true news data, and shuffle them randomly.\n2. Fake news data is in Fake.csv with label 1, while true news data is in True.csv with label 0.\n3. Logistic regression model can be used to complete the task.\n4. gold result: accuracy: 99.22%, precision: 99.20%, recall: 99.31%, f1: 99.25%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-006"]}}], "post_process": []}
{"id": "ml-binary-007", "source": "https://www.kaggle.com/code/aadyadewangan/churn-predictor", "instruction": "This is a dataset about customer churn, with the dataset description available in README.md. You need to predict whether customers will churn based on this dataset in customer_churn_dataset-testing-master.csv. Write the prediction results into result.csv with the column name 'result'.", "hints": "\n1. Convert some categorical feature variables into numerical encoding.\n2. Data transformation: Use KBinsDiscretizer for data transformation, bin continuous features.\n3. Model training: Use GradientBoostingClassifier as the classifier, set n_estimators to 50, max_depth to 10, and train the model using the training dataset.\n4. gold result: accuracy: 99.33%, precision: 99.08%, recall: 99.51%, f1: 99.30%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-007"]}}], "post_process": []}
{"id": "ml-binary-008", "source": "https://www.kaggle.com/code/yonatanrabinovich/loan-prediction-dataset-ml-project", "instruction": "I have a dataset on loan approval status. You need to predict the loan approval status in test.csv based on this dataset. Write the prediction results (Y or N) into result.csv with the column name 'Loan_Status'.", "hints": "1. Remove the Loan_ID column, handles missing values, and converts text categories to numerical categories. \n2. Use a Decision Tree classifier with a maximum depth of 6.\n3.accuracy: 73.98%, recall: 74.49%, precision: 91.25&, f1: 82.02%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-008"]}}], "post_process": []}
{"id": "ml-binary-009", "source": "https://www.kaggle.com/code/teejmahal20/classification-predicting-customer-satisfaction", "instruction": "This is an airline passenger satisfaction survey dataset, with the description available in README.md. You need to predict the passenger satisfaction in test.csv based on this dataset. Write the prediction results into result.csv with the column name 'satisfaction'.", "hints": "1. Transform the text features in the dataset into numerical types, while handling missing values.\n2. Standardize the feature data using StandardScaler to scale the feature values to a standard normal distribution with a mean of 0 and a variance of 1.\n3. Select the Random Forest classifier RandomForestClassifier.\n4. gold result: accuracy: 96.33%, precision: 95.59% , recall: 97.98%, f1: 96.77%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-009"]}}], "post_process": []}
{"id": "ml-binary-010", "source": "https://www.kaggle.com/code/namanmanchanda/heart-attack-eda-prediction-90-accuracy", "instruction": "I have a dataset for predicting heart attack occurrences, with the dataset description available in README.md. You need to predict the likelihood of a heart attack for individuals in test.csv based on this dataset. Please fill in the prediction results in result.csv, following the provided template.", "hints": "1. Differentiate between categorical feature columns and continuous feature columns.\n3. Scale continuous features using RobustScaler.\n4. Fit the training data using the Logistic Regression model LogisticRegression.\n5. gold result: accuracy: 92%, precision: 90.32% , recall: 96.55%, f1: 93.33%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-010"]}}], "post_process": []}
{"id": "ml-binary-011", "source": "https://www.kaggle.com/code/kamaumunyori/20th-century-usa-income-prediction-96-f1-score", "instruction": "I currently have an income prediction dataset, with the description available in README.md. You need to predict whether the individuals in Test.csv have an income above the income limit based on this dataset. Write your prediction results into results.csv, with the column names \"ID\" (user id) and \"income_above_limit\" (your predicted value).", "hints": "1.Delete columns with more than 70% missing values.\n2. Fill specific values for rows with encoded as 0 for different age groups and occupations.\n3. Handle missing values.\n4. Define mapping rules to convert these features into binary or multiclass encoding.\n5. Define and apply a function to ensure consistent encoding of categorical features in the training and test sets.\n6. Use the SMOTE algorithm to oversample the training data and balance the class distribution.\n7. Create and train a Random Forest classifier.\n8. Gold Results: accuracy: 96.36%, precision: 47.85%, recall: 91.23%, f1: 62.77%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-011"]}}], "post_process": []}
{"id": "ml-binary-012", "source": "https://www.kaggle.com/code/adityarahul/twitter-sentiment-analysis", "instruction": "I have an Emoticon-Based Sentiment in Tweets dataset, with the description available in README.md. You need to predict the sentiment classification of the comments in testdata.manual.2009.06.14.csv based on this dataset (please use characters to represent the sentiment). Write your prediction results into sentiment.csv, with the column name 'emotion'.", "hints": "\n1. Remove emojis, @ tags, # tags, links, and punctuation marks from the text.\n2. Remove stopwords, convert to lowercase, remove duplicates, and tokenize the text.\n3. Use WordNetLemmatizer to lemmatize the tokenized text.\n4. Train a classifier using the LinearSVC model.\n5. accuracy:  79.39%, precision:  79.35%, recall:  80.22%, f1:  79.78%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-012"]}}], "post_process": []}
{"id": "ml-binary-013", "source": "https://www.kaggle.com/code/lilyhyseni/renewind-energy-tuning-pipelining-ml-models", "instruction": "I have a dataset on wind turbine failures, with the description available in README.md. You need to predict whether the turbine will fail based on the data in Test.csv and write the prediction results into target.csv, with the column name \"Target\".", "hints": "1. Fill missing values in the features.\n2. Upsample categories with low counts.\n3. Use the AdaBoost model.\n4. accuracy:  97.56 %, precision:  88.10 %, recall:  65.60 %, f1:  75.20 %", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-013"]}}], "post_process": []}
{"id": "ml-binary-014", "source": "https://www.kaggle.com/code/arvindkhoda/classification-for-customer-churn", "instruction": "I have a customer churn prediction dataset, with the description available in README.md. You need to predict whether the users in test.csv will churn based on their data and write the prediction results into churn.csv, with the column name \"Churn\".", "hints": "1. Convert categorical features to numerical form and standardize them.\n2. Use SMOTE to oversample the training data to balance the classes.\n3. Define an AdaBoost classifier.\n4. accuracy: 76.80%, precision: 37.16%, recall: 40.52%, f1: 38.77%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-014"]}}], "post_process": []}
{"id": "ml-binary-015", "source": "https://www.kaggle.com/code/abdmental01/bank-churn-lightgbm-and-catboost-0-8945", "instruction": "This is a dataset for a Bank customer data for churn prediction competition, with the description available in README.md. You are now a contestant in this competition and need to design a method to predict the data in test.csv according to the competition requirements. Write the results into submission.csv according to the format of sample_submission.csv.", "hints": "1. Select suitable feature\n2. standardized numeric data\n3. Choose CatBoost Classifier", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-015"]}}], "post_process": []}
{"id": "ml-binary-016", "source": "https://www.kaggle.com/code/arunklenin/ps3e24-smoking-cessation-prediction-binary", "instruction": "This is a dataset for a health indicators and smoking status prediction competition, with the description available in README.md. Additionally, I have included an extra dataset. You are now a contestant in this competition and need to design a method to predict the data in test.csv according to the competition requirements. Write the results into submission.csv according to the format of sample_submission.csv.", "hints": "1. fill missing data\n2. Choose suitable feature\n3. Use classifisers to ensemble voting classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-016"]}}], "post_process": []}
{"id": "ml-binary-017", "source": "https://www.kaggle.com/code/tetsutani/icr-iarc-eda-ensemble-and-stacking-baseline", "instruction": "This is a dataset for a health features and medical condition prediction competition, with the description available in README.md. Additionally, I have included an extra dataset. You are now a contestant in this competition and need to design a method to predict the data in test.csv according to the competition requirements. Write the results into submission.csv according to the format of sample_submission.csv.", "hints": "1. fill missing data\n2. Choose suitable feature\n3. Use classifisers to ensemble voting classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-017"]}}], "post_process": []}
{"id": "ml-binary-018", "source": "https://www.kaggle.com/code/haliloglumehmet/genetic-variant-classification", "instruction": "This is a Genetic Variant Classifications dataset, with relevant descriptions provided in the README.md file. Based on the information in test.csv, you need to predict the corresponding categories and write the predicted results into a file named class.csv, with the column name \"CLASS\".", "hints": "1. fill missing data\n2. calculate feature importance\n3. Choose Hist GradientBoosting Classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-018"]}}], "post_process": []}
{"id": "ml-binary-019", "source": "https://www.kaggle.com/code/bansodesandeep/credit-card-default-prediction", "instruction": "This is a Credit Card Default dataset, with relevant descriptions provided in the README.md file. Based on the credit card client information in test.csv, you need to predict whether they will default and write the predicted results into a file named defaulter.csv, with the column name \"IsDefaulter\".", "hints": "1. fill missing data\n2. transform feature to numeric\n3. Use SVM", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-019"]}}], "post_process": []}
{"id": "ml-binary-021", "source": "https://www.kaggle.com/code/prashant111/logistic-regression-classifier-tutorial", "instruction": "This is a Rain in Australia dataset, with relevant descriptions provided in the README.md file. Based on the data in test.csv, you need to predict whether it will rain the next day for each row and write the predicted results into a file named tomorrow.csv, with the column name \"RainTomorrow\".", "hints": "1. preprocess data\n2. use feature engineering\n3. choose logistic regression", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-021"]}}], "post_process": []}
{"id": "ml-binary-022", "source": "https://www.kaggle.com/code/bhuvanchennoju/data-storytelling-auc-focus-on-strokes", "instruction": "This is a Stroke Prediction dataset, with relevant descriptions provided in the README.md file. Based on the information in test.csv, you need to predict whether the individuals will have a stroke and write the predicted results into a file named stroke.csv, with the column name \"stroke.\"", "hints": "1. preprocessing data\n2. Use SMOTE to upsample\n3. Choose Logistic Regression", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-022"]}}], "post_process": []}
{"id": "ml-binary-023", "source": "https://www.kaggle.com/code/mig555/mushroom-classification", "instruction": "This is a Mushroom dataset, with relevant descriptions provided in the README.md file. Based on the mushroom information in test.csv, you need to predict whether they are poisonous and write the predicted results into a file named class.csv, with the column name \"class.\"", "hints": "1. preprocessing data\n2. Choose Decision Tree Classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-023"]}}], "post_process": []}
{"id": "ml-binary-024", "source": "https://www.kaggle.com/code/tumpanjawat/heart-disease-eda-fe-resam-xgboost", "instruction": "This is a Cardiovascular Diseases Risk Prediction dataset, with relevant descriptions provided in the README.md file. Based on the body information in test.csv, you need to predict whether they have heart disease and write the predicted results into a file named disease.csv, with the column name \"Heart_Disease\".", "hints": "1. preprocess data\n2. feature enigneering\n3. Choose XGBClassifier", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-024"]}}], "post_process": []}
{"id": "ml-binary-025", "source": "https://www.kaggle.com/code/tumpanjawat/diabetes-eda-random-forest-hp", "instruction": "This is a Diabetes Prediction dataset, with relevant descriptions provided in the README.md file. Based on the body information in test.csv, you need to predict whether they have diabetes and write the predicted results into a file named diabetes.csv, with the column name \"diabetes.\"", "hints": "1. preprocessing data\n2. feature enigneering\n3. scaling data\n4. Choose RandomForest Classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-025"]}}], "post_process": []}