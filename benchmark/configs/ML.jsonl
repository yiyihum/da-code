{"id": "ml-binary-001", "source": "https://www.kaggle.com/code/pratik250/eda-predicting-model#Model-2:-Decision-Tree", "instruction": "I have a dataset for sentiment classification, and the dataset information can be found in the README.md file.  Please help memake predictions on test.csv. Finally, write the predicted character labels (\"Negative\", \"Positive\") into result.csv, following the provided result.csv template.", "hints": "1. Use a hyperparameter tuning process for a decision tree model based on randomized search cross-validation \n2.Numerical encoding for non-numeric features and upsampling for imbalanced classes.\n3. gold result: Precision: 0.8400, Recall: 0.8400, F1 Score: 0.8400, Accuracy: 0.8400", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-001"]}}], "post_process": []}
{"id": "ml-binary-002", "source": "https://www.kaggle.com/datasets/anmolkumar/health-insurance-cross-sell-prediction", "instruction": "This is a Health Insurance Cross Sell Prediction dataset, and the relevant description is in README.md. You need to predict whether the users in test.csv will respond, and write the results into submission.csv in the format of sample_submission.csv.", "hints": "1. check missing data\n2. transform data to numeric\n3. Choose LGBMClassifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-002"]}}], "post_process": []}
{"id": "ml-binary-003", "source": "https://www.kaggle.com/code/ranahafezz/twitter-sentiment-analysis-nlp", "instruction": "I have a sentiment classification dataset for statements from various platforms, with the dataset description available in README.md. Please help me predict the sentiment categories for the texts in twitter_validation.csv. Fill your prediction results into prediction.csv, with the column name 'result'.", "hints": "1. Although there are four labels in the training set, according to the description in README.md, Irrelevant and Neutral are considered as one category.\n2. Using multi-threading to process data can speed up data processing time, and we will also select the Random Forest model for training.\n3. accuracy: 95.3%, precision: 95.62%, recall: 94.98%, f1:95.29%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-003"]}}], "post_process": []}
{"id": "ml-binary-004", "source": "https://www.kaggle.com/code/computervisi/best-models-spaceship-titanic", "instruction": "I have a Spaceship Titanic dataset, with the dataset description available in README.md. You need to predict whether passengers were transported to an alternate dimension after the spaceship collision based on this dataset. The data to be predicted is in test.csv. You need to write the predicted data into submission.csv, following the template provided in sample_submission.csv. Please strictly adhere to the template.", "hints": "1. Choose Decision Tree Model, and select suitable hyperparameters, which are max_depth=10, min_samples_split=4, min_samples_leaf=2\n2. fill missing values, and could use method such as Using Statistical Values, Group-based Filling, Mode Filling, Regression Prediction, Logical Filling.\n3. Gold Result:  accuracy: 76.44%, precision: 81.64%, recall: 67.27%, f1:. 73.76%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-004"]}}], "post_process": []}
{"id": "ml-binary-005", "source": "https://www.kaggle.com/code/bhatnagardaksh/pca-and-lda-implementation", "instruction": "This is a Breast Cancer Wisconsin (Diagnostic) Data Set, with the dataset description available in README.md. You need to predict the tumor diagnosis result (B or M) based on the given information. The data to be predicted is in test.csv. You need to write the predicted results into label.csv with the column name 'result'.", "hints": "1.Calculate the p-value between variables and the target value, exclude variables that are not statistically significant.\n2.Calculate the proportion of the number of samples between categories, introduce class weight ratios when training the model.\n3. Normalize the feature values.\n4. Use the Random Forest model.\n5. Gold Result: accuracy: 97.37%, precision: 97.62%, recall: 95.35%, f1: 96.47%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-005"]}}], "post_process": []}
{"id": "ml-binary-006", "source": "https://www.kaggle.com/code/zimhadi1/logestic-reg-svm-naive-bayes-random-forset", "instruction": "I have a dataset containing real and fake news, with the dataset description available in README.md. You need to help me predict the authenticity of the news in validation.csv. Write the prediction results into result.csv with the column named 'result'.", "hints": "\n1.Merge the content of fake and true news data, and shuffle them randomly.\n2. Fake news data is in Fake.csv with label 1, while true news data is in True.csv with label 0.\n3. Logistic regression model can be used to complete the task.\n4. gold result: accuracy: 99.22%, precision: 99.20%, recall: 99.31%, f1: 99.25%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-006"]}}], "post_process": []}
{"id": "ml-binary-007", "source": "https://www.kaggle.com/code/aadyadewangan/churn-predictor", "instruction": "This is a dataset about customer churn, with the dataset description available in README.md. You need to predict whether customers will churn based on this dataset in customer_churn_dataset-testing-master.csv. Write the prediction results into result.csv with the column name 'result'.", "hints": "\n1. Convert some categorical feature variables into numerical encoding.\n2. Data transformation: Use KBinsDiscretizer for data transformation, bin continuous features.\n3. Model training: Use GradientBoostingClassifier as the classifier, set n_estimators to 50, max_depth to 10, and train the model using the training dataset.\n4. gold result: accuracy: 99.33%, precision: 99.08%, recall: 99.51%, f1: 99.30%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-007"]}}], "post_process": []}
{"id": "ml-binary-008", "source": "https://www.kaggle.com/code/yonatanrabinovich/loan-prediction-dataset-ml-project", "instruction": "I have a dataset on loan approval status. You need to predict the loan approval status in test.csv based on this dataset. Write the prediction results (Y or N) into result.csv with the column name 'Loan_Status'.", "hints": "1. Remove the Loan_ID column, handles missing values, and converts text categories to numerical categories. \n2. Use a Decision Tree classifier with a maximum depth of 6.\n3.accuracy: 73.98%, recall: 74.49%, precision: 91.25&, f1: 82.02%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-008"]}}], "post_process": []}
{"id": "ml-binary-009", "source": "https://www.kaggle.com/code/teejmahal20/classification-predicting-customer-satisfaction", "instruction": "This is an airline passenger satisfaction survey dataset, with the description available in README.md. You need to predict the passenger satisfaction in test.csv based on this dataset. Write the prediction results into result.csv with the column name 'satisfaction'.", "hints": "1. Transform the text features in the dataset into numerical types, while handling missing values.\n2. Standardize the feature data using StandardScaler to scale the feature values to a standard normal distribution with a mean of 0 and a variance of 1.\n3. Select the Random Forest classifier RandomForestClassifier.\n4. gold result: accuracy: 96.33%, precision: 95.59% , recall: 97.98%, f1: 96.77%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-009"]}}], "post_process": []}
{"id": "ml-binary-010", "source": "https://www.kaggle.com/code/namanmanchanda/heart-attack-eda-prediction-90-accuracy", "instruction": "I have a dataset for predicting heart attack occurrences, with the dataset description available in README.md. You need to predict the likelihood of a heart attack for individuals in test.csv based on this dataset. Please fill in the prediction results in result.csv, following the provided template.", "hints": "1. Differentiate between categorical feature columns and continuous feature columns.\n3. Scale continuous features using RobustScaler.\n4. Fit the training data using the Logistic Regression model LogisticRegression.\n5. gold result: accuracy: 92%, precision: 90.32% , recall: 96.55%, f1: 93.33%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-010"]}}], "post_process": []}
{"id": "ml-binary-011", "source": "https://www.kaggle.com/code/kamaumunyori/20th-century-usa-income-prediction-96-f1-score", "instruction": "I currently have an income prediction dataset, with the description available in README.md. You need to predict whether the individuals in Test.csv have an income above the income limit based on this dataset. Write your prediction results into results.csv, with the column names \"ID\" (user id) and \"income_above_limit\" (your predicted value).", "hints": "1.Delete columns with more than 70% missing values.\n2. Fill specific values for rows with encoded as 0 for different age groups and occupations.\n3. Handle missing values.\n4. Define mapping rules to convert these features into binary or multiclass encoding.\n5. Define and apply a function to ensure consistent encoding of categorical features in the training and test sets.\n6. Use the SMOTE algorithm to oversample the training data and balance the class distribution.\n7. Create and train a Random Forest classifier.\n8. Gold Results: accuracy: 96.36%, precision: 47.85%, recall: 91.23%, f1: 62.77%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-011"]}}], "post_process": []}
{"id": "ml-binary-012", "source": "https://www.kaggle.com/code/adityarahul/twitter-sentiment-analysis", "instruction": "I have an Emoticon-Based Sentiment in Tweets dataset, with the description available in README.md. You need to predict the sentiment classification of the comments in testdata.manual.2009.06.14.csv based on this dataset (please use number to represent the sentiment). Write your prediction results into sentiment.csv, with the column name 'emotion'.", "hints": "\n1. Remove emojis, @ tags, # tags, links, and punctuation marks from the text.\n2. Remove stopwords, convert to lowercase, remove duplicates, and tokenize the text.\n3. Use WordNetLemmatizer to lemmatize the tokenized text.\n4. Train a classifier using the LinearSVC model.\n5. accuracy:  79.39%, precision:  79.35%, recall:  80.22%, f1:  79.78%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-012"]}}], "post_process": []}
{"id": "ml-binary-013", "source": "https://www.kaggle.com/code/lilyhyseni/renewind-energy-tuning-pipelining-ml-models", "instruction": "I have a dataset on wind turbine failures, with the description available in README.md. You need to predict whether the turbine will fail based on the data in Test.csv and write the prediction results into target.csv, with the column name \"Target\".", "hints": "1. Fill missing values in the features.\n2. Upsample categories with low counts.\n3. Use the AdaBoost model.\n4. accuracy:  97.56 %, precision:  88.10 %, recall:  65.60 %, f1:  75.20 %", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-013"]}}], "post_process": []}
{"id": "ml-binary-014", "source": "https://www.kaggle.com/code/arvindkhoda/classification-for-customer-churn", "instruction": "I have a customer churn prediction dataset, with the description available in README.md. You need to predict whether the users in test.csv will churn based on their data and write the prediction results into churn.csv, with the column name \"Churn\".", "hints": "1. Convert categorical features to numerical form and standardize them.\n2. Use SMOTE to oversample the training data to balance the classes.\n3. Define an AdaBoost classifier.\n4. accuracy: 76.80%, precision: 37.16%, recall: 40.52%, f1: 38.77%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-014"]}}], "post_process": []}
{"id": "ml-binary-015", "source": "https://www.kaggle.com/code/haliloglumehmet/genetic-variant-classification", "instruction": "This is a Genetic Variant Classifications dataset, with relevant descriptions provided in the README.md file. Based on the information in test.csv, you need to predict the corresponding categories and write the predicted results into a file named class.csv, with the column name \"CLASS\".", "hints": "1. fill missing data\n2. calculate feature importance\n3. Choose Hist GradientBoosting Classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-015"]}}], "post_process": []}
{"id": "ml-binary-016", "source": "https://www.kaggle.com/code/bansodesandeep/credit-card-default-prediction", "instruction": "This is a Credit Card Default dataset, with relevant descriptions provided in the README.md file. Based on the credit card client information in test.csv, you need to predict whether they will default and write the predicted results into a file named defaulter.csv, with the column name \"IsDefaulter\".", "hints": "1. fill missing data\n2. transform feature to numeric\n3. Use SVM", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-016"]}}], "post_process": []}
{"id": "ml-binary-017", "source": "https://www.kaggle.com/code/prashant111/logistic-regression-classifier-tutorial", "instruction": "This is a Rain in Australia dataset, with relevant descriptions provided in the README.md file. Based on the data in test.csv, you need to predict whether it will rain the next day for each row and write the predicted results into a file named tomorrow.csv, with the column name \"RainTomorrow\".", "hints": "1. preprocess data\n2. use feature engineering\n3. choose logistic regression", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-017"]}}], "post_process": []}
{"id": "ml-binary-018", "source": "https://www.kaggle.com/code/bhuvanchennoju/data-storytelling-auc-focus-on-strokes", "instruction": "This is a Stroke Prediction dataset, with relevant descriptions provided in the README.md file. Based on the information in test.csv, you need to predict whether the individuals will have a stroke and write the predicted results into a file named stroke.csv, with the column name \"stroke.\"", "hints": "1. preprocessing data\n2. Use SMOTE to upsample\n3. Choose Logistic Regression", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-018"]}}], "post_process": []}
{"id": "ml-binary-019", "source": "https://www.kaggle.com/code/mig555/mushroom-classification", "instruction": "This is a Mushroom dataset, with relevant descriptions provided in the README.md file. Based on the mushroom information in test.csv, you need to predict whether they are poisonous and write the predicted results into a file named class.csv, with the column name \"class.\"", "hints": "1. preprocessing data\n2. Choose Decision Tree Classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-019"]}}], "post_process": []}
{"id": "ml-binary-020", "source": "https://www.kaggle.com/code/tumpanjawat/heart-disease-eda-fe-resam-xgboost", "instruction": "This is a Cardiovascular Diseases Risk Prediction dataset, with relevant descriptions provided in the README.md file. Based on the body information in test.csv, you need to predict whether they have heart disease and write the predicted results into a file named disease.csv, with the column name \"Heart_Disease\".", "hints": "1. preprocess data\n2. feature enigneering\n3. Choose XGBClassifier", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-020"]}}], "post_process": []}
{"id": "ml-binary-021", "source": "https://www.kaggle.com/code/tumpanjawat/diabetes-eda-random-forest-hp", "instruction": "This is a Diabetes Prediction dataset, with relevant descriptions provided in the README.md file. Based on the body information in test.csv, you need to predict whether they have diabetes and write the predicted results into a file named diabetes.csv, with the column name \"diabetes.\"", "hints": "1. preprocessing data\n2. feature enigneering\n3. scaling data\n4. Choose RandomForest Classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-021"]}}], "post_process": []}
{"id": "ml-binary-022", "source": "https://www.kaggle.com/code/marto24/bankruptcy-detection", "instruction": "This is a Company Bankruptcy Prediction dataset, with relevant descriptions provided in the README.md file. Based on the information in test.csv, you need to predict whether the company will go bankrupt and write the predicted results into a file named bankrupt.csv, with the column name \"Bankrupt?\".", "hints": "1. use SMOTE to upsample\n2. Choose Logistic Regression", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-binary-022"]}}], "post_process": []}
{"id": "ml-cluster-001", "source": "https://www.kaggle.com/datasets/sonalisingh1411/mallcustomersdataset", "instruction": "This is a dataset of annual income and spending scores in a mall. You need to perform clustering analysis on the annual income and spending scores based on this dataset. Write the clustering results into cluster.csv, where result.csv consists of 'Feature_i' (the ith value of the processed feature vector) and 'Cluster' column (the clustering label results).", "hints": "1.Select the third and fourth columns of data to form a feature vector.\n2. Standardize the variables using StandardScaler.\n3. Choose the AgglomerativeClustering model.\n4. gold result: silhouette: 0.553", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-001"]}}], "post_process": []}
{"id": "ml-cluster-002", "source": "https://www.kaggle.com/code/ayushisharma23/wine-kmeans", "instruction": "I have a dataset of wine chemical components, with the dataset description available in README.md. You need to perform clustering on the data in wine-clustering.csv. Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. Use PCA for dimensionality reduction, transforming the original data into a two-dimensional feature space.\n2. Apply the KMeans algorithm, setting the number of clusters to 3.\n3. gold result: silhouette: 0.572", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-002"]}}], "post_process": []}
{"id": "ml-cluster-003", "source": "https://www.kaggle.com/code/iamnimish/automotive-data-analysis-and-recommendation-system", "instruction": "This is a dataset of car ratings and car feature data, with the description available in README.md. You need to perform a clustering task based on the New York car data. Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. Handle missing values, perform random sampling, and standardize numerical features.\n2. Use Principal Component Analysis (PCA) to reduce the dimensionality of the features.\n3. Implement clustering using the K-means algorithm.", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-003"]}}], "post_process": []}
{"id": "ml-cluster-004", "source": "https://www.kaggle.com/code/esraameslamsayed/clustering-for-facebook-interactions", "instruction": "This is a Facebook Live dataset, with the description available in README.md. You need to perform a clustering task on Facebook interactions based on this dataset. Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. use AgglomerativeClustering, choose 4 clusters\n2. use data cleaning, transform data\n3. silhouette_score 0.814", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-004"]}}], "post_process": []}
{"id": "ml-cluster-005", "source": "https://www.kaggle.com/code/jingtianji12138/quiz-kmeans-solutions", "instruction": "There is now a clustering task dataset, with the description available in README.md. You need to perform clustering tasks on blob_dataset.Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. for blob dataset, use kmeans based on euclidean\n2. for cirlce data, build an adjacency matrix, and use kmeans based on graph distance\n3. silhouette_score: 0.683", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-005"]}}], "post_process": []}
{"id": "ml-cluster-006", "source": "https://www.kaggle.com/code/katherineoktaviani/patient-clustering", "instruction": "This is a Patient Dataset, with the description available in README.md. You need to perform a clustering task based on this dataset. Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. Use MaxMinScaler to normalize the data\n2. Use AgglomerativeClustering method", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-006"]}}], "post_process": []}
{"id": "ml-cluster-007", "source": "https://www.kaggle.com/code/zabihullah18/clustering-analysis-of-students", "instruction": "This is a Students' Social Network Profile dataset, with the description available in README.md. You need to perform a clustering task based on this dataset. Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. fill missing data\n2. data transformation\n3. choose kmeans", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-007"]}}], "post_process": []}
{"id": "ml-cluster-008", "source": "https://www.kaggle.com/code/pavitsu/eda-and-k-mode-cluster-model-interpretation", "instruction": "This is a dataset of user activity records in a real estate system, with the description available in README.md. You need to perform a clustering task based on property.csv, dividing the data into 4 clusters. Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. fill missing data\n2. Use feature engnieering\n2.. Use KModes", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-008"]}}], "post_process": []}
{"id": "ml-cluster-009", "source": "https://www.kaggle.com/code/dipansujoshi/global-country-information-clustering", "instruction": "This is a global countries dataset, with the description available in README.md. You need to perform a clustering task based on this dataset, dividing the data into 3 clusters. Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. Use  SimpleImpute\n2. Use PCA\n3. Choose Kmeans", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-009"]}}], "post_process": []}
{"id": "ml-cluster-010", "source": "https://www.kaggle.com/code/minc33/visualizing-high-dimensional-clusters", "instruction": "This is a Forest Cover Type Dataset, with the description available in README.md. You need to perform a clustering task based on this dataset, dividing the data into an appropriate number of clusters (at least two clusters). Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis..", "hints": "1. choose suitable feature\n2. use T-SNE method\n3. use kMeans", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-010"]}}], "post_process": []}
{"id": "ml-cluster-011", "source": "https://www.kaggle.com/code/hellbuoy/online-retail-k-means-hierarchical-clustering", "instruction": "This is an Online Retail dataset, with the description available in README.md. You need to perform a clustering task based on this dataset, dividing the data into an appropriate number of clusters (at least two clusters). Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis..", "hints": "1. choose suitable feature\n2. fill missing data\n3. use kMeans", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-011"]}}], "post_process": []}
{"id": "ml-cluster-012", "source": "https://www.kaggle.com/code/vishakhdapat/customer-segmentation-using-kmeans", "instruction": "This is a Customer Segmentation dataset, with relevant descriptions provided in the README.md file. Based on this dataset, you need to perform a clustering task to divide the data into an appropriate number of clusters (at least two clusters). Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. choose suitable feature\n2. process feature\n3. use KMeans", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-012"]}}], "post_process": []}
{"id": "ml-cluster-013", "source": "https://www.kaggle.com/code/vipulgohel/clustering-pca", "instruction": "This is a dataset of socioeconomic and health factors for various countries, with relevant descriptions provided in the README.md file. Based on this dataset, you need to perform a clustering task to divide the data into an appropriate number of clusters (at least two clusters). Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. process data\n2. use PCA\n3. Choose Hierarchical Clustering, and select suitable distance threshold", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-013"]}}], "post_process": []}
{"id": "ml-cluster-014", "source": "https://www.kaggle.com/code/karnikakapoor/customer-segmentation-clustering", "instruction": "This is a dataset of customers' personal and purchase data, with relevant descriptions provided in the README.md file. Based on this dataset, you need to perform a clustering task to divide the data into an appropriate number of clusters (at least two clusters). Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. fill missing data\n3. transform feature to numeric\n3. choose AgglomerativeClustering", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-014"]}}], "post_process": []}
{"id": "ml-cluster-015", "source": "https://www.kaggle.com/code/petebleackley/clustering-proteins", "instruction": "This is a Breast Cancer Proteomes dataset, with relevant descriptions provided in the README.md file. Based on this dataset, you need to analyze the breast cancer proteome data and perform a clustering task to divide the data into an appropriate number of clusters (at least two clusters). Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. choose 77_cancer_proteomes_CPTAC_itraq.csv and clinical_data_breast_cancer.csv\n2. choose AgglomerativeClustering", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-015"]}}], "post_process": []}
{"id": "ml-cluster-016", "source": "https://www.kaggle.com/code/khusheekapoor/clustering-using-rfm-analysis-in-python", "instruction": "This is an Online Retail II UCI dataset, with relevant descriptions provided in the README.md file. Based on this dataset, you need to perform a clustering task to segment the customers into an appropriate number of clusters (at least two clusters). Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. Calculate features \n2. Conduct RFM analysis\n3. Choose Agglomerative Clustering", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-016"]}}], "post_process": []}
{"id": "ml-cluster-017", "source": "https://www.kaggle.com/code/shawkyelgendy/customer-segmentation-eda-k-means-pca", "instruction": "This is a Bank Customer Segmentation dataset, with relevant descriptions provided in the README.md file. Based on this dataset, you need to perform a clustering task to segment the bank customers into an appropriate number of clusters (at least two clusters). Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. Clean data\n2. transform feature\n3. Conduct RFM analysis\n4. Choose K-Means++ and 4 clusters", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-017"]}}], "post_process": []}
{"id": "ml-cluster-018", "source": "https://www.kaggle.com/code/mahmoudelfahl/cohort-analysis-customer-segmentation-with-rfm", "instruction": "This is an Online Retail  dataset, with relevant descriptions provided in the README.md file. Based on this dataset, you need to perform a clustering task to segment different types of customer groups into an appropriate number of clusters (at least two clusters). Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. transform data to numeric\n2. Conduct RFM analysis\n3. Choose K-mean and 5 clusters", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-018"]}}], "post_process": []}
{"id": "ml-cluster-019", "source": "https://www.kaggle.com/code/pinardogan/rfm-customer-segmentation-using-k-means", "instruction": "This is an Online Retail II Data Set dataset, with relevant descriptions provided in the README.md file. Based on this dataset, you need to perform a clustering task to segment different types of customer groups into an appropriate number of clusters (at least two clusters). Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. transform data to numeric\n2. Conduct RFM analysis\n3. Choose K-mean and 6 clusters", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-019"]}}], "post_process": []}
{"id": "ml-cluster-020", "source": "https://www.kaggle.com/code/daniilkrasnoproshin/k-means-simplified-expedition-into-clustering", "instruction": "This is an Iris Flower Dataset, with relevant descriptions provided in the README.md file. You need to perform clustering on these flower samples, selecting an appropriate number of clusters (at least two clusters). Write the clustering results into a file named cluster.csv. The file should include columns named Processed_Feature_i for each value of the processed feature vector, where i represents the index of the feature, and Cluster for the label of the cluster obtained from the clustering analysis.", "hints": "1. preprocess data\n2. Choose K-Means and select 3 clusters", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-cluster-020"]}}], "post_process": []}
{"id": "ml-competition-001", "source": "https://www.kaggle.com/code/abdmental01/bank-churn-lightgbm-and-catboost-0-8945", "instruction": "This is a dataset for a Bank customer data for churn prediction competition, with the description available in README.md. You are now a contestant in this competition and need to design a method to predict the data in test.csv according to the competition requirements. Write the results into submission.csv according to the format of sample_submission.csv.", "hints": "1. Select suitable feature\n2. standardized numeric data\n3. Choose CatBoost Classifier", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-001"]}}], "post_process": []}
{"id": "ml-competition-002", "source": "https://www.kaggle.com/code/arunklenin/ps3e24-smoking-cessation-prediction-binary", "instruction": "This is a dataset for a health indicators and smoking status prediction competition, with the description available in README.md. Additionally, I have included an extra dataset. You are now a contestant in this competition and need to design a method to predict the data in test.csv according to the competition requirements. Write the results into submission.csv according to the format of sample_submission.csv.", "hints": "1. fill missing data\n2. Choose suitable feature\n3. Use classifisers to ensemble voting classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-002"]}}], "post_process": []}
{"id": "ml-competition-003", "source": "https://www.kaggle.com/code/tetsutani/icr-iarc-eda-ensemble-and-stacking-baseline", "instruction": "This is a dataset for a health features and medical condition prediction competition, with the description available in README.md. Additionally, I have included an extra dataset. You are now a contestant in this competition and need to design a method to predict the data in test.csv according to the competition requirements. Write the results into submission.csv according to the format of sample_submission.csv.", "hints": "1. fill missing data\n2. Choose suitable feature\n3. Use classifisers to ensemble voting classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-003"]}}], "post_process": []}
{"id": "ml-competition-004", "source": "https://www.kaggle.com/code/lucamassaron/steel-plate-eda-xgboost-is-all-you-need", "instruction": "This is a dataset for a Steel plates data for defect prediction competition, with the description available in README.md. You are now a contestant in this competition and need to design a method to predict the data in test.csv according to the competition requirements. Write the results into submission.csv according to the format of sample_submission.csv.", "hints": "1. analysis target data\n2. use  feature engineering\n3. choose xgboost classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-004"]}}], "post_process": []}
{"id": "ml-competition-005", "source": "https://www.kaggle.com/code/markuslill/s3e26-xgbclassifer", "instruction": "This is a dataset for a Patient data for cirrhosis outcomes prediction competition, along with an additional dataset. The descriptions are available in README.md. You are now a contestant in this competition and need to design a method to predict the data in test.csv according to the competition requirements. Write the results into submission.csv according to the format of sample_submission.csv.", "hints": "1. select suitable feature\n2. chosse xgboost classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-005"]}}], "post_process": []}
{"id": "ml-competition-006", "source": "https://www.kaggle.com/code/abhi011097/s3-e5-eda-multi-approach-models-w-o-smote", "instruction": "This is a dataset for a Wine Quality Prediction competition, with the description available in README.md. You are now a contestant in this competition and need to design a method to predict the data in test.csv according to the competition requirements. Write the results into submission.csv according to the format of sample_submission.csv.", "hints": "1. fill missing data\n2. calculate correlationship to select suitable feature\n3. Use RandomForest Classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-006"]}}], "post_process": []}
{"id": "ml-competition-007", "source": "https://www.kaggle.com/code/serigne/stacked-regressions-top-4-on-leaderboard", "instruction": "You are now participating in a House Prices prediction competition, with the description available in README.md. You need to complete the price prediction and write the prediction results into submission.csv. You can refer to sample_submission.csv for the format of the csv file.", "hints": "1. fill missing data\n2. Transforming some numerical variables that seem really categorical\n3. Label Encoding some categorical variables that may contain information in their ordering set\n4.  choose many base models, cross-validate them on the data before stacking/ensembling them", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-007"]}}], "post_process": []}
{"id": "ml-competition-008", "source": "https://www.kaggle.com/code/aritra100/notebook-linear-regression-vs-regressor-r2score85", "instruction": "This is a flood prediction competition dataset, with the description available in README.md. As a participant, you need to design a method to predict the probability of flood occurrence in test.csv and write the prediction results into submission.csv, following the format of the sample_submission.csv template.", "hints": "1.Remove the id column.\n2. Standardize the training data.\n3. Encode and preprocess the target variable\n4. Use stacked model", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-008"]}}], "post_process": []}
{"id": "ml-competition-009", "source": "https://www.kaggle.com/code/rohangulati14/leading-sol-regression-with-an-abalone-dataset", "instruction": "This is a competition based on an abalone dataset, with the description available in README.md. As a participant, you need to design a solution to complete this competition. Write your prediction results into submission.csv following the format of sample_submission.csv.", "hints": "1. Remove the id column from the training and testing data.\n2. Merge the original training data with the new training data.\n3. Remove duplicate values.\n4. Train a stacked regression model.", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-009"]}}], "post_process": []}
{"id": "ml-competition-010", "source": "https://www.kaggle.com/code/iqmansingh/crab-age-voting-regression-synthetic-data", "instruction": "This is a crab age prediction competition, with the description available in README.md. To achieve a higher ranking, an additional dataset of crab ages is provided. As a participant, you need to design and optimize a method to complete this competition. Write the prediction results into submission.csv, following the format of 'sample_submission.csv'.", "hints": "1. use feature in the dataset to generate new feature\n2. use VoteRegressor", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-010"]}}], "post_process": []}
{"id": "ml-competition-011", "source": "https://www.kaggle.com/code/sergiosaharovskiy/ps-s3e14-2023-first-place-winning-solution", "instruction": "This is a wild blueberry yield prediction competition, with the description available in README.md. Additionally, I have provided an extra dataset. As a participant, you need to design and optimize a method to complete this competition. Write the prediction results into submission.csv, following the format of \"sample_submission.csv\".", "hints": "1. feauter engineering\n2. Choose LGBMCVModel", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-011"]}}], "post_process": []}
{"id": "ml-competition-012", "source": "https://www.kaggle.com/code/kacperrabczewski/rwanda-co2-step-by-step-guide", "instruction": "This is a dataset for a CO2 emissions prediction competition, with the description available in README.md. You are now a contestant in this competition and need to design a method to predict the data in test.csv. Write the results into submission.csv according to the format of sample_submission.csv.", "hints": "1. fill missing data\n2. use feature engineering to process feature\n3. Choose RandomForestRegressor", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-012"]}}], "post_process": []}
{"id": "ml-competition-013", "source": "https://www.kaggle.com/code/tumpanjawat/s3e19-course-eda-fe-lightgbm", "instruction": "This is a dataset for a sales volume prediction competition, with the description available in README.md. You are now a contestant in this competition and need to design a method to predict the data in test.csv. Write the results into submission.csv according to the format of sample_submission.csv.", "hints": "1. fill missing data\n2. feature engineering\n3. Train LightGBM model ", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-013"]}}], "post_process": []}
{"id": "ml-competition-014", "source": "https://www.kaggle.com/code/cdeotte/linear-regression-baseline-lb-1-092", "instruction": "This is a dataset for a U.S. county-level monthly microbusiness data competition, with the description available in README.md. You are now a contestant in this competition and need to design a method to predict the data in test.csv. Write the results into submission.csv according to the format of sample_submission.csv.", "hints": "1. fill missing data\n2. Choose Linear Regression", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-014"]}}], "post_process": []}
{"id": "ml-competition-015", "source": "https://www.kaggle.com/code/hardikgarg03/regression-with-mohs-hardness", "instruction": "This is a dataset for a Mineral properties data for hardness prediction competition, with the description available in README.md. You are now a contestant in this competition and need to design a method to predict the data in test.csv according to the competition requirements. Write the results into submission.csv according to the format of sample_submission.csv.\n\n\n\n\n", "hints": "1. fill missing data\n2. choose sutiable feature\n3. Choose Linear Regression", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-015"]}}], "post_process": []}
{"id": "ml-competition-016", "source": "https://www.kaggle.com/code/yantxx/xgboost-binary-classifier-machine-failure", "instruction": "This is a dataset for the Binary Classification of Machine Failures competition, with relevant descriptions provided in the README.md file. As a participant, you need to complete the competition requirements by predicting the results for test.csv and writing them into submission.csv following the format of sample_submission.csv.", "hints": "1. drop duplicated rows\n2. transform feature to numerci\n3. Choose XgboostClassifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-016"]}}], "post_process": []}
{"id": "ml-competition-017", "source": "https://www.kaggle.com/code/ye11725/tfidf-lgbm-baseline-cv-0-799-lb-0-799", "instruction": "You are participating in an Automated Essay Scoring competition. The dataset and relevant descriptions are provided in the README.md file. As a participant, your task is to generate predictions of data in test.csv and write the results into a submission file named submission.csv in the format specified by sample_submission.csv.", "hints": "1. clean test data\n2. use tf-idf vectorizor\n3, chooese LGBMClassifier ", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-017"]}}], "post_process": []}
{"id": "ml-competition-018", "source": "https://www.kaggle.com/code/yongsukprasertsuk/ai-generated-text-mod-weight-add-more-data-0-929", "instruction": "This is a dataset for the LLM - Detect AI Generated Text competition, with relevant descriptions provided in the README.md file. As a participant, you need to complete the competition requirements by predicting the results for test_essays.csv and writing them into submission.csv following the format of sample_submission.csv.", "hints": "1. clearn data\n2. extract word feature\n3. use lgbmclassifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-018"]}}], "post_process": []}
{"id": "ml-competition-019", "source": "https://www.kaggle.com/competitions/playground-series-s4e2/data", "instruction": "This is a dataset for the Multi-Class Prediction of Obesity Risk competition, with relevant descriptions provided in the README.md file. As a participant, you need to complete the competition requirements by predicting the results for test.csv and writing them into submission.csv following the format of sample_submission.csv.", "hints": "1. explore data\n2. transform feature to numeric\n3. choose lgbmclassifiser\n4. select best hyperparameter", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-019"]}}], "post_process": []}
{"id": "ml-competition-020", "source": "https://www.kaggle.com/code/hardikgarg03/horse-health-prediction-using-stacked-models", "instruction": "This is a dataset for the Predict Health Outcomes of Horses competition, with relevant descriptions provided in the README.md file. As a participant, you need to complete the competition requirements by predicting the results for test.csv and writing them into submission.csv following the format of sample_submission.csv.", "hints": "1. transform data to numeric\n2. Ensemble XGBClassifiser, RandomForestClassifiser, CatBoostClassifier to a Stacked Classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-competition-020"]}}], "post_process": []}
{"id": "ml-multi-001", "source": "https://www.kaggle.com/code/jillanisofttech/human-activity-recognition-with-smartphones-99-acc", "instruction": "I have a human activity classification dataset, with the description available in README.md. You need to predict the activity categories in activity_test.csv based on this dataset. Write your prediction results into activity.csv, with the column name \"Activity\".", "hints": "1. Select activities.csv for model training.\n2. Normalize the data.\n3. Choose the SVM model for training.\n4. gold result: accuracy: 95.66%, precision: 95.74%, recall: 95.47%, f1: 95.55%", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-multi-001"]}}], "post_process": []}
{"id": "ml-multi-002", "source": "https://www.kaggle.com/code/iamnimish/automotive-data-analysis-and-recommendation-system", "instruction": "This is a dataset of car ratings and car feature data, with the description available in README.md. You need to predict the status and type of the cars based on the car information in test.csv, and write the prediction results into result.csv with the column name \"new&used\".\n\n\n\n\n", "hints": "1. fill missing variable\n2. transform feature to numeric\n3. choose logisticregression", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-multi-002"]}}], "post_process": []}
{"id": "ml-multi-003", "source": "https://www.kaggle.com/code/benvarghese/linkedin-job-posting-machine-learning", "instruction": "This is a job information dataset, with the description available in README.md. You need to predict the experience level of job positions in test.csv based on this dataset and write the results into result.csv, with the column name \"formatted_experience_level\".", "hints": "1. fill missing data\n2. choose and process suitable feature\n3. choose logisticregression", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-multi-003"]}}], "post_process": []}
{"id": "ml-multi-004", "source": "https://www.kaggle.com/code/wonduk/predict-eda-on-adaptivity-in-online-education", "instruction": "This is a dataset on Students Adaptability Level in Online Education, with relevant descriptions provided in the README.md file. Based on the student information in test.csv, you need to predict their activity level and write the predicted results into a file named level.csv, with the column name \"Adaptivity Level\".\n", "hints": "1. fill missing data\n2. select suitabl feature\n3. choose CatBoostClassifier", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-multi-004"]}}], "post_process": []}
{"id": "ml-multi-005", "source": "https://www.kaggle.com/code/hanyjr/emotion-detection-text-processing-ml", "instruction": "This is an Emotions dataset for NLP, with relevant descriptions provided in the README.md file. Based on the text information in test.txt, you need to predict the corresponding emotions and write the predicted results into a file named emotions.csv, with the column name \"emotion\".", "hints": "1. Perform operations such as converting to lowercase, removing special characters, punctuation, stop words, and stemming.\n2. Use CountVectorizer\n3. use mutl classifisers to ensemble a   VotingClassifier", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-multi-005"]}}], "post_process": []}
{"id": "ml-multi-006", "source": "https://www.kaggle.com/code/redpen12/feature-engineering-catboost", "instruction": "This is a Credit Score Classification dataset, with relevant descriptions provided in the README.md file. Based on the information in test.csv, you need to predict the corresponding credit scores and write the predicted results into a file named score.csv, with the column name \"Credit_Score\".", "hints": "\n1. use methods like get_month, get_numbers, replace_special_character, preprocess_text, and fill_na.\n2. choose catboost classifiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-multi-006"]}}], "post_process": []}
{"id": "ml-multi-007", "source": "https://www.kaggle.com/code/ahmetesencan/multiclass-date-classification-with-some-models", "instruction": "This is a Fruit Classification dataset, with relevant descriptions provided in the README.md file. Based on the fruit information in test.csv, you need to predict the corresponding categories and write the predicted results into a file named class.csv, with the column name \"Class\".", "hints": "1. normalize feature\n2. choose SVM", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-multi-007"]}}], "post_process": []}
{"id": "ml-multi-008", "source": "https://www.kaggle.com/code/steremma/news-exploration-using-gensim-and-sklearn", "instruction": "This is a News Aggregator Dataset, with relevant descriptions provided in the README.md file. Based on the text information in test.csv, you need to predict the corresponding categories and write the predicted results into a file named category.csv, with the column name \"CATEGORY\".", "hints": "1. clean tokens\n2. use CountVectorizer\n3. choose RandomForest", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-multi-008"]}}], "post_process": []}
{"id": "ml-multi-009", "source": "https://www.kaggle.com/code/thisishusseinali/malicious-url-detection", "instruction": "This is a Malicious URLs dataset, with relevant descriptions provided in the README.md file. Based on the text information in test.csv, you need to predict the corresponding categories and write the predicted results into a file named type.csv, with the column name \"type\".", "hints": "1. Calculate class weight\n2. Choose ExtraTreesClassfiser", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-multi-009"]}}], "post_process": []}
{"id": "ml-multi-010", "source": "https://www.kaggle.com/datasets/kukuroo3/body-performance-data/data", "instruction": "This is a Body Performance dataset, with relevant descriptions provided in the README.md file. Based on the data in test.csv, you need to make predictions and write the predicted results into a file named class.csv, with the column name \"class\".", "hints": "1. preprocess data\n2. Ensemble VotingClassifier", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-multi-010"]}}], "post_process": []}
{"id": "ml-multi-011", "source": "https://www.kaggle.com/code/datatattle/battle-of-ml-classification-models", "instruction": "This is a Coronavirus Tweets NLP - Text Classification dataset, with relevant descriptions provided in the README.md file. Based on the text information in Corona_NLP_test.csv, you need to predict their sentiment (classifying them as \"Positive,\" \"Negative,\" or \"Neutral\") and write the predicted results into a file named sentiment.csv, with the column name \"Sentiment.\"", "hints": "1. cleaning text\n2. Choose  LinearSVC", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-multi-011"]}}], "post_process": []}
{"id": "ml-multi-012", "source": "https://www.kaggle.com/code/krishd123/predicting-earthquake-damage-lgbm/notebook#4.-Prediction-on-Test-data", "instruction": "I have a dataset about earthquake-affected building damages. The dataset information can be found in the README.md file. Please help me predict the damage status of the buildings listed in the incomplete.csv file. Save the results to a file named prediction.csv with the following column names: building_id, damage_grade.", "hints": "1. Choose LGBMClassifier\n2. scaling feature", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-multi-012"]}}], "post_process": []}
{"id": "ml-regression-001", "source": "https://www.kaggle.com/code/varunsaikanuri/flight-fare-prediction-10-ml-models", "instruction": "This is a flight booking information dataset, with the description available in README.md. You need to predict the flight prices in test.csv based on this dataset. Write the prediction results into result.csv with the column name 'price'.", "hints": "1. Use LabelEncoder to encode the text categories in the dataset and convert them into numerical types.\n2. Normalize the feature data using MinMaxScaler, scaling the feature values to a specified range between 0 and 1.\n3. Use the ExtraTreesRegressor model with n_estimators set to 100, max_depth set to 16, min_samples_leaf set to 4, n_jobs set to -1, and random_state set to 42.\n4. gold reuslt: MAE: 1870.437,  MSE: 12741486.303, RMSE: 3569.522, R2_score: 0.975282\n", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-001"]}}], "post_process": []}
{"id": "ml-regression-002", "source": "https://www.kaggle.com/code/nigelclinton/energy-price-prediction-ml", "instruction": "I have a dataset on Spanish electricity and weather, with the description available in README.md. You need to predict the electricity prices in test.csv based on this dataset. Write your prediction results into result.csv, with the column name \"price actual\".", "hints": "1. Calculate correlations and remove variables with weak correlations.\n2. Impute missing values.\n3. Select the Random Forest regression model.\n4. Gold Result: MSE: 350.173, RMSE: 18.713 ,R2_score: -0.724, MAE: 14.776", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-002"]}}], "post_process": []}
{"id": "ml-regression-003", "source": "https://www.kaggle.com/code/aslanahmedov/walmart-sales-forecasting", "instruction": "This is a Walmart sales dataset, with the description available in README.md. You need to predict the weekly sales based on this dataset and write the prediction results into submission.csv, with the column name \"Weekly_Sales\".", "hints": "1. Use features in stores.csv and features.csv\n2. Cleaning data and select important variable\n3. use xgb model\n4. Gold Result: MAE: 14230.528, MSE: 379459071.536, \nRMSE: 19479.709,  R2_score: -0.047715\n", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-003"]}}], "post_process": []}
{"id": "ml-regression-004", "source": "https://www.kaggle.com/code/dima806/spotify-song-ratings-predict-catboost-shap", "instruction": "I currently have a pop music dataset, with the description available in README.md. You need to predict the popularity of the songs in test.csv based on this dataset. Write the prediction results into popularity.csv, with the column name \"Poplarity\".", "hints": "1.Remove duplicates, filter out the label column, extract features, and group them for processing.\n2. Encode and preprocess the features.\n3.Train and make predictions using the CatBoostRegressor model. \n4. MAE: 16.879, MSE: 433.984,  RMSE: 20.832, R2_score: 0.096803, RMSLE: 3.037", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-004"]}}], "post_process": []}
{"id": "ml-regression-005", "source": "https://www.kaggle.com/code/minkhantmk19/used-car-prediction", "instruction": "I currently have an income prediction dataset, with the description available in README.md. You need to predict the individual incomes in test.csv based on this dataset. Write your prediction results into price.csv, with the column name \"price\".\n\n\n\n\n", "hints": "1. Load the training data, convert column names to lowercase, remove missing values in the price column, and convert the price to an integer.\n2. Identify the target variable, binary variables, categorical variables, and numerical variables. Remove outliers in price and engine size, and retain selected categorical variables.\n3. Train xgb model\n4. MAE: 5081.665, MSE: 195978257.369, RMSE: 13999.223, R2_score: 0.730044\n", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-005"]}}], "post_process": []}
{"id": "ml-regression-006", "source": "https://www.kaggle.com/code/hknaralasetty/lego-regression-55-23-randomforest-mae-e-5", "instruction": "This is a Lego sets and price [1955 - 2023] dataset, with the description available in README.md. You need to predict the star rating for the data in test.csv. Write your prediction results into result.csv, with the column name \"Star rating\".", "hints": "1. fill missing data\n2. choose randomforest\n3.MAE: 0.353, MSE: 0.229, RMSE: 0.478, R2_score: -0.227516", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-006"]}}], "post_process": []}
{"id": "ml-regression-007", "source": "https://www.kaggle.com/code/dima806/job-satisfaction-eurostat-autoviz-catboost-shap", "instruction": "This data is collected from Eurostat, with the description available in README.md. You need to predict the average job satisfaction in test.csv and write your prediction results into job_satisfaction.csv, with the column name \"AVG_JOB_SATISFACTION\".", "hints": "1. Bin or transform numerical features.\n2. Train the model using the CatBoostRegressor\n3. MAE: 0.507, MSE: 0.47, RMSE: 0.686, R2_score: -0.364015, RMSLE: -0.377", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-007"]}}], "post_process": []}
{"id": "ml-regression-008", "source": "https://www.kaggle.com/code/michaelminhpham/predict-unit-sold-mens-women-shoes-on-tiki", "instruction": "This is a dataset of product information from the TIKI e-commerce platform, with the description available in README.md. You need to predict the product sales based on the product information in test.csv. Please note that all items in test.csv are shoes. Write the prediction results into quantity.csv, with the column name \"quantity_sold\"", "hints": "1. Choose LazyRegressor Model\n2. Standerize feature\n3. choose vietnamese_tiki_products_men_shoes.csv and ietnamese_tiki_products_women_shoes.csv", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-008"]}}], "post_process": []}
{"id": "ml-regression-009", "source": "https://www.kaggle.com/code/renjiabarai/barcelona-airbnb-regression", "instruction": " have an Airbnb listing dataset for Barcelona, with the description available in README.md. You need to predict the prices of the listings in test.csv based on their information. Write the prediction results into price.csv, with the column name \"price\".", "hints": "1. Convert categorical data to numerical data.\n2. Fill missing values.\n3. Choose the CatBoost regression model.", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-009"]}}], "post_process": []}
{"id": "ml-regression-010", "source": "https://www.kaggle.com/code/renjiabarai/drug-reviews-regression", "instruction": "This is a dataset of comprehensive drug ratings, with the description available in README.md. You need to predict the usefulness of drugs in drugsComTest_raw.csv based on this dataset and write the prediction results into \"Usefulness.csv\", with the column name \"usefulness\".", "hints": "1. Use Data Manipulation\n2. Choose CatBoostRegressor", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-010"]}}], "post_process": []}
{"id": "ml-regression-011", "source": "https://www.kaggle.com/code/mehmetisik/u-s-farms-biogas-ml-prediction-livestock", "instruction": "Here is a biogas dataset, with the description available in README.md. You need to predict the Biogas Generation Estimate (cu-ft/day) in test.csv based on this dataset, and write the prediction results into result.csv, with the column name 'biogas_generation_estimate_cuftday'.", "hints": "1. fill missing data \n2. data transformation\n3. Chosse LGBMRegressor", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-011"]}}], "post_process": []}
{"id": "ml-regression-012", "source": "https://www.kaggle.com/code/iamnimish/automotive-data-analysis-and-recommendation-system", "instruction": "This is a dataset of vehicle information in New York, with the description available in README.md. You need to predict the Mileage of vehicles in test.csv based on this dataset and write the results into result.csv, with the column name \"Mileage\".", "hints": "1. fill missing data\n2. choose suitable feature\n3. Choose GradientBoostingRegressor ", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-012"]}}], "post_process": []}
{"id": "ml-regression-013", "source": "https://www.kaggle.com/code/farzadnekouei/polynomial-regression-regularization-assumptions", "instruction": "This is a Vehicle dataset, with relevant descriptions provided in the README.md file. Based on the vehicle data in test.csv, you need to predict their prices and write the predicted results into a file named price.csv, with the column name \"Selling_Price\".", "hints": "1. select feature and transform them\n2. use regularization\n3. Build Elastic-Net Regression Model", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-013"]}}], "post_process": []}
{"id": "ml-regression-014", "source": "https://www.kaggle.com/code/qusaybtoush1990/car-prices-poland", "instruction": "This is a Car Prices Poland dataset, with relevant descriptions provided in the README.md file. Based on the vehicle information in test.csv, you need to predict their prices and write the predicted results into a file named price.csv, with the column name \"price\".", "hints": "1. fill missing data\n2. transform feature to numeric\n3. Choose RandomForest Regressor", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-014"]}}], "post_process": []}
{"id": "ml-regression-015", "source": "https://www.kaggle.com/code/msand1984/appliance-energy-prediction", "instruction": "This is an Appliances Energy Prediction dataset, with relevant descriptions provided in the README.md file. Based on the information in test.csv, you need to predict the corresponding appliance energy consumption and write the predicted results into a file named appliance.csv, with the column name \"Appliances\".", "hints": "1. Calculate Correlation matrix\n2. drop irrelevant feature\n3. Choose ExtraTreesRegressor", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-015"]}}], "post_process": []}
{"id": "ml-regression-016", "source": "https://www.kaggle.com/code/arnabchaki/flight-fare-prediction-0-96-r2-score", "instruction": "This is an Airfare ML: Predicting Flight Fares dataset, with relevant descriptions provided in the README.md file. Based on the flight information in test.csv, you need to predict the corresponding fares and write the predicted results into a file named fare.csv, with the column name \"Fare\".", "hints": "1. select suitable feature\n2. Choose ExtraTreesRegressor", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-016"]}}], "post_process": []}
{"id": "ml-regression-017", "source": "https://www.kaggle.com/code/alperkaraca1/steam-score-prediction", "instruction": "This is a Steam Releases dataset, with relevant descriptions provided in the README.md file. Based on the game information in test.csv, you need to predict the corresponding ratings and write the predicted results into a file named rating.csv, with the column name \"rating\".", "hints": "1. select suitable feature\n2. calculate feature importance\n3. Choose RandomForest Regressor", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-017"]}}], "post_process": []}
{"id": "ml-regression-018", "source": "https://www.kaggle.com/code/anoopashware/food-demand-forecasting-predict-orders", "instruction": "This is a Food Demand Forecasting dataset, with relevant descriptions provided in the README.md file. Based on the information in test.csv, you need to predict the corresponding orders and write the predicted results into submission.csv following the format of sample_submission.csv.", "hints": "1. select suitable feature\n2. normalize data\n3. choose RandomForestRegressor", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-018"]}}], "post_process": []}
{"id": "ml-regression-019", "source": "https://www.kaggle.com/code/wkirgsn/eda-and-baseline-on-motor-temperature-estimation", "instruction": "This is an Electric Motor Temperature dataset, with relevant descriptions provided in the README.md file. Based on the sensor data in test.csv, you need to predict the rotor temperature and write the predicted results into a file named pm.csv, with the column name \"pm\".", "hints": "1. select suitable feature, and transform them\n2. Choose RandomForestRegressor", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-019"]}}], "post_process": []}
{"id": "ml-regression-020", "source": "https://www.kaggle.com/code/saloni1712/deliverontime-food-delivery-duration-predictor", "instruction": "This is a Food Delivery Dataset, with relevant descriptions provided in the README.md file. Based on the information in test.csv, you need to predict the required delivery time and write the predicted results into submission.csv following the format of sample_submission.csv.", "hints": "1. Clean Data\n2. transform data and select suitable feature\n3. Choose XGBoost Regressor", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-020"]}}], "post_process": []}
{"id": "ml-regression-021", "source": "https://www.kaggle.com/code/iabhishekmaurya/used-car-price-prediction", "instruction": "This is a Used Cars Price Prediction dataset, with relevant descriptions provided in the README.md file. Based on the vehicle information in test-data.csv, you need to predict their prices and write the predicted results into a file named price.csv, with the column name \"price.\"", "hints": "1. select feature\n2. Choose RandomForestRegressor", "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/ml-regression-021"]}}], "post_process": []}
