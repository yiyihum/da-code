{"id": "dm-csv-001", "source": "https://drive.google.com/drive/folders/1OU_cqpOHpBpXk-BuvOz11GFr96Z7a7gC?usp=sharing", "instruction": "This is a UFC Fighters’ Statistics 2024 dataset with a description in README.md.  You should filter out the best fighters in each UFC weight class and determine how many fighters in each class have never been defeated. Finally, fill in the results into ‘undefeated.csv’", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-001"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-002", "source": "https://drive.google.com/drive/folders/1sp-WM5vMDhbmtz7I3u_Z7-S9CPuc26KE?usp=share_link", "instruction": "This is a Dropout and Success: Student Data Analysis dataset with a description in README.md. Count the number of students who are “Never Married” and “Previously Married”, and fill the results into result.csv, following the template in sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-002"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-003", "source": "https://drive.google.com/drive/folders/1pnuwL2YklpB3Ulybz9Iq9NUqjsJCdKPI?usp=share_link", "instruction": "This is a Dropout and Success: Student Data Analysis dataset with a description in README.md. Determine the top five most common educational qualifications for both mothers and fathers. Analyze the data to find the frequency of each qualification and save the results in a file named top_qualifications.csv. The file should include the qualification names instead of codes and should be sorted in decreasing order of frequency. Ensure the top_qualifications.csv file has the following column names: “Mother’s Qualification”, “Mother’s Frequency”, “Father’s Qualification”, “Father’s Frequency”.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-003"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-004", "source": "https://drive.google.com/drive/folders/1YN5lSZInIb75vYQfdEaWKGau-RTCKF_2?usp=share_link", "instruction": "This is an Olympics 124 years Dataset (till 2020) with a description in README.md. You should onduct an analysis to determine the total number of Games held for both the Summer and Winter Olympics, and record this information in “allGames.csv” following the template in “sample_allGames.csv”. Additionally, for each edition of both the Summer and Winter Olympics, identify the host city and the total number of events conducted, and compile this detailed information in “allEvents.csv” following the template in “sample_allEvents.csv”.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-004"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-005", "source": "https://drive.google.com/drive/folders/1XvKXqZNPLXco8efGE33fpMN3zVF9PmZ6?usp=share_link", "instruction": "This is a Book Recommendation Dataset with a description in README.md. Based on the instructions in age.txt, count the number of people in each age group and record the results in result.csv following the template provided in sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-005"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-006", "source": "https://drive.google.com/drive/folders/1jwQT4xLOG4uHCjWSvEqbgAwOan7051qC?usp=share_link", "instruction": "This is a Bike Store Relational Database dataset with a description in README.md. Determine which products are frequently purchased together. Specifically, find the different products that are purchased together in the same order and calculate the number of times they are purchased together. Write the information of the top two pairs with the highest purchase count into result.csv. The column names in result.csv should be “product_a” for the name of the first product, “product_b” for the name of the second product, and “co_purchase_count” for the number of times the two products are purchased together.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-006"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-007", "source": "https://drive.google.com/drive/folders/1wVs85eVx4KYhN0qa-eLjlNEBSLEoJGQc?usp=share_link", "instruction": "This is a TMDB 5000 Movie Dataset with a description in README.md. According to the guidance in ‘wrFormula.tex’, you should identify the top 10 most popular movies and record their name in result.csv following the template provided in sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-007"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-009", "source": "https://drive.google.com/drive/folders/14793kyfMJ5GRbe5djEr0uzvQwXkwr-JM?usp=share_link", "instruction": "This is an Amazon Books Dataset with a description in README.md. Identify the top 10 Best-Rated Authors, Most Expensive Authors, and Most Rated Authors. Record the results in author.csv following the template provided in sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-009"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-010", "source": "https://drive.google.com/drive/folders/1V339AXpqR-f1DZK9wJNd0CN_svQf-I7o?usp=sharing", "instruction": "This is a Bike Store Relational Database, with related descriptions provided in the README.md file. You need to calculate the annual average sales volume for each bike category and write the results into avg_units_sold.csv following the template of sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-010"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-011", "source": "https://drive.google.com/drive/folders/1tO4GVH2DYJJwF2-HmSf3zTEzOUopthwH?usp=sharing", "instruction": "This is a Bike Store Relational Database, with relevant descriptions provided in the README.md file. You need to calculate and aggregate the total quantity sold and total sales revenue for each bike type from 2016 to 2018. Finally, write the results into result.csv following the template of sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-011"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-012", "source": "https://drive.google.com/drive/folders/1cAh_ZTFINYS6PoEnV6VHfo3_cCS4QAnZ?usp=share_link", "instruction": "This is a Bike Store Relational Database, with relevant descriptions provided in the README.md file. You need to assist in selecting the names of the top five users ranked by total expenditure along with their corresponding total expenditure, and then write the results into result.csv following the template of sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-012"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-013", "source": "https://drive.google.com/drive/folders/1WaS17AYMtntVQPjmg7uEboQJTQLMt8sz?usp=share_link", "instruction": "This is a FIFA 20 complete player dataset, with relevant descriptions provided in the README.md file. You need to identify the club with the best average physicality among the top 20 clubs with the highest average scores in FIFA 20. Additionally, according to the description in BMI.txt, you are required to determine the top scorer of the selected club. Record the name of the club and the full name of the player following the template of sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-013"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-014", "source": "https://drive.google.com/drive/folders/1ffMCL3EzHaFgQhXKSQX_n4uEZDWQiExV?usp=share_link", "instruction": "This is the Amazon Musical Instruments Reviews dataset, with relevant descriptions provided in the README.md file. You need to calculate each review’s score using the formula designed in Wilson.tex, then extract summaries of the top 3 reviews. Finally, write the results into result.csv following the template of sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-014"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-015", "source": "https://drive.google.com/drive/folders/1yAz4jIJ4nuBf8qKEvzPYHrzja9RBMdek?usp=share_link", "instruction": "This is a dataset of baseball games, with relevant descriptions provided in the README.md file. You need to help me calculate the player with the most games played, the player with the most runs scored, the player with the most hits, and the player with the most home runs. Each statistical data should include the player’s name and their corresponding data; for example, for the player with the most games played, record their number of games played, and for the player with the most runs scored, record their runs scored. Finally, write the results into result.csv following the template of sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-015"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-016", "source": "https://drive.google.com/drive/folders/1Nfx9mAWRZzmY6e3GPrIb2oAo2JSXfsIs?usp=share_link", "instruction": "This is a dataset for football matches, with relevant descriptions provided in the README.md file. I would like you to help me compile statistics for the seasons and the corresponding winning clubs hosted by IT1 and BESC. Finally, write the results into result.csv following the template of sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-016"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-018", "source": "https://drive.google.com/drive/folders/196KJ6-Xt_zpAyvYUjTuB-j7wzYQrDSka?usp=share_link", "instruction": "This is a Data Science Programs list dataset, with relevant descriptions provided in the README.md file. You need to identify the top 10 universities offering the most affordable data science programs and record their tuition fees. Finally, write the results into result.csv following the template of sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-018"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-019", "source": "https://drive.google.com/drive/folders/1FBBwFmmHPwIq5CaEasj2ngfjEnIXknEI?usp=share_link", "instruction": "This is a La Liga Complete Dataset, with relevant descriptions provided in the README.md file. You need to calculate the top 20 teams by average score and their corresponding number of draws. Finally, write the results into result.csv following the template of sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-019"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-020", "source": "https://drive.google.com/drive/folders/18pL4CXpmnngXz8GYbjog9c1Pkj1kaSRD?usp=share_link", "instruction": "This is a Telco customer churn dataset, with relevant descriptions provided in the README.md file. You need to identify the top 10 cities with the highest telecom customer churn rate and write the results into result.csv following the template of sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-020"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-021", "source": "https://drive.google.com/drive/folders/18pL4CXpmnngXz8GYbjog9c1Pkj1kaSRD?usp=share_link", "instruction": "This is a Marketing Campaigns Dataset, with relevant descriptions provided in the README.md file. You need to identify the top 3 most popular product categories among families with 0, 1, and 2 children, and write the results into result.csv following the template of sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-021"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-022", "source": "https://drive.google.com/drive/folders/1p8b_Tyx_J9g7wpyhn-LlrKSl-pgkk4m6?usp=drive_link", "instruction": "This is a Marketing Campaigns Dataset, with relevant descriptions provided in the README.md file. Assuming the current year is 2024, you need to calculate the Mean Campaign Acceptance Rate by Age for each country according to the year ranges specified in result.csv, and fill in the results in result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-022"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-023", "source": "https://drive.google.com/drive/folders/1BlxnCEL8hNS5s5TwapGsf_FsF-8i0ca_?usp=share_link", "instruction": "This is a Marketing Campaigns Data Set, with relevant descriptions provided in the README.md file. You need to calculate the average number of campaigns it takes for customers with each education level to accept an offer, and write the results into result.csv following the template of sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-023"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-024", "source": "https://drive.google.com/drive/folders/1GDZHUgkCjeXax63vd-fRo6kfo8gUWIri?usp=share_link", "instruction": "This is a Marketing Campaigns Data Set, with relevant descriptions provided in the README.md file. You need to calculate the total number of online purchases and in-store purchases for different income groups, and fill in the results in purchase_by_income.csv. The template for purchase_by_income.csv has been provided.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-024"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-025", "source": "https://drive.google.com/drive/folders/1_ZmzR5S8YNzsl9HhK1YX06y91zoX-xLR?usp=share_link", "instruction": "This is a IPL Complete Dataset (2008-2024), with relevant descriptions provided in the README.md file. Your task is to continue the development of the existing code in analys.py to calculate the winning and losing probabilities for each team. Afterwards, you need to identify the team with the highest probability of winning and the team with the highest probability of losing. Finally, write their names and corresponding (winning or losing) probabilities into team_probabilities.csv following the template provided in sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-025"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-026", "source": "https://drive.google.com/drive/folders/1MNmqFKeUQR7hpgVxc7pPJOcymQa35K9p?usp=share_link", "instruction": "This is a dataset containing information on FIFA 22 players, with detailed descriptions provided in the README.md file. Your task is to complete the analysis.py script to rank the players based on the specified score at the position level. You can find relevant hints in some text (txt) and Markdown (md) files. Ensure that the results are written to the result.csv file in the format demonstrated in sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-026"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-027", "source": "https://drive.google.com/drive/folders/1bzqJXG2xjnXjbzZdW8UYyH7MYVF0ZHsw?usp=share_link", "instruction": "This is a Netflix Data dataset, with detailed descriptions provided in the README.md file. Your task is to identify the top 10 countries by the number of produced shows and their corresponding counts, as well as the top 10 movie genres by the number of occurrences and their corresponding counts. Record the results in the provided templates: Top_10_countries.csv and Top_10_Movies.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-027"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-028", "source": "https://drive.google.com/drive/u/0/folders/1FVNk4S8BxmjlJWER84a8rCsQP4ZUZj3z", "instruction": "This is a Sales Data dataset, with detailed descriptions provided in the README.md file. Your task is to calculate the total profit for each state, sort the results in descending order, and write them into the state_profit.csv file using the provided template.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-028"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-029", "source": "https://drive.google.com/drive/folders/1ibfAui8NvdVlZTQGW5MQab57BKPQeAH_?usp=share_link", "instruction": "This is a dataset titled “The-GitHub-History-of-the-Scala-Language,” with detailed descriptions provided in the README.md file. Your task is to identify the top 3 users with the most pull requests and record their usernames and the number of pull requests in the top3_pull_requests.csv file using the provided template.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-029"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-030", "source": "https://drive.google.com/drive/folders/1Wyg0lPtEKqh3F_sZOnR7wNZFb2iW7yt8?usp=share_link", "instruction": "This is a dataset titled “The-GitHub-History-of-the-Scala-Language,” with detailed descriptions provided in the README.md file. Your task is to identify the latest 10 pull requests, merge the related file data, and find the unique files involved in these pull requests. Record the results in the unique_files.csv file using the sample_result.csv template.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-030"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-031", "source": "https://drive.google.com/drive/folders/1evC6AsX-2sevVmpbE5nlpqrfO1LZgmUJ", "instruction": "This is a dataset titled “The-GitHub-History-of-the-Scala-Language,” with detailed descriptions provided in the README.md file. Your task is to identify the users who made the last 6 pull requests for the specific file \"src/compiler/scala/reflect/reify/phases/Calculate.scala\". Record the results in the users_last_6.csv file using the provided template.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-031"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-032", "source": "https://drive.google.com/drive/folders/1y7Z4-O-2b5O4j3a20CnORFZ3dOcn9cq-?usp=share_link", "instruction": "This is a dataset titled “Mobile-Games-Testing-with-Cookie-Cats,” with detailed descriptions provided in the README.md file. Your task is to calculate the proportion of 1-day retention being True for the gate_30 and gate_40 versions, respectively. Record the results in the retention_by_version.csv file using the provided template.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-032"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-033", "source": "https://drive.google.com/drive/folders/13jdtj7v3Ie4Hj9aasZiNjQUc46PE9eH3?usp=sharing", "instruction": "This is a dataset titled “Mobile-Games-Testing-with-Cookie-Cats,” with detailed descriptions provided in the README.md file. Your task is to compare the 1-day retention rates between two versions of a game (gate_30 and gate_40) according to the instructions in guidance.txt. Calculate the probability that the retention rate is higher for gate_30 and record the result in the probability_greater_retention.csv file using the provided template.\n", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-033"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-034", "source": "https://drive.google.com/drive/folders/19EUef4q8aewkLlRDndOMM55OPCCBsFmo?usp=share_link", "instruction": "This is a dataset titled “Mobile-Games-Testing-with-Cookie-Cats,” with detailed descriptions provided in the README.md file. Your task is to calculate the proportion of 7-day retention being True for the gate_30 and gate_40 versions, respectively. Record the results in the retention_7_by_version.csv file using the provided template.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-034"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-035", "source": "https://drive.google.com/drive/folders/17qStaA8VTAsCf50HWVlZT4x-e7nw2haB?usp=share_link", "instruction": "This dataset is titled “The-GitHub-History-of-the-Scala-Language,” with detailed descriptions provided in the README.md file. Your task is to convert all time columns to Coordinated Universal Time (UTC) and record each user’s pulled files based on their pid. If a user pulled multiple files within one pid, you need to record these files separately. Write the results in the output.csv file using the format provided in sample_output.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-035"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-036", "source": "https://drive.google.com/drive/folders/1o7QlFnyB-_RcHE9Kp7Jfa3VPu1Yf72-S?usp=share_link", "instruction": "This is a dataset titled “The-GitHub-History-of-the-Scala-Language,” with detailed descriptions provided in the README.md file. Your task is to identify the last six users who made pull requests for `src/compiler/scala/reflect/reify/phases/Calculate.scala`. and fill in their usernames in the template file users_last_6.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-036"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-037", "source": "https://drive.google.com/drive/folders/1G-zP7Vu07sIpX4mw598XqS2v8muQXRtf?usp=share_link", "instruction": "This is a dataset titled “The-GitHub-History-of-the-Scala-Language,” with detailed descriptions provided in the README.md file. Your task is to identify the top three users who made the most pull requests for `src/compiler/scala/reflect/reify/phases/Calculate.scala` and fill in their usernames in the template file top_3_developers.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-037"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-038", "source": "https://drive.google.com/drive/folders/1X9N6aLhTfXbic4dgXAt0e8G2x8TaTHir?usp=share_link", "instruction": "This is a dataset titled “The-GitHub-History-of-the-Scala-Language,” with detailed descriptions provided in the README.md file. I want to know the number of pull requests made by two users with the nicknames “soc” and “xeno-by” for each year between 2011 and 2016. Please fill in your statistical results in the provided template file pull_requests_by_year_and_author.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-038"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-039", "source": "https://drive.google.com/drive/folders/16Hk8i_1SqBwYWI3sp-hp4rMAgyynqsjk?usp=share_link", "instruction": "This is an Avocado Toast dataset, with detailed descriptions provided in the README.md file. You need to conduct a supply chain analysis of three ingredients used in an avocado toast, utilizing the Open Food Facts database. Identify the list of ingredients and their countries of origin, and record the results in the ingredient_origins.csv file using the provided template.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-039"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-040", "source": "https://drive.google.com/drive/folders/1VVAuXJEKeeM2MuLAa7Yh68y0JZSjXbhR?usp=sharing", "instruction": "This is a dataset titled “Categorizing salaries,” with detailed descriptions provided in the README.md file. You need to divide the salary scale into four levels according to the salaries of all employees. For the company size with the largest number of top-level employees, find the designations of the top 10 paid employees and their salaries. Write the results in the result.csv file using the format provided in sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-040"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-041", "source": "https://drive.google.com/drive/folders/1tO4GVH2DYJJwF2-HmSf3zTEzOUopthwH?usp=share_link", "instruction": "This is a dataset titled “Police Activity,” with detailed descriptions provided in the README.md file. You need to count the stop outcomes for female and male drivers when they are pulled over for speeding, and express them as proportions. Save the results to the stop_outcomes_by_gender.csv file using the provided template.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-041"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-042", "source": "https://drive.google.com/drive/folders/1qrL2U5vJWbYCNVeAGMiIcXutZULmQnBU?usp=share_link", "instruction": "This task involves working with a user Segmation dataset. Detailed descriptions are provided in the README.md file. Your objective is to calculate the total number of days between the Invoice date and the Cohort date for each entry in the dataset. Save this calculated difference as CohortIndex in the result.csv file.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-042"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-043", "source": "https://drive.google.com/drive/folders/1izUKLoSM66ofPI6CV_l4_gzhM3uIZI5N?usp=share_link", "instruction": "You are provided with a Customer Segmation dataset, and detailed descriptions can be found in the README.md file. Your task is to calculate the retention data for each cohort according to the instructions provided in the tips.txt file. Save the calculated results to a file named retention.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-043"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-044", "source": "https://drive.google.com/drive/folders/1mgjfhA3CF-Ksq7U2WHLCXspVV-RJNWvP?usp=share_link", "instruction": "This is a Customer Segmation dataset, and detailed descriptions are provided in the README.md file. Your task is to calculate the average unit price paid for items by groups of customers over time. Each group should be determined by the month of their first purchase. Save the calculated results in a file named average_price.csv, utilizing the provided template file.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-044"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-045", "source": "https://drive.google.com/drive/folders/1rkI23NdN7xI8LPrKfxQkAiIY0EhQIFJA?usp=share_link", "instruction": "This is a customer Segmentation dataset, with detailed descriptions available in the README.md file. Following the instructions in tips.txt, you need to use the RFM method to calculate values for each CustomerID in the datasmart.csv for the recent 12 months. Save the results in datasmart.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-045"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-046", "source": "https://drive.google.com/drive/folders/1dyc8eZCeu6zKmv0UPn1pIdPZ66KUll-6?usp=share_link", "instruction": "This is a Portfolio Risk Management dataset, with detailed descriptions available in the README.md file. Your task is to calculate the annualized volatility and annualized variance of Microsoft trading data. Fill in the calculated results in result.csv according to the template provided in sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-046"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-047", "source": "https://drive.google.com/drive/folders/1NwxdeEnmJkl6G0Mx9luiN4eLyKsuholH?usp=share_link", "instruction": "This is a Portfolio Risk Management dataset, with detailed descriptions provided in the README.md file. Your task involves calculating the historical beta of FamaFrenchData using the Capital Asset Pricing Model (CAPM). Write the calculated results into result.csv, with the column named “result”.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-047"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-048", "source": "https://drive.google.com/drive/folders/1DrVlEaMwsnu482InXkR_-IjmAwb8BRmH?usp=share_link", "instruction": "This is a Portfolio Risk Management dataset, and detailed descriptions are available in the README.md file. Your task is to calculate the drawdown of USO, an ETF that tracks oil prices. Fill in the results into result.csv, as provided in the corresponding file.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-048"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-050", "source": "https://drive.google.com/drive/folders/1DQdtNaN-K38D6s5WMpqkGUUW1n9mdkTX?usp=share_link", "instruction": "This is a Portfolio Risk Management dataset, with detailed descriptions available in the README.md file. Using the 2017 stock return datasets for the 9 biggest companies, you need to calculate the cumulative returns of three different portfolio strategies: the default portfolio, the equal-weight portfolio, and the market value-weighted portfolio. Write the results into result.csv according to the template provided in sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-050"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-051", "source": "https://drive.google.com/drive/folders/1wajE6rnIL5gxdtPzPg1DU2qLcSdr2RdV?usp=share_link", "instruction": "This is a Portfolio Risk Management dataset, with detailed descriptions provided in the README.md file. Following the instructions in tips.md, you need to calculate the portfolio volatility of the default portfolio and provide the answer in percentage. Write the result into output.csv, with the column named “result”.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-051"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-052", "source": "https://drive.google.com/drive/folders/1fLUJMT9WE5_NbHjnlMG_gvgejo8TrhlL?usp=share_link", "instruction": "This is a customer segmentation dataset, with detailed descriptions available in the README.md file. Following the instructions in tips.md, use a 1-4 scale to calculate the RFM Score and complete the segmentation of users. Write the results into result.csv according to the format provided in sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-052"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-053", "source": "https://drive.google.com/drive/folders/1FXrR01v8UUqjqSO28ukK6UUkIFDe8Jm-?usp=share_link", "instruction": "This is a customer segmentation dataset, with detailed descriptions available in the README.md file. Following the instructions in tips.md, use a 1-3 scale to calculate the RFM Score. For each CustomerID in RFM_Score.csv, calculate the corresponding user’s RFM score and fill in the results in RFM_Score.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-053"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-054", "source": "https://drive.google.com/drive/folders/1uChU1XaP_wqGWPCIYtUF2eUO4y7UMAmc?usp=share_link", "instruction": "This is a Portfolio Risk Management dataset, with detailed descriptions available in the README.md file. Following the instructions in tips.md, calculate the Sharpe Ratio for each asset, and find the minimum and maximum values of the Sharpe ratios. Write the results into result.csv according to the format provided in sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-054"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-055", "source": "https://drive.google.com/drive/folders/1LnrifRqeAvrKIaTQR8HTCN6xuGNImKjz?usp=share_link", "instruction": "This is a Portfolio Risk Management dataset, with detailed descriptions available in the README.md file. Your task is to calculate the cumulative returns of the portfolio (“Portfolio”) and the excess returns over the risk-free rate (“Portfolio_Excess”) of FamaFrenchData over time. After calculating, ensure to fill in your results into result.csv. Please note that the Date column data in result.csv has already been provided.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-055"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-056", "source": "https://drive.google.com/drive/folders/1liDYNKkhlboeM-b4opXRQJfxd842I2Lu?usp=drive_link", "instruction": "This is a Portfolio Risk Management dataset, with detailed descriptions available in the README.md file. Following the instructions in tips.md, calculate the historical beta of FamaFrenchData. Write the results into result.csv according to the format provided in sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-056"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-057", "source": "https://drive.google.com/drive/folders/1jsG1ULrKBLm_CCSpnfAOszZmLJ-yY9-X?usp=share_link", "instruction": "This is a Customer Analytics dataset, with detailed descriptions available in the README.md file. Your task is to calculate a set of summary statistics about the purchase data, broken out by ‘device’ (Android or iOS) and ‘gender’ (Male or Female). Fill the corresponding blanks in purchase_summary.csv with these summary statistics.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-057"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-058", "source": "https://drive.google.com/drive/folders/1waeq3xZJljGcT0rCM31bPf9bpKZ5b1MM?usp=share_link", "instruction": "This is a Customer Analytics dataset, with detailed descriptions available in the README.md file. Your task is to calculate and print the confidence interval for the difference in conversion rates (lift) between a test group and a control group. Write the results into result.csv according to the format provided in sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-058"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-059", "source": "https://drive.google.com/drive/folders/1t1cWSI9zD7hKexuPQtIBxd2fNsXYAQlb?usp=share_link", "instruction": "This is a Customer Analytics dataset, with detailed descriptions available in the README.md file. Based on the registration dates in result.csv, you need to analyze the purchasing behavior of users within the first week of their registration date. Calculate the average number of purchases made in the first week on a daily basis, and then fill the results into result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-059"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-060", "source": "https://drive.google.com/drive/folders/1xUuZ27EPlYFTIxpY4T3IUANcuflqx-4m?usp=share_link", "instruction": "This is a Customer Analytics dataset, with detailed descriptions available in the README.md file. The dataset is a sample of 0.1% of our overall population for ease of use. Your task is to calculate the average daily purchases and paywall views for the entire population. Write the results into result.csv according to the format provided in sample_result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-060"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-061", "source": "https://drive.google.com/drive/folders/16BgZCLUksJ1Kg1hV9tOfOr8sRMHevom7?usp=share_link", "instruction": "This is an Airbnb Market Trends dataset, with detailed descriptions available in the README.md file. Your task is to calculate the dates of the earliest and most recent reviews, the numbers of private rooms, and the average listing price. Fill in the results into result.csv according to the template provided in result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-061"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-063", "source": "https://drive.google.com/drive/folders/1u84GU0Cxb7znHRIGY7_Q2ShT2BUSLiNC?usp=share_link", "instruction": "This is a World’s Oldest Businesses dataset, with detailed descriptions available in the README.md file. Your task is to find the oldest business on each continent and fill in the relevant information into result.csv according to the fomat specified in result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-063"]}}], "post_process": ["plot_process"]}
{"id": "dm-csv-064", "source": "https://drive.google.com/drive/folders/1yVJ8DAhrJXrAgDgNO1LEh_IR8VAkKooh?usp=sharing", "instruction": "This is a World’s Oldest Businesses dataset, with detailed descriptions available in the README.md file. Your task is to identify the restaurants in our dataset that have been around since before the year 1800. Then, fill in their relevant information into result.csv according to the format specified in result.csv.", "hints": null, "hardness": "level1", "config": [{"type": "copy_all_subfiles", "parameters": {"dirs": ["./benchmark/source/dm-csv-064"]}}], "post_process": ["plot_process"]}
